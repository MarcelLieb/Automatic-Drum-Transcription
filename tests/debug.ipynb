{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Inspect training",
   "id": "f718cbf904227e80"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T22:29:06.913906Z",
     "start_time": "2025-07-12T22:29:06.910590Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "from dataclasses import asdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import optim\n",
    "\n",
    "import dataset.mapping"
   ],
   "id": "53530f4eb79566ca",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T22:29:09.827075Z",
     "start_time": "2025-07-12T22:29:06.931991Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dataset.datasets import get_dataset\n",
    "from settings import TrainingSettings, AnnotationSettings, AudioProcessingSettings, CNNSettings, EvaluationSettings, \\\n",
    "    DatasetSettings\n",
    "from main import train_epoch, evaluate\n",
    "from model.cnn import CNN"
   ],
   "id": "58116c4c864135f7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "training_settings: TrainingSettings = TrainingSettings(epochs=30, scheduler=False, num_workers=16)\n",
    "audio_settings: AudioProcessingSettings = AudioProcessingSettings()\n",
    "annotation_settings: AnnotationSettings = AnnotationSettings(time_shift=0.0)\n",
    "dataset_settings = DatasetSettings(\n",
    "    audio_settings=audio_settings,\n",
    "    annotation_settings=annotation_settings,\n",
    ")\n",
    "cnn_settings = CNNSettings()\n",
    "evaluation_settings = EvaluationSettings()\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(device)"
   ],
   "id": "a69a39d184389ef4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib import color_sequences\n",
    "\n",
    "print(color_sequences)\n",
    "\n",
    "colors = np.array([\n",
    "    [230, 25, 75],\n",
    "    [60, 180, 75],\n",
    "    [255, 225, 25],\n",
    "    [0, 130, 200],\n",
    "    [245, 130, 48],\n",
    "    [145, 30, 180],\n",
    "    [70, 240, 240],\n",
    "    [240, 50, 230],\n",
    "    [210, 245, 60],\n",
    "    [250, 190, 190],\n",
    "    [0, 128, 128],\n",
    "    [230, 190, 255],\n",
    "    [170, 110, 40],\n",
    "    [255, 250, 200],\n",
    "    [128, 0, 0],\n",
    "    [170, 255, 195],\n",
    "    [128, 128, 0],\n",
    "    [255, 215, 180],\n",
    "    [0, 0, 128],\n",
    "    [128, 128, 128],\n",
    "    [0, 0, 0],\n",
    "]) / 255\n",
    "colormap = ListedColormap(colors, N=21)\n",
    "\n",
    "# Plot a pseudo pr curve\n",
    "for i in range(10):\n",
    "    x = np.linspace(0, 1, 100)\n",
    "    y = np.sin(x * np.pi * i) * 0.5 + 0.5\n",
    "    plt.plot(x, y, color=colors[i], label=f\"Class {i}\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall curve\")"
   ],
   "id": "4dbc04e9a5da33f6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "loader_train, loader_val, loader_test_rbma, loader_test_mdb = get_dataset(\n",
    "    training_settings, audio_settings, annotation_settings\n",
    ")"
   ],
   "id": "61db910bb080af78"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = CNN(**asdict(cnn_settings))\n",
    "model.to(device)"
   ],
   "id": "e161a78cc35b7fba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "max_lr = training_settings.learning_rate\n",
    "initial_lr = max_lr / 25\n",
    "_min_lr = initial_lr / 1e4\n",
    "initial_lr = (\n",
    "    training_settings.learning_rate\n",
    "    if not training_settings.scheduler\n",
    "    else initial_lr\n",
    ")\n",
    "optimizer = optim.RAdam(\n",
    "    model.parameters(), lr=initial_lr, weight_decay=1e-5\n",
    ")\n",
    "scheduler = (\n",
    "    optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer,\n",
    "        max_lr=max_lr,\n",
    "        steps_per_epoch=len(loader_train),\n",
    "        epochs=training_settings.epochs,\n",
    "    )\n",
    "    if training_settings.scheduler\n",
    "    else None\n",
    ")\n",
    "error = torch.nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ],
   "id": "d7262fdde2f89fa4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model.to(device)\n",
    "best_loss = float(\"inf\")\n",
    "best_score = 0\n",
    "last_improvement = 0\n",
    "for epoch in range(10):\n",
    "    train_loss = train_epoch(\n",
    "        epoch,\n",
    "        loader_train,\n",
    "        device,\n",
    "        None,\n",
    "        error,\n",
    "        model,\n",
    "        optimizer,\n",
    "        scaler,\n",
    "        scheduler,\n",
    "        tensorboard_writer=None,\n",
    "    )\n",
    "    val_loss, f_score, avg_f_score = evaluate(\n",
    "        epoch,\n",
    "        model,\n",
    "        loader_val,\n",
    "        error,\n",
    "        device,\n",
    "        evaluation_settings.ignore_beats,\n",
    "        tensorboard_writer=None,\n",
    "        tag=\"Validation\",\n",
    "    )\n",
    "    print(\n",
    "        f\"Epoch: {epoch + 1} \"\n",
    "        f\"Loss: {train_loss * 100:.4f}\\t \"\n",
    "        f\"Val Loss: {val_loss * 100:.4f} F-Score: {avg_f_score * 100:.4f}/{f_score * 100:.4f}\"\n",
    "    )"
   ],
   "id": "f42846831e2f2c6d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "torch.cuda.empty_cache()\n",
    "model.cpu()\n",
    "loader = iter(loader_test_rbma)"
   ],
   "id": "11af8aa2edcf8f65"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "spec, target, annotation = next(loader)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(spec)"
   ],
   "id": "b9b727261820ea55"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(output.shape)\n",
    "print(target.shape)\n",
    "print(spec.shape)"
   ],
   "id": "e6d2727422c29259"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "section = range(1000, 20000)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(output[0][0][section].numpy(), label=\"Output\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "5015faf065a93fc8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "section = range(1000, 20000)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(output[0][0][section].numpy(), label=\"Output\")\n",
    "plt.plot(target[0][0][section].numpy(), label=\"Target\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "9046e27d3547c1cb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from model import ResidualBlock1d  # , CausalConv2d, ResidualBlock\n",
    "\n",
    "eps = np.nextafter(np.float16(0.0), np.float16(1.0))\n",
    "class_idx = 2\n",
    "offset = 1\n",
    "first_label = target[0][class_idx].nonzero()[15]\n",
    "print(first_label)\n",
    "\n",
    "causal_test = spec.clone()\n",
    "causal_test[0, :, :first_label + offset] = 0\n",
    "# causal_test[0, :, first_label+offset+30:] = 0\n",
    "empty_model = ResidualBlock1d(1, 1, kernel_size=5)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # output = model(causal_test)\n",
    "    empty_output = empty_model(causal_test.unsqueeze(1)).squeeze(1)\n",
    "\n",
    "output = empty_output\n",
    "\n",
    "print(torch.min(output[0, class_idx, first_label - offset - 40:first_label + offset]))\n",
    "print(torch.max(output[0, class_idx, first_label - offset - 40:first_label + offset]))\n",
    "print(torch.min(output[0, class_idx, first_label + offset:]))\n",
    "print(torch.max(output[0, class_idx, first_label + offset:]))\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(output[0][0][first_label + offset - 10 - 1:first_label + offset + 10].numpy(), label=\"Output\")\n",
    "plt.minorticks_on()"
   ],
   "id": "6d6297ac4bf58933"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Test spectogram alignment",
   "id": "65fcacfaa74955d8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import nnAudio.features\n",
    "from dataset.RBMA13 import RBMA13\n",
    "from dataset import load_audio\n",
    "import torchaudio\n",
    "import librosa\n",
    "from dataset import get_time_index, get_indices"
   ],
   "id": "bdabbf1a09e3ce45"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "rbma = RBMA13(\n",
    "    path=\"./data/rbma_13\",\n",
    "    settings=dataset_settings,\n",
    "    use_dataloader=False,\n",
    "    is_train=False,\n",
    ")"
   ],
   "id": "a4a30525b6aabfb8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "mel_log, labels, gt = rbma[2]\n",
    "test_audio = load_audio(rbma.get_full_path(\"RBMA-13-Track-03\"), audio_settings.sample_rate, audio_settings.normalize)\n",
    "gt = gt[2:]"
   ],
   "id": "3851b4bdff3c31a2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "cqt = nnAudio.features.CQT1992v2(\n",
    "    sr=audio_settings.sample_rate,\n",
    "    hop_length=audio_settings.hop_size,\n",
    "    fmin=20,\n",
    "    fmax=20000,\n",
    "    bins_per_octave=12,\n",
    "    pad_mode=audio_settings.pad_mode,\n",
    ")\n",
    "\n",
    "nnAudio_stft = nnAudio.features.STFT(\n",
    "    n_fft=audio_settings.fft_size,\n",
    "    hop_length=audio_settings.hop_size,\n",
    "    win_length=audio_settings.fft_size // 2,\n",
    "    window=\"hann\",\n",
    "    center=audio_settings.center,\n",
    "    pad_mode=audio_settings.pad_mode,\n",
    "    trainable=False,\n",
    "    output_format=\"Magnitude\",\n",
    ")\n",
    "\n",
    "torch_stft = torchaudio.transforms.Spectrogram(\n",
    "    n_fft=audio_settings.fft_size,\n",
    "    hop_length=audio_settings.hop_size,\n",
    "    win_length=audio_settings.fft_size // 2,\n",
    "    power=2,\n",
    "    center=audio_settings.center,\n",
    "    pad_mode=audio_settings.pad_mode,\n",
    "    normalized=True,\n",
    "    onesided=True,\n",
    ")\n",
    "\n",
    "mel = torchaudio.transforms.MelScale(\n",
    "    n_mels=audio_settings.n_mels,\n",
    "    sample_rate=audio_settings.sample_rate,\n",
    "    f_min=audio_settings.mel_min,\n",
    "    f_max=audio_settings.mel_max,\n",
    "    n_stft=audio_settings.fft_size // 2 + 1,\n",
    ")"
   ],
   "id": "205fcb8f92853690"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "cqt_spec = cqt(test_audio)[0]\n",
    "torch_stft_spec = torch_stft(test_audio)\n",
    "nnAudio_stft_spec = nnAudio_stft(test_audio)\n",
    "mel_spec = mel(torch_stft_spec)\n",
    "print(torch_stft_spec.shape)\n",
    "print(nnAudio_stft_spec.shape)\n",
    "print(cqt_spec.shape)\n",
    "print(mel_spec.shape)"
   ],
   "id": "457455519902d117"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(torch_stft_spec.shape[-1] / audio_settings.sample_rate * audio_settings.hop_size)\n",
    "print(nnAudio_stft_spec.shape[-1] / audio_settings.sample_rate * audio_settings.hop_size)\n",
    "print(cqt_spec.shape[-1] / audio_settings.sample_rate * audio_settings.hop_size)\n",
    "print(test_audio.shape[-1] / audio_settings.sample_rate)\n",
    "print(audio_settings.fft_size // audio_settings.hop_size)"
   ],
   "id": "28b86f8a2dea396b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plot_range = slice(000, 200)\n",
    "\n",
    "gt_labels = [np.array(\n",
    "    [label - plot_range.start / 100 for label in cls if plot_range.start <= int(label * 100) <= plot_range.stop]) for\n",
    "    cls in gt]\n",
    "print(gt_labels)\n",
    "\n",
    "db = librosa.amplitude_to_db(cqt_spec[:, plot_range], ref=np.max)\n",
    "fig, ax = plt.subplots(nrows=3)\n",
    "_img1 = librosa.display.specshow(\n",
    "    db,\n",
    "    y_axis='cqt_hz',\n",
    "    x_axis='time',\n",
    "    ax=ax[0],\n",
    "    sr=audio_settings.sample_rate,\n",
    "    hop_length=audio_settings.hop_size,\n",
    "    fmin=20,\n",
    "    fmax=20000,\n",
    ")\n",
    "ax[0].set(title='CQT spectrogram')\n",
    "\n",
    "M = mel_spec[:, plot_range].detach().numpy()\n",
    "M_db = librosa.power_to_db(M, ref=np.max)\n",
    "_img2 = librosa.display.specshow(\n",
    "    M_db,\n",
    "    y_axis='mel',\n",
    "    x_axis='time',\n",
    "    ax=ax[1],\n",
    "    sr=audio_settings.sample_rate,\n",
    "    hop_length=audio_settings.hop_size,\n",
    "    fmin=audio_settings.mel_min,\n",
    "    fmax=audio_settings.mel_max\n",
    ")\n",
    "ax[1].set(title='Mel spectrogram')\n",
    "\n",
    "time = get_time_index(plot_range.stop - plot_range.start, audio_settings.sample_rate, audio_settings.hop_size)\n",
    "time = np.array([time] * annotation_settings.n_classes).T\n",
    "\n",
    "ax[0].vlines(time[labels[:, plot_range].T == 1], ymin=0, ymax=1)\n",
    "ax[1].vlines(time[labels[:, plot_range].T == 1], ymin=0, ymax=1)\n",
    "ax[2].vlines(time[labels[:, plot_range].T == 1], ymin=0, ymax=1, colors=[\"blue\"])\n",
    "for cls in gt_labels:\n",
    "    ax[2].vlines(cls, ymin=0, ymax=1, colors=[\"red\"])\n",
    "ax[2].set_xlim(left=0, right=time[-1][0])\n",
    "plt.tight_layout()"
   ],
   "id": "e7d4014aed611154"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "sample_rate = audio_settings.sample_rate\n",
    "hop_size = audio_settings.hop_size\n",
    "fft_size = audio_settings.fft_size\n",
    "\n",
    "for cls in gt_labels:\n",
    "    if len(cls) == 0:\n",
    "        continue\n",
    "    index = get_indices(cls, sample_rate, hop_size)\n",
    "    time = get_time_index(np.max(index) + 1, sample_rate, hop_size)\n",
    "    assert np.allclose(time[index], cls,\n",
    "                       atol=hop_size / sample_rate / 2), f\"{time[index][np.abs(time[index] - cls) > hop_size / sample_rate / 2]} \\n{cls[np.abs(time[index] - cls) > hop_size / sample_rate / 2]}\"\n",
    "    print()\n"
   ],
   "id": "9b43a325a98c0ca7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Test audio loading",
   "id": "57b1a84b4bc8de89"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%matplotlib inline\n",
    "import librosa\n",
    "from dataset import load_audio, get_length\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd"
   ],
   "id": "6e0b042456656a10"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def plot_audio(audio, sr, title=\"\", offset=0, num_samples=None):\n",
    "    if num_samples is None:\n",
    "        num_samples = len(audio)\n",
    "    t = np.arange(offset, num_samples + offset) / sr\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(t, audio[offset:offset + num_samples])\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Time [s]\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.show()"
   ],
   "id": "10989be678c39075"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "audio_path = \"./data/a2md_public/ytd_audio/dist0p00/ytd_audio_00040_TRVNNMF128F4285161.mp3\"\n",
    "sample_rate = librosa.get_samplerate(audio_path)\n",
    "duration = get_length(audio_path)\n",
    "print(sample_rate, duration)\n",
    "segment = (12, 20)\n",
    "print(segment[0] * sample_rate, segment[1] * sample_rate)"
   ],
   "id": "3b3cef4e251f476a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import timeit\n",
    "\n",
    "n_runs = 10\n",
    "\n",
    "torch_time = timeit.timeit(\n",
    "    lambda: torchaudio.load(audio_path, frame_offset=int(segment[0] * sample_rate),\n",
    "                            num_frames=int((segment[1] - segment[0]) * sample_rate), backend=\"ffmpeg\", normalize=True),\n",
    "    number=n_runs\n",
    ")\n",
    "\n",
    "librosa_time = timeit.timeit(\n",
    "    lambda: librosa.load(audio_path, sr=sample_rate, offset=segment[0], duration=segment[1] - segment[0]),\n",
    "    number=n_runs\n",
    ")\n",
    "\n",
    "loader_time = timeit.timeit(\n",
    "    lambda: load_audio(path=audio_path, sample_rate=sample_rate, start=segment[0], end=segment[1], normalize=False,\n",
    "                       backend=\"sox\"),\n",
    "    number=n_runs\n",
    ")\n",
    "\n",
    "print(f\"Loader: {loader_time:.4f} s\")\n",
    "print(f\"Torch: {torch_time:.4f} s\")\n",
    "print(f\"Librosa: {librosa_time:.4f} s\")"
   ],
   "id": "b544dd72ec001a98"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "torch_audio = %time torchaudio.load(audio_path, frame_offset=int(segment[0] * sample_rate), num_frames=int((segment[1] - segment[0]) * sample_rate), normalize=True)[0].squeeze()\n",
    "librosa_audio, _ = %time librosa.load(audio_path, sr=sample_rate, offset=segment[0], duration=segment[1] - segment[0])\n",
    "loader_audio = %time load_audio(path=audio_path, sample_rate=sample_rate, start=segment[0], end=segment[1], normalize=False)"
   ],
   "id": "85fcfe1a8882ed9e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "ref_index = np.argmax(np.abs(librosa_audio))\n",
    "other_ref_index = torch.argmax(torch.abs(torch_audio)).item()\n",
    "if ref_index != other_ref_index:\n",
    "    print(ref_index, other_ref_index)\n",
    "\n",
    "index = torch.argmax(torch.abs(loader_audio)).item()\n",
    "actual_offset = index - ref_index\n",
    "print(actual_offset)\n",
    "print(actual_offset / sample_rate)"
   ],
   "id": "f5ac1d34e55f3d93"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(loader_audio.shape, loader_audio.dtype)\n",
    "print(torch_audio.shape, torch_audio.dtype)\n",
    "print(librosa_audio.shape, librosa_audio.dtype)"
   ],
   "id": "ea971d44bf41ac07"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(torch.max(loader_audio).item(), torch.min(loader_audio).item())\n",
    "print(torch.max(torch_audio).item(), torch.min(torch_audio).item())\n",
    "print(np.max(librosa_audio), np.min(librosa_audio))\n",
    "print()\n",
    "\n",
    "difference = loader_audio.shape[-1] - torch_audio.shape[-1]\n",
    "if difference != 0:\n",
    "    print(f\"Loader audio is longer by {difference} samples\")\n",
    "    # loader_audio = loader_audio[difference:]\n",
    "\n",
    "if not np.allclose(librosa_audio, torch_audio.numpy(), atol=1e-5):\n",
    "    print(f\"Librosa and torch audio are not equal\")\n",
    "    print(np.max(np.abs(librosa_audio - torch_audio.numpy())))\n",
    "if not np.allclose(loader_audio.numpy(), torch_audio.numpy(), atol=1e-5):\n",
    "    print(f\"Loader and torch audio are not equal\")\n",
    "    print(np.max(np.abs(loader_audio.numpy() - torch_audio.numpy())))\n",
    "if not np.allclose(loader_audio, librosa_audio, atol=1e-5):\n",
    "    print(f\"Loader and librosa audio are not equal\")\n",
    "    print(np.max(np.abs(loader_audio.numpy() - librosa_audio)))"
   ],
   "id": "bbd739637629e5e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "abs_error = 1e-4\n",
    "mask = (~(np.isclose(loader_audio.numpy(), librosa_audio, atol=abs_error))).nonzero()\n",
    "print(mask, len(mask[0]))\n",
    "errors = loader_audio[~np.isclose(loader_audio.numpy(), librosa_audio, atol=abs_error)]\n",
    "print(errors.shape, errors.shape[-1] / loader_audio.shape[-1])"
   ],
   "id": "4874d57710df63e1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if difference > 0:\n",
    "    extra_audio = loader_audio[:difference]\n",
    "    extra_audio = extra_audio / torch.max(extra_audio)\n",
    "    ipd.Audio(extra_audio, rate=sample_rate)"
   ],
   "id": "c666e1428c7d58f5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "num_samples = 800\n",
    "offset = 0"
   ],
   "id": "52a1462f889d6af8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plot_audio(loader_audio, sample_rate, \"Loader audio\", num_samples=num_samples, offset=offset)\n",
    "plot_audio(torch_audio.numpy(), sample_rate, \"Torch audio\", num_samples=num_samples, offset=offset)\n",
    "plot_audio(librosa_audio, sample_rate, \"Librosa audio\", num_samples=num_samples, offset=offset)"
   ],
   "id": "46a81517f57f1636"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "ipd.Audio(loader_audio.numpy(), rate=sample_rate)",
   "id": "31b9d5b6bb6b5578"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Dataset inspection",
   "id": "62337c466f14ec29"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from pretty_midi import PrettyMIDI\n",
    "import pretty_midi\n",
    "import numpy as np\n",
    "from dataset.A2MD import get_tracks"
   ],
   "id": "4a650916eb340ef8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "midi = PrettyMIDI(\"./data/a2md_public/align_mid/dist0p00/align_mid_00012_TRYIYUF128F932573D.mid\")",
   "id": "d31a659af740b382"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_drum_pitch_velocity(_midi: PrettyMIDI) -> np.ndarray:\n",
    "    drum_instruments: list[pretty_midi.Instrument] = [\n",
    "        instrument for instrument in _midi.instruments if instrument.is_drum\n",
    "    ]\n",
    "    notes = np.array(\n",
    "        [\n",
    "            (note.pitch, note.velocity)\n",
    "            for instrument in drum_instruments\n",
    "            for note in instrument.notes\n",
    "        ]\n",
    "    )\n",
    "    return notes\n",
    "\n",
    "\n",
    "np.array(drum_instruments[0])\n",
    "# np.unique(notes[:, 0].astype(int), return_counts=True)"
   ],
   "id": "f061d108c2048665"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Inspect trained model",
   "id": "b58b31141180d274"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T22:29:09.842462200Z",
     "start_time": "2025-07-06T13:45:00.495299Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.RBMA13 import RBMA13\n",
    "from dataset.A2MD import A2MD\n",
    "from settings import DatasetSettings, CNNMambaSettings, TrainingSettings, CNNSettings, CNNAttentionSettings\n",
    "from dataclasses import asdict\n",
    "import dataset\n",
    "from evallib import peak_pick_max_mean, calculate_pr\n",
    "\n",
    "from model.CRNN import CRNN\n",
    "from model.unet import UNet\n",
    "from model.cnnM2 import CNNMambaFast\n",
    "from model.cnnM import CNNMamba\n",
    "from model.cnnA import CNNAttention"
   ],
   "id": "f28a989b0fecf9e8",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T22:29:09.842976700Z",
     "start_time": "2025-07-06T13:45:41.895510Z"
    }
   },
   "cell_type": "code",
   "source": "checkpoint = torch.load(\"../models/Jul06_14-22-00_marclie-desktop_mamba_fast_81.15.pt\", map_location=torch.device(\"cpu\"))",
   "id": "42d2638a9f5f03bd",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T22:29:09.843491500Z",
     "start_time": "2025-07-06T13:45:44.853518Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.cuda.empty_cache()\n",
    "dataset_settings = DatasetSettings.from_flat_dict(checkpoint[\"dataset_settings\"])\n",
    "dataset_settings.segment_type = None\n",
    "training_settings = TrainingSettings.from_flat_dict(checkpoint[\"training_settings\"])\n",
    "model_settings = training_settings.get_model_settings_class().from_flat_dict(checkpoint[\"model_settings\"])\n",
    "match training_settings.model_settings:\n",
    "    case \"cnn\":\n",
    "        model = CNN(**asdict(model_settings), n_classes=dataset_settings.annotation_settings.n_classes,\n",
    "                    n_mels=checkpoint[\"dataset_settings\"][\"n_mels\"])\n",
    "    case \"cnn_attention\":\n",
    "        model = CNNAttention(**asdict(model_settings), n_classes=dataset_settings.annotation_settings.n_classes,\n",
    "                             n_mels=checkpoint[\"dataset_settings\"][\"n_mels\"])\n",
    "    case \"mamba\":\n",
    "        model = CNNMamba(**asdict(model_settings), n_classes=dataset_settings.annotation_settings.n_classes,\n",
    "                         n_mels=checkpoint[\"dataset_settings\"][\"n_mels\"])\n",
    "    case \"mamba_fast\":\n",
    "        model = CNNMambaFast(**asdict(model_settings), n_classes=dataset_settings.annotation_settings.n_classes,\n",
    "                             n_mels=checkpoint[\"dataset_settings\"][\"n_mels\"])\n",
    "    case \"unet\":\n",
    "        model = UNet(**asdict(model_settings))\n",
    "    case \"crnn\":\n",
    "        model = CRNN(**asdict(model_settings), n_classes=dataset_settings.annotation_settings.n_classes,\n",
    "                     n_mels=checkpoint[\"dataset_settings\"][\"n_mels\"])\n",
    "    case _:\n",
    "        raise ValueError(\"Invalid model setting\")\n",
    "model.load_state_dict(checkpoint[\"model\"])\n",
    "model = model.eval()"
   ],
   "id": "e2058bb5ec43e9c3",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T22:29:09.843491500Z",
     "start_time": "2025-07-06T14:02:13.550310Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate weight stats\n",
    "def get_weight_stats(model: torch.nn.Module):\n",
    "    weights = []\n",
    "    for name, param in model.named_parameters():\n",
    "        if \"weight\" in name:\n",
    "            weights.append(param.data.flatten())\n",
    "    weights = torch.cat(weights, dim=0)\n",
    "    return {\n",
    "        \"mean\": weights.mean().item(),\n",
    "        \"std\": weights.std().item(),\n",
    "        \"min\": weights.min().item(),\n",
    "        \"max\": weights.max().item(),\n",
    "    }\n",
    "\n",
    "print(get_weight_stats(model))\n",
    "print(torch.nextafter(torch.tensor(0.0, dtype=torch.float16), torch.tensor(1.0, dtype=torch.float16)), torch.nextafter(torch.tensor(0.0, dtype=torch.bfloat16), torch.tensor(1.0, dtype=torch.bfloat16)))\n",
    "print(torch.finfo(torch.float16).max, torch.finfo(torch.bfloat16).max)"
   ],
   "id": "749955fa4ab8242f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean': 0.00033131445525214076, 'std': 0.04683024436235428, 'min': -0.9670994877815247, 'max': 1.0618863105773926}\n",
      "tensor(5.9605e-08, dtype=torch.float16) tensor(9.1835e-41, dtype=torch.bfloat16)\n",
      "65504.0 3.3895313892515355e+38\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "training_settings",
   "id": "505c1f9e3a42525e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "rbma = RBMA13(\n",
    "    path=\"../data/rbma_13\",\n",
    "    settings=dataset_settings,\n",
    "    use_dataloader=True,\n",
    "    is_train=False,\n",
    "    segment=False,\n",
    ")\n",
    "\n",
    "rbma_loader = dataset.get_dataloader(rbma, 1, 1, is_train=False)\n",
    "\n",
    "a2md = A2MD(\n",
    "    path=\"data/a2md_public\",\n",
    "    settings=dataset_settings,\n",
    "    use_dataloader=False,\n",
    "    is_train=False,\n",
    "    segment=False,\n",
    ")"
   ],
   "id": "5fa5396d266adeaa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "mel_log, labels, gt = next(iter(rbma_loader))\n",
    "print(mel_log.shape, labels.shape, len(gt[0]))\n",
    "gt = gt[0][2:]"
   ],
   "id": "60ce5b160cbb131e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "next(iter(rbma_loader))",
   "id": "92ded97262d785fe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = model.cuda()\n",
    "output: torch.Tensor = model(mel_log.cuda()).detach().cpu().sigmoid().squeeze(0)\n",
    "print(output.shape)"
   ],
   "id": "5566d8f8da79d58b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "peaks = peak_pick_max_mean(output.unsqueeze(0), dataset_settings.audio_settings.sample_rate, dataset_settings.audio_settings.hop_size, dataset_settings.audio_settings.fft_size)\n",
    "for cls in peaks:\n",
    "    for peak in cls:\n",
    "        peak[0] -= dataset_settings.annotation_settings.time_shift\n",
    "_, _, _, score_sum, score_avg, _ = calculate_pr(peaks, [gt], detection_window=0.025)\n",
    "score_avg, score_sum"
   ],
   "id": "668a90331ffc6544"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = model.cuda()\n",
    "with torch.inference_mode():\n",
    "    segment = mel_log[..., 6200:7000]\n",
    "    print(segment.min(), segment.max())\n",
    "    segment = segment.cuda()\n",
    "    # for some reason, the output is dependent on the segment length\n",
    "    expected_output = model(segment)[..., :400].detach().cpu().squeeze(0)\n",
    "    # plt.plot(expected_output[0].numpy(), scaley=False)\n",
    "    for i in range(100):\n",
    "        # segment = (torch.rand_like(segment) * 8 + 1).log()\n",
    "        random = (torch.rand_like(segment) * 8 + 1).log()\n",
    "        in_seg = torch.concatenate([segment, random], dim=-1)\n",
    "        out_mixed = model(in_seg)[..., :400].detach().cpu().squeeze(0)\n",
    "        # plt.plot((out_mixed - expected_output).abs()[0].numpy(), scaley=True)\n",
    "        # assert torch.allclose(expected_output, out_clean, atol=1e-7), f\"{(out_clean - expected_output).abs().sum().item(), (out_clean - expected_output).argmax(dim=-1)}\"\n",
    "        assert torch.allclose(out_mixed, expected_output,\n",
    "                              atol=1e-9), f\"{(out_mixed - expected_output).abs().sum().item(), (out_mixed - expected_output).argmax(dim=-1)}\""
   ],
   "id": "4b34a74965a95da"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "gt_labels = dataset.get_labels(gt, dataset_settings.audio_settings.sample_rate, dataset_settings.audio_settings.hop_size, labels.shape[-1])\n",
    "plt.plot(output[0, 7230:7230 + 10].numpy(), scaley=False)\n",
    "plt.plot(labels[0, 0, 7230:7230 + 10].numpy(), scaley=False)\n",
    "plt.plot(gt_labels[0, 7230:7230 + 10].numpy(), scaley=False)"
   ],
   "id": "8e9d1a91a1f7c955"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "num_pos, num_neg = a2md.get_sample_distribution()\n",
    "# weights according to https://markcartwright.com/files/cartwright2018increasing.pdf section 3.4.1 Task weights\n",
    "total = (num_pos + num_neg)[0]\n",
    "print(num_pos)\n",
    "p_i = num_pos / (total * dataset_settings.annotation_settings.n_classes)\n",
    "weight = 1 / (-p_i * p_i.log() - (1 - p_i) * (1 - p_i).log())\n",
    "weight"
   ],
   "id": "3b41ea3cd5efaf7f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Test Causal Blocks",
   "id": "5cffcfe789b0ba1b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "from model import CausalAvgPool1d, CausalConv1d, CausalConv2d, CausalMaxPool1d, ResidualBlock\n",
    "from model.cnn_feature import CNNFeature\n",
    "from functools import partial"
   ],
   "id": "cf98ae631f1cc1b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "blocks_to_test = [\n",
    "    partial(torch.nn.Conv2d, 100, 32, 1),\n",
    "    partial(torch.nn.MaxPool2d, kernel_size=(2, 1), stride=(2, 1)),\n",
    "    partial(torch.nn.Dropout2d, 0.3),\n",
    "    partial(ResidualBlock, 100, 10, 3),\n",
    "    partial(CNNFeature, num_channels=16, n_layers=2, down_sample_factor=2, channel_multiplication=2, activation=torch.nn.ReLU(), causal=True, dropout=0.3, in_channels=100)\n",
    "]"
   ],
   "id": "2bcff8c7af5c5840"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "torch.use_deterministic_algorithms(True)\n",
    "compare_size = 64\n",
    "for block in blocks_to_test:\n",
    "    mod = block().eval()\n",
    "    print(f\"Testing: {mod.__class__}\")\n",
    "    for name, param in mod.named_parameters():\n",
    "        # Set weights to one\n",
    "        if 'weight' in name:\n",
    "              param.data = torch.ones_like(param)\n",
    "        elif 'bias' in name:\n",
    "              param.data = torch.ones_like(param)\n",
    "    with torch.inference_mode():\n",
    "        for i in range(100):\n",
    "            a = torch.rand(1, 100, 10, compare_size)\n",
    "            b = torch.concatenate([a, torch.rand_like(a)[..., :]], dim=-1)\n",
    "            assert (mod(a)[..., :compare_size] == mod(b)[..., :compare_size]).all(), f\"Error in iteration {i}: {(mod(a)[..., :compare_size] - mod(b)[..., :compare_size]).abs().sum()}\""
   ],
   "id": "7745f3457d8e1a3d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Learning rate finder",
   "id": "9d869628fc9d94c6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from dataclasses import asdict\n",
    "\n",
    "\n",
    "from dataset.datasets import get_dataset\n",
    "from hyperparameters import final_experiment_params\n",
    "from settings import Config\n",
    "from model.CRNN import CRNN\n",
    "from model.unet import UNet\n",
    "from model.cnnM2 import CNNMambaFast\n",
    "from model.cnnM import CNNMamba\n",
    "from model.cnnA import CNNAttention\n",
    "\n",
    "from torch_lr_finder import LRFinder, TrainDataLoaderIter, ValDataLoaderIter\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n"
   ],
   "id": "4fbb25ce774aa377"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"..\")\n",
    "# get the current working directory\n",
    "current_working_directory = os.getcwd()\n",
    "current_working_directory"
   ],
   "id": "29c1a8904df3b427"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class CustomTrainIter(TrainDataLoaderIter):\n",
    "    def inputs_labels_from_batch(self, batch_data):\n",
    "        return batch_data[0], batch_data[1]\n",
    "\n",
    "class CustomValIter(ValDataLoaderIter):\n",
    "    def inputs_labels_from_batch(self, batch_data):\n",
    "        return batch_data[0], batch_data[1]"
   ],
   "id": "8cc4710fbdd25f4c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "config = Config.from_flat_dict(final_experiment_params[\"Mamba fast\"])\n",
    "\n",
    "model_settings = config.model\n",
    "match config.training.model_settings:\n",
    "    case \"cnn\":\n",
    "        model = CNN(**asdict(model_settings), n_classes=config.dataset.annotation_settings.n_classes,\n",
    "                    n_mels=config.dataset.audio_settings.n_mels)\n",
    "    case \"cnn_attention\":\n",
    "        model = CNNAttention(**asdict(model_settings), n_classes=config.dataset.annotation_settings.n_classes,\n",
    "                             n_mels=config.dataset.audio_settings.n_mels)\n",
    "    case \"mamba\":\n",
    "        model = CNNMamba(**asdict(model_settings), n_classes=config.dataset.annotation_settings.n_classes,\n",
    "                         n_mels=config.dataset.audio_settings.n_mels)\n",
    "    case \"mamba_fast\":\n",
    "        model = CNNMambaFast(**asdict(model_settings), n_classes=config.dataset.annotation_settings.n_classes,\n",
    "                             n_mels=config.dataset.audio_settings.n_mels)\n",
    "    case \"unet\":\n",
    "        model = UNet(**asdict(model_settings))\n",
    "    case \"crnn\":\n",
    "        model = CRNN(**asdict(model_settings), n_classes=config.dataset.annotation_settings.n_classes,\n",
    "                     n_mels=config.dataset.audio_settings.n_mels)\n",
    "    case _:\n",
    "        raise ValueError(\"Invalid model setting\")"
   ],
   "id": "53755f1a384eab01"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "config.training.dataset_version = \"S\"\n",
    "config.training.test_sets = ()\n",
    "\n",
    "train_loader, val_loader, _ = get_dataset(config.training, config.dataset)"
   ],
   "id": "6f5590bd059f3332"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = model.cuda()\n",
    "\n",
    "optimizer = optim.RAdam(\n",
    "    model.parameters(),\n",
    "    lr=config.training.learning_rate,\n",
    "    betas=(config.training.beta_1, config.training.beta_2),\n",
    "    weight_decay=config.training.weight_decay,\n",
    "    decoupled_weight_decay=config.training.decoupled_weight_decay,\n",
    "    eps=config.training.epsilon,\n",
    ")\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "amp_config = {\n",
    "    'device_type': 'cuda',\n",
    "    'dtype': torch.float16,\n",
    "}\n",
    "grad_scaler = torch.amp.GradScaler(\"cuda\")\n"
   ],
   "id": "f42f39a4ce629e2e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "lr_finder = LRFinder(\n",
    "    model, optimizer, criterion, device='cuda',\n",
    "    amp_backend='torch', amp_config=amp_config, grad_scaler=grad_scaler\n",
    ")\n",
    "lr_finder.range_test(train_loader, val_loader=val_loader, start_lr=1e-6, end_lr=0.1, num_iter=100)\n",
    "lr_finder.plot() # to inspect the loss-learning rate graph\n",
    "lr_finder.reset() # to reset the model and optimizer to their initial state"
   ],
   "id": "85bd6289c29dbf9f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.plot(range(10))\n",
    "plt.show()"
   ],
   "id": "42a61320bc86a6d8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Use Metadata from external Sources",
   "id": "f8b9345da6b22fd1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T20:52:44.805393Z",
     "start_time": "2025-07-15T20:52:42.364744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dataset.A2MD import get_tracks\n",
    "import polars as pl\n",
    "import json"
   ],
   "id": "d9f52ff40a3bd6bd",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T20:52:44.834964Z",
     "start_time": "2025-07-15T20:52:44.826833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_metadata(file: str):\n",
    "    with open(f\"../metadata/{file}.json\", \"r\") as f:\n",
    "        parsed = json.load(f)\n",
    "        if parsed[\"status\"][\"msg\"] != \"Success\":\n",
    "            return None, None, None, None, None\n",
    "        metadata = parsed[\"metadata\"][\"music\"]\n",
    "        first = metadata[0]\n",
    "\n",
    "        if \"spotify\" in first[\"external_metadata\"] and len(first[\"external_metadata\"][\"spotify\"][\"artists\"]) > 0:\n",
    "            artists = [artist[\"name\"] for artist in first[\"external_metadata\"][\"spotify\"][\"artists\"]]\n",
    "        elif \"deezer\" in first[\"external_metadata\"] and len(first[\"external_metadata\"][\"deezer\"][\"artists\"]) > 0:\n",
    "            artists = [artist[\"name\"] for artist in first[\"external_metadata\"][\"deezer\"][\"artists\"]]\n",
    "        elif len(first[\"artists\"]) > 0:\n",
    "            artists = [artist[\"name\"] for artist in first[\"artists\"]]\n",
    "        else:\n",
    "            print(\"No artists found for\", file)\n",
    "        genres = [genre[\"name\"] for genre in first[\"genres\"]] if \"genres\" in first else []\n",
    "        ytb_id = first[\"external_metadata\"][\"youtube\"][\"vid\"] if \"youtube\" in first[\"external_metadata\"] else None\n",
    "        title = first[\"title\"]\n",
    "        release_date = first[\"release_date\"] if \"release_date\" in first else None\n",
    "        return artists, genres, title, ytb_id, release_date\n",
    "\n",
    "get_metadata(\"dist0p00_00000_TRRORHF128E0786C6F\")"
   ],
   "id": "9e0313ece1a34a11",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Young Deenay'],\n",
       " ['Hip Hop', 'Pop'],\n",
       " 'Wanna Be Your Lover - Extended Mix',\n",
       " 'bT6kGVVReYI',\n",
       " '1998-06-02')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T20:52:48.540893Z",
     "start_time": "2025-07-15T20:52:48.490337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tracks = get_tracks(\"../data/a2md_public\")\n",
    "\n",
    "parsed_tracks = [tuple([folder, track]) for folder, track_list in tracks.items() for track in track_list]\n",
    "df = pl.DataFrame(parsed_tracks, schema=[\"folder\", \"identifier\"], orient=\"row\")"
   ],
   "id": "9ebe5bd7230c232c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T20:52:58.614614Z",
     "start_time": "2025-07-15T20:52:55.771417Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = (\n",
    "    df.lazy()\n",
    "    .with_columns(args=pl.concat_list(pl.col(\"folder\") ,pl.col(\"identifier\")).list.join(\"_\"))\n",
    "    .with_columns(pl.col(\"args\").map_elements(get_metadata, return_dtype=pl.Object))\n",
    "    .with_columns(\n",
    "        artists=pl.col(\"args\").map_elements(lambda x: x[0] if x else None, return_dtype=pl.List(pl.String)),\n",
    "        genres=pl.col(\"args\").map_elements(lambda x: x[1] if x else None, return_dtype=pl.List(pl.String)),\n",
    "        title=pl.col(\"args\").map_elements(lambda x: x[2] if x else None, return_dtype=pl.String),\n",
    "        ytb_id=pl.col(\"args\").map_elements(lambda x: x[3] if x else None, return_dtype=pl.String),\n",
    "        release_date=pl.col(\"args\").map_elements(lambda x: x[4] if x else None, return_dtype=pl.String).str.to_date(strict=False),\n",
    "    )\n",
    "    .drop(\"args\")\n",
    "    .collect()\n",
    ")"
   ],
   "id": "1fbf0af7b305732a",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T20:53:04.485342Z",
     "start_time": "2025-07-15T20:53:04.449768Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df.select(\"folder\", \"identifier\", \"genres\").explode(\"genres\").write_csv(\"../data/a2md_public/genres.csv\", include_header=True, separator=\",\")\n",
    "df.select(\"folder\", \"identifier\", \"artists\").explode(\"artists\").write_csv(\"../data/a2md_public/artists.csv\", include_header=True, separator=\",\")"
   ],
   "id": "352e940564121c06",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T17:02:55.883422Z",
     "start_time": "2025-07-28T17:02:55.847146Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_artists = df.select(pl.col(\"artists\").explode().str.to_lowercase()).unique().sort(\"artists\").to_series().to_list()\n",
    "df = (\n",
    "    df.lazy()\n",
    "    .explode(\"artists\")\n",
    "    .with_columns(\n",
    "        artist_id=pl.col(\"artists\").str.to_lowercase().map_elements(all_artists.index, return_dtype=pl.Int64).fill_null(0)\n",
    "    )\n",
    "    .group_by(\"folder\", \"identifier\")\n",
    "    .agg(\n",
    "        \"artists\",\n",
    "        \"artist_id\",\n",
    "        pl.col(\"title\").first(),\n",
    "        pl.col(\"ytb_id\").first(),\n",
    "        pl.col(\"release_date\").first(),\n",
    "        pl.col(\"genres\").first()\n",
    "    )\n",
    "    .collect()\n",
    ")\n",
    "max_id = len(all_artists)\n",
    "collabs = df.filter(pl.col(\"artist_id\").list.len() > 1).select(ids=\"artist_id\").unique().sort(\"ids\").to_series().to_list()\n",
    "flat_ids = sorted({iden for collab in collabs for iden in collab})\n",
    "groups = [collabs[0]]\n",
    "unfinished = collabs[1:]\n",
    "iterations_taken = 0\n",
    "while True:\n",
    "    for collab in unfinished:\n",
    "        for i, group in enumerate(groups):\n",
    "            group: list = group\n",
    "            if any([iden in group for iden in collab]):\n",
    "                groups[i] = list({*group, *collab})\n",
    "                break\n",
    "        else:\n",
    "            groups.append(collab)\n",
    "    if sum([len(group) for group in groups]) == len(flat_ids):\n",
    "        break\n",
    "    unfinished = groups[1:]\n",
    "    groups = [groups[0]]\n",
    "    iterations_taken += 1\n",
    "group_map = {iden: [iden in group for group in groups].index(True) + max_id for iden in flat_ids}\n",
    "identity = {i: i for i in range(max_id)}\n",
    "identity.update(group_map)\n",
    "group_map = identity\n",
    "\n",
    "df = (\n",
    "    df.lazy()\n",
    "    .explode(\"artist_id\")\n",
    "    .with_columns(group=pl.col(\"artist_id\").replace_strict(group_map))\n",
    "    .group_by(\"folder\", \"identifier\")\n",
    "    .agg(\n",
    "        pl.col(\"artists\").first(),\n",
    "        \"artist_id\",\n",
    "        \"group\",\n",
    "        pl.col(\"title\").first(),\n",
    "        pl.col(\"ytb_id\").first(),\n",
    "        pl.col(\"release_date\").first(),\n",
    "        pl.col(\"genres\").first()\n",
    "    )\n",
    "    .collect()\n",
    ")\n",
    "\n",
    "assert df.filter(pl.col(\"group\").list.len() > 1).select(pl.col(\"group\").list.unique()).select(pl.col(\"group\").list.len()).unique().select(pl.len())[0, 0] == 1, \"A song is in multiple groups\"\n",
    "\n",
    "df = df.with_columns(group=pl.col(\"group\").list.get(0))\n",
    "\n",
    "df.select(\"folder\", \"identifier\", \"group\").sort(\"identifier\").write_csv(\"../data/a2md_public/groups.csv\", include_header=True, separator=\",\")"
   ],
   "id": "ae0c352355aabd0a",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[44], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m all_artists \u001B[38;5;241m=\u001B[39m \u001B[43mdf\u001B[49m\u001B[38;5;241m.\u001B[39mselect(pl\u001B[38;5;241m.\u001B[39mcol(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124martists\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mexplode()\u001B[38;5;241m.\u001B[39mstr\u001B[38;5;241m.\u001B[39mto_lowercase())\u001B[38;5;241m.\u001B[39munique()\u001B[38;5;241m.\u001B[39msort(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124martists\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mto_series()\u001B[38;5;241m.\u001B[39mto_list()\n\u001B[1;32m      2\u001B[0m df \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m      3\u001B[0m     df\u001B[38;5;241m.\u001B[39mlazy()\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;241m.\u001B[39mexplode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124martists\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     17\u001B[0m     \u001B[38;5;241m.\u001B[39mcollect()\n\u001B[1;32m     18\u001B[0m )\n\u001B[1;32m     19\u001B[0m max_id \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(all_artists)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'df' is not defined"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T20:57:00.716458Z",
     "start_time": "2025-07-15T20:57:00.686515Z"
    }
   },
   "cell_type": "code",
   "source": "df.write_parquet(\"../data/a2md_public/metadata.parquet\", compression=\"gzip\", compression_level=9)",
   "id": "bf50ec29d935d662",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T20:57:49.097027Z",
     "start_time": "2025-07-15T20:57:49.093074Z"
    }
   },
   "cell_type": "code",
   "source": "df",
   "id": "db36ed238085bbac",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shape: (1_565, 9)\n",
       "\n",
       " folder    identifie  artists    artist_id    title      ytb_id     release_d  genres    \n",
       " ---       r          ---        ---           ---        ---        ate        ---       \n",
       " str       ---        list[str]  list[i64]     str        str        ---        list[str] \n",
       "           str                                                       date                 \n",
       "\n",
       " dist0p40  01281_TRU  [\"Depeche  [180]        Shout!     a4hwQKyT_  1983-01-0  [\"Rock\"]  \n",
       "           FCVS12903  Mode\"]                   (Live in   q0         1                    \n",
       "           C9E728                              Hammersmi                                  \n",
       "                                               th)                                        \n",
       " dist0p40  01012_TRB  [\"Bryan    [118]        Straight   ImCTOtOJy  2005-01-0  [\"Pop\",   \n",
       "           SXPE128F1  Adams\"]                  From The   i0         1          \"Rock\"]   \n",
       "           453DCE                              Heart                                      \n",
       " dist0p50  01432_TRM  [\"Little   [396]        Ridera'    Dpw95LkE9  2012-10-1  [\"Pop -   \n",
       "           KWQX128F4  Tony\"]                              Rc         2          Italo\"]   \n",
       "           251C93                                                                         \n",
       " dist0p40  01036_TRU  [\"Subsoni  [625]        Nuova Oss  WEOGrMVRD  2006-12-1  [\"Alterna \n",
       "           URXI128F1  ca\"]                     essione    Xk         1          tive\",    \n",
       "           494970                                                               \"Pop\"]    \n",
       " dist0p40  01149_TRD  [\"Rose     [559]        Car Wash   PkxaunLyb  2007-01-0  [\"Pop\",   \n",
       "           GCIZ128F1  Royce\"]                             uM         1          \"Rock\"]   \n",
       "           4640CE                                                                         \n",
       "                                                                                 \n",
       " dist0p30  00951_TRW  [\"Brooks   [115]        Little     kCmi7RAUD  2012-06-1  [\"Country \n",
       "           FHWK128F9  & Dunn\"]                 Miss       no         2          \"]        \n",
       "           305E83                              Honky                                      \n",
       "                                               Tonk                                       \n",
       " dist0p20  00300_TRM  [\"Michael  [445]        Haven't    1AJmKkU5P  2009-10-0  [\"Pop\"]   \n",
       "           RHAD12903  Bubl\"]                  Met You    OA         6                    \n",
       "           CC0130                              Yet                                        \n",
       " dist0p40  01293_TRW  [\"Sam &    [571]        I Thank    null       2018-10-1  [\"R & B\"] \n",
       "           MAAQ128EF  Dave\"]                   You                   9                    \n",
       "           344587                                                                         \n",
       " dist0p40  01257_TRR  [\"Blackst  [87]         Good       TEywd4I_j  1996-01-0  [\"Pop\"]   \n",
       "           RYBV128E0  reet\"]                   Lovin'     X0         1                    \n",
       "           793857                                                                         \n",
       " dist0p30  00682_TRB  [\"Britney  [114]        Oops!...   CduA0TULn  2013-05-2  [\"Pop\"]   \n",
       "           AUVN128F9  Spears\"]                 I Did It   ow         4                    \n",
       "           32FEF8                              Again                                      \n",
       ""
      ],
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_565, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>folder</th><th>identifier</th><th>artists</th><th>artist_id</th><th>group</th><th>title</th><th>ytb_id</th><th>release_date</th><th>genres</th></tr><tr><td>str</td><td>str</td><td>list[str]</td><td>list[i64]</td><td>i64</td><td>str</td><td>str</td><td>date</td><td>list[str]</td></tr></thead><tbody><tr><td>&quot;dist0p40&quot;</td><td>&quot;01281_TRUFCVS12903C9E728&quot;</td><td>[&quot;Depeche Mode&quot;]</td><td>[180]</td><td>785</td><td>&quot;Shout! (Live in Hammersmith)&quot;</td><td>&quot;a4hwQKyT_q0&quot;</td><td>1983-01-01</td><td>[&quot;Rock&quot;]</td></tr><tr><td>&quot;dist0p40&quot;</td><td>&quot;01012_TRBSXPE128F1453DCE&quot;</td><td>[&quot;Bryan Adams&quot;]</td><td>[118]</td><td>783</td><td>&quot;Straight From The Heart&quot;</td><td>&quot;ImCTOtOJyi0&quot;</td><td>2005-01-01</td><td>[&quot;Pop&quot;, &quot;Rock&quot;]</td></tr><tr><td>&quot;dist0p50&quot;</td><td>&quot;01432_TRMKWQX128F4251C93&quot;</td><td>[&quot;Little Tony&quot;]</td><td>[396]</td><td>396</td><td>&quot;Ridera&#x27;&quot;</td><td>&quot;Dpw95LkE9Rc&quot;</td><td>2012-10-12</td><td>[&quot;Pop - Italo&quot;]</td></tr><tr><td>&quot;dist0p40&quot;</td><td>&quot;01036_TRUURXI128F1494970&quot;</td><td>[&quot;Subsonica&quot;]</td><td>[625]</td><td>625</td><td>&quot;Nuova Ossessione&quot;</td><td>&quot;WEOGrMVRDXk&quot;</td><td>2006-12-11</td><td>[&quot;Alternative&quot;, &quot;Pop&quot;]</td></tr><tr><td>&quot;dist0p40&quot;</td><td>&quot;01149_TRDGCIZ128F14640CE&quot;</td><td>[&quot;Rose Royce&quot;]</td><td>[559]</td><td>559</td><td>&quot;Car Wash&quot;</td><td>&quot;PkxaunLybuM&quot;</td><td>2007-01-01</td><td>[&quot;Pop&quot;, &quot;Rock&quot;]</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;dist0p30&quot;</td><td>&quot;00951_TRWFHWK128F9305E83&quot;</td><td>[&quot;Brooks &amp; Dunn&quot;]</td><td>[115]</td><td>115</td><td>&quot;Little Miss Honky Tonk&quot;</td><td>&quot;kCmi7RAUDno&quot;</td><td>2012-06-12</td><td>[&quot;Country&quot;]</td></tr><tr><td>&quot;dist0p20&quot;</td><td>&quot;00300_TRMRHAD12903CC0130&quot;</td><td>[&quot;Michael Bubl&quot;]</td><td>[445]</td><td>445</td><td>&quot;Haven&#x27;t Met You Yet&quot;</td><td>&quot;1AJmKkU5POA&quot;</td><td>2009-10-06</td><td>[&quot;Pop&quot;]</td></tr><tr><td>&quot;dist0p40&quot;</td><td>&quot;01293_TRWMAAQ128EF344587&quot;</td><td>[&quot;Sam &amp; Dave&quot;]</td><td>[571]</td><td>571</td><td>&quot;I Thank You&quot;</td><td>null</td><td>2018-10-19</td><td>[&quot;R &amp; B&quot;]</td></tr><tr><td>&quot;dist0p40&quot;</td><td>&quot;01257_TRRRYBV128E0793857&quot;</td><td>[&quot;Blackstreet&quot;]</td><td>[87]</td><td>87</td><td>&quot;Good Lovin&#x27;&quot;</td><td>&quot;TEywd4I_jX0&quot;</td><td>1996-01-01</td><td>[&quot;Pop&quot;]</td></tr><tr><td>&quot;dist0p30&quot;</td><td>&quot;00682_TRBAUVN128F932FEF8&quot;</td><td>[&quot;Britney Spears&quot;]</td><td>[114]</td><td>114</td><td>&quot;Oops!... I Did It Again&quot;</td><td>&quot;CduA0TULnow&quot;</td><td>2013-05-24</td><td>[&quot;Pop&quot;]</td></tr></tbody></table></div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Inspect A2MD Splits",
   "id": "a1943b05b85aa6a1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T22:37:23.206317Z",
     "start_time": "2025-07-28T22:37:23.202470Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dataset.A2MD import get_splits, get_annotation\n",
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "from dataset.mapping import DrumMapping\n",
    "from itertools import combinations\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np"
   ],
   "id": "adbaabed24b6a801",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T22:08:57.541387Z",
     "start_time": "2025-07-28T22:08:57.510822Z"
    }
   },
   "cell_type": "code",
   "source": "groups = pl.read_csv(\"../data/a2md_public/groups.csv\", separator=\",\", has_header=True).with_columns(group=pl.col(\"group\").cast(pl.Int64))",
   "id": "ff9f0463a849cfeb",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T22:12:29.714133Z",
     "start_time": "2025-07-28T22:09:10.993471Z"
    }
   },
   "cell_type": "code",
   "source": [
    "identifiers = groups.select(\"folder\", \"identifier\").unique().sort(\"identifier\").to_dict()\n",
    "annotations = {\n",
    "    identifier: get_annotation(\"../data/a2md_public\", folder, identifier, DrumMapping.THREE_CLASS) for folder, identifier in zip(identifiers[\"folder\"], identifiers[\"identifier\"])\n",
    "}\n",
    "class_names = [DrumMapping.THREE_CLASS.get_name(i) for i in range(len(DrumMapping.THREE_CLASS))]\n",
    "annotations = [(identifier, *[len(ann) for ann in annotation[1]], *[len(ann) for ann in annotation[2]]) for identifier, annotation in annotations.items() if annotation is not None]\n",
    "annotations = pl.DataFrame(annotations, schema=[\"identifier\", *class_names, \"down_beat\", \"beat\"], orient=\"row\")"
   ],
   "id": "b42fc56ab3483bf1",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "possible_seeds = sorted(set([get_splits(\"S\",  [0.8, 0.2, 0.], \"../data/a2md_public\", seed=seed, return_seed=True)[1] for seed in range(1000)]))",
   "id": "cd394d3ed8282b0f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "splits = {seed: get_splits(\"S\", [0.8, 0.2, 0.], \"../data/a2md_public\", seed=seed, return_seed=False) for seed in possible_seeds}",
   "id": "e2f19c34386681d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T16:22:11.130732Z",
     "start_time": "2025-07-28T16:22:11.127224Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 3,
   "source": [
    "def get_group(identifier: str, _groups: pl.DataFrame) -> int:\n",
    "    group = _groups.lazy().filter(pl.col(\"identifier\") == identifier).select(\"group\").collect().to_series().to_list()\n",
    "    if len(group) == 0:\n",
    "        return -1\n",
    "    return group[0]"
   ],
   "id": "e8b3627ef666dd2f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T14:04:12.854644Z",
     "start_time": "2025-07-24T14:04:12.800995Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 23,
   "source": [
    "flat_splits = [(seed, folder, identifier, \"train\") for seed in possible_seeds for folder, idens in splits[seed][0].items() for identifier in idens] + \\\n",
    "              [(seed, folder, identifier, \"val\") for seed in possible_seeds for folder, idens in splits[seed][1].items() for identifier in idens] + \\\n",
    "              [(seed, folder, identifier, \"test\") for seed in possible_seeds for folder, idens in splits[seed][2].items() for identifier in idens]\n",
    "flat_splits = pl.DataFrame(flat_splits, schema=[\"seed\", \"folder\", \"identifier\", \"split\"], orient=\"row\")\n",
    "flat_splits = flat_splits.join(groups, on=(\"folder\", \"identifier\"), how=\"inner\", validate=\"m:1\")"
   ],
   "id": "9bdab56b16bd2db2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T18:29:21.598235Z",
     "start_time": "2025-07-24T18:29:21.589987Z"
    }
   },
   "cell_type": "code",
   "source": "flat_splits = flat_splits.join(annotations, on=\"identifier\", how=\"inner\", validate=\"m:1\")",
   "id": "60c568d3900af322",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T19:08:27.869236Z",
     "start_time": "2025-07-24T19:08:27.840461Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ratios = flat_splits.group_by(\"seed\", \"split\").agg(\n",
    "    pl.col(*class_names).sum(),\n",
    ").with_columns(\n",
    "    total=pl.sum_horizontal(*class_names)\n",
    ").with_columns(\n",
    "    (pl.col(*class_names) / pl.col(\"total\") * 100)\n",
    ").sort(\"seed\", \"split\")"
   ],
   "id": "cb49e0b56739577d",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T21:43:36.977457Z",
     "start_time": "2025-07-24T21:43:36.969299Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ratios.group_by(\"seed\").agg(\n",
    "    pl.col(class_names).std()\n",
    ")"
   ],
   "id": "22474587382a21a2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shape: (179, 4)\n",
       "\n",
       " seed  BD        SD        HH       \n",
       " ---   ---       ---       ---      \n",
       " i64   f64       f64       f64      \n",
       "\n",
       " 9     1.649048  0.345792  1.99484  \n",
       " 12    0.807109  1.968988  1.161879 \n",
       " 21    1.645274  0.990823  0.654451 \n",
       " 23    3.928319  0.173146  3.755173 \n",
       " 26    1.013447  0.581445  1.594892 \n",
       "                                \n",
       " 975   1.81161   3.033956  1.222346 \n",
       " 982   1.245749  0.675034  0.570715 \n",
       " 989   1.375396  0.259135  1.116261 \n",
       " 995   0.245936  1.706094  1.952029 \n",
       " 1006  1.629513  1.107687  2.737201 \n",
       ""
      ],
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (179, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>seed</th><th>BD</th><th>SD</th><th>HH</th></tr><tr><td>i64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>9</td><td>1.649048</td><td>0.345792</td><td>1.99484</td></tr><tr><td>12</td><td>0.807109</td><td>1.968988</td><td>1.161879</td></tr><tr><td>21</td><td>1.645274</td><td>0.990823</td><td>0.654451</td></tr><tr><td>23</td><td>3.928319</td><td>0.173146</td><td>3.755173</td></tr><tr><td>26</td><td>1.013447</td><td>0.581445</td><td>1.594892</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>975</td><td>1.81161</td><td>3.033956</td><td>1.222346</td></tr><tr><td>982</td><td>1.245749</td><td>0.675034</td><td>0.570715</td></tr><tr><td>989</td><td>1.375396</td><td>0.259135</td><td>1.116261</td></tr><tr><td>995</td><td>0.245936</td><td>1.706094</td><td>1.952029</td></tr><tr><td>1006</td><td>1.629513</td><td>1.107687</td><td>2.737201</td></tr></tbody></table></div>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 142
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T21:45:10.751142Z",
     "start_time": "2025-07-24T21:45:08.329648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "seeded_groups = flat_splits.group_by(\"seed\", \"split\").agg(\n",
    "    pl.col(\"group\")\n",
    ").filter(\n",
    "    pl.col(\"split\") == \"val\"\n",
    ").select(\n",
    "    \"seed\", \"group\"\n",
    ").to_dict(as_series=False)\n",
    "seeded_groups = zip(seeded_groups[\"seed\"], seeded_groups[\"group\"])\n",
    "overlap_count = []\n",
    "current_min = 99999999\n",
    "for combination in combinations(seeded_groups, 3):\n",
    "    overlapping = len(set([iden for seed, group in combination for iden in group]))\n",
    "    current_min = min(current_min, overlapping)\n",
    "    if overlapping < current_min * 1.05:\n",
    "        overlap_count.append((*(list(zip(*combination))[0]), overlapping))"
   ],
   "id": "e704f08aa52175bb",
   "outputs": [],
   "execution_count": 144
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T19:50:26.781254Z",
     "start_time": "2025-07-24T19:50:26.773186Z"
    }
   },
   "cell_type": "code",
   "source": "np.argpartition(np.array(overlap_count)[:, -1], -10)[-10:]",
   "id": "6c6347737605d87a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2, 14,  3,  7, 16,  8, 10, 11, 15,  0])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 106
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T21:45:13.957485Z",
     "start_time": "2025-07-24T21:45:13.952950Z"
    }
   },
   "cell_type": "code",
   "source": "np.array(overlap_count)",
   "id": "1d816395c9378ca5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[184, 952, 210,  64],\n",
       "       [184, 952, 884,  64],\n",
       "       [184, 952,  82,  67],\n",
       "       [184, 952, 493,  67],\n",
       "       [184, 952, 536,  67],\n",
       "       [184, 952,  49,  66],\n",
       "       [184, 952, 564,  66],\n",
       "       [184, 952, 982,  62],\n",
       "       [184, 952, 695,  65],\n",
       "       [184, 952, 758,  65],\n",
       "       [184, 952, 906,  65],\n",
       "       [184, 952, 638,  65],\n",
       "       [184, 952, 961,  63],\n",
       "       [184, 952, 911,  64],\n",
       "       [184, 952, 879,  65],\n",
       "       [184, 952, 490,  65],\n",
       "       [184, 952, 450,  63],\n",
       "       [184, 952, 577,  65],\n",
       "       [184, 952, 215,  63],\n",
       "       [184, 952, 561,  65],\n",
       "       [184, 952, 355,  64],\n",
       "       [184, 952, 684,  64],\n",
       "       [184, 952, 900,  65],\n",
       "       [184, 952, 989,  65],\n",
       "       [184, 952, 121,  65],\n",
       "       [184, 952, 737,  62],\n",
       "       [184, 952, 623,  65],\n",
       "       [184, 952, 460,  64],\n",
       "       [184, 952, 614,  65],\n",
       "       [184, 952,  60,  64],\n",
       "       [184, 952, 252,  64],\n",
       "       [184, 952, 662,  61],\n",
       "       [184, 952, 939,  64],\n",
       "       [184, 952, 605,  64],\n",
       "       [184, 952, 934,  64],\n",
       "       [184, 952,  89,  62],\n",
       "       [184, 952, 432,  64],\n",
       "       [184, 952,  84,  63],\n",
       "       [184, 952,  21,  63],\n",
       "       [184, 952, 588,  64],\n",
       "       [184, 952, 606,  63],\n",
       "       [184, 952, 217,  63],\n",
       "       [184, 952, 958,  63],\n",
       "       [184, 952, 736,  60],\n",
       "       [184, 952, 452,  62],\n",
       "       [184, 884, 450,  62],\n",
       "       [184, 884, 215,  62],\n",
       "       [184, 884, 724,  62],\n",
       "       [184,  82, 510,  62],\n",
       "       [184, 536, 354,  62],\n",
       "       [184,  49, 311,  61],\n",
       "       [184, 287, 662,  62],\n",
       "       [184, 982, 911,  62],\n",
       "       [184, 982, 606,  62],\n",
       "       [184, 982, 868,  62],\n",
       "       [184, 982, 361,  62],\n",
       "       [184, 354, 963,  62],\n",
       "       [184, 354, 911,  62],\n",
       "       [184, 354, 450,  61],\n",
       "       [184, 354,  60,  62],\n",
       "       [184, 354, 713,  62],\n",
       "       [184, 354, 252,  62],\n",
       "       [184, 354, 662,  61],\n",
       "       [184, 354, 948,  62],\n",
       "       [184, 354,  21,  62],\n",
       "       [184, 354, 736,  62],\n",
       "       [184, 354, 136,  62],\n",
       "       [184, 354, 510,  62],\n",
       "       [184, 354, 330,  62],\n",
       "       [184, 354, 548,  59],\n",
       "       [184, 354, 741,  61],\n",
       "       [184, 771, 450,  61],\n",
       "       [184, 771,  21,  61],\n",
       "       [184, 638, 450,  61],\n",
       "       [184, 638, 623,  60],\n",
       "       [184, 638, 605,  61],\n",
       "       [184, 638, 588,  60],\n",
       "       [184, 911, 510,  61],\n",
       "       [184, 241, 450,  61],\n",
       "       [184, 241,  21,  61],\n",
       "       [184, 450, 215,  60],\n",
       "       [184, 450, 355,  61],\n",
       "       [184, 450, 655,  60],\n",
       "       [184, 450, 614,  60],\n",
       "       [184, 450, 662,  58],\n",
       "       [184, 450,  30,  60],\n",
       "       [184, 655, 662,  60],\n",
       "       [184, 623, 662,  60],\n",
       "       [184, 662,  21,  60],\n",
       "       [184, 662, 789,  59],\n",
       "       [184, 662, 510,  60],\n",
       "       [184, 662, 330,  60],\n",
       "       [184,  21, 736,  60],\n",
       "       [184, 958, 510,  60],\n",
       "       [952, 210, 217,  60],\n",
       "       [952, 210, 974,  60],\n",
       "       [952, 210, 531,  60],\n",
       "       [952, 884, 134,  60],\n",
       "       [952, 536, 217,  59],\n",
       "       [952, 982, 934,  60],\n",
       "       [952, 982, 606,  60],\n",
       "       [952, 982, 217,  60],\n",
       "       [952, 695, 121,  59],\n",
       "       [952, 695, 217,  60],\n",
       "       [952, 695, 646,  60],\n",
       "       [952, 963, 217,  59],\n",
       "       [952, 963, 134,  59],\n",
       "       [952, 481, 101,  59],\n",
       "       [952, 481, 289,  60],\n",
       "       [952, 514, 217,  60],\n",
       "       [952, 514,  23,  60],\n",
       "       [952, 758, 737,  60],\n",
       "       [952, 961, 531,  60],\n",
       "       [952,  99, 989,  58],\n",
       "       [952, 739, 989,  60],\n",
       "       [952, 739, 217,  60],\n",
       "       [952, 561, 217,  59],\n",
       "       [952, 355, 217,  59],\n",
       "       [952, 873, 217,  60],\n",
       "       [952, 684, 101,  60],\n",
       "       [952, 900, 134,  60],\n",
       "       [952, 900, 320,  60],\n",
       "       [952, 989, 217,  58],\n",
       "       [952, 655, 665,  60],\n",
       "       [952, 655, 974,  60],\n",
       "       [952, 737,  89,  59],\n",
       "       [952, 960, 217,  60],\n",
       "       [952,  60, 217,  57],\n",
       "       [952, 252, 134,  59],\n",
       "       [952, 327, 217,  59],\n",
       "       [952,  89,  84,  59],\n",
       "       [952,  89, 217,  59],\n",
       "       [952,  89,  23,  58],\n",
       "       [952,  84, 217,  58],\n",
       "       [952, 606, 217,  58],\n",
       "       [952, 217, 958,  59],\n",
       "       [952, 217, 736,  57],\n",
       "       [952, 217, 134,  55],\n",
       "       [493, 655, 974,  57],\n",
       "       [536, 213, 548,  57],\n",
       "       [695,   9, 646,  57],\n",
       "       [695,  61, 646,  56],\n",
       "       [354, 524, 391,  57],\n",
       "       [354, 213, 548,  57],\n",
       "       [822, 327, 622,  57],\n",
       "       [481, 101, 289,  56],\n",
       "       [975, 584, 960,  57],\n",
       "       [771,  35, 237,  56],\n",
       "       [299, 655, 665,  57],\n",
       "       [ 99, 655, 665,  57],\n",
       "       [823,  61, 646,  57],\n",
       "       [241, 605, 646,  57],\n",
       "       [241,  61, 646,  56],\n",
       "       [241, 389, 724,  57],\n",
       "       [575, 873, 933,  57],\n",
       "       [371, 855, 214,  57],\n",
       "       [215, 355, 510,  57],\n",
       "       [215, 432, 719,  56],\n",
       "       [215, 958, 510,  57],\n",
       "       [561, 958, 510,  57],\n",
       "       [355, 958, 510,  57],\n",
       "       [873, 161,  26,  55],\n",
       "       [873, 213, 373,  57],\n",
       "       [161, 560, 548,  57],\n",
       "       [161, 461,  26,  56],\n",
       "       [161,  26, 566,  56],\n",
       "       [605,  61, 646,  56],\n",
       "       [858, 855, 933,  57],\n",
       "       [213, 560, 548,  57],\n",
       "       [560, 824, 193,  56],\n",
       "       [ 61, 719, 646,  57],\n",
       "       [136, 548, 509,  57],\n",
       "       [ 35, 193, 781,  57]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 145
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create K-Fold Splits",
   "id": "deb8691f6c22eb97"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T22:37:27.586880Z",
     "start_time": "2025-07-28T22:37:27.581780Z"
    }
   },
   "cell_type": "code",
   "source": "group_ids = np.array(groups.select(\"group\").unique().sort(\"group\").to_series().to_list())",
   "id": "c3a10441ea153e4d",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T22:13:45.693079Z",
     "start_time": "2025-07-28T22:13:45.689192Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def count_folders(_groups: pl.DataFrame, group_ids: list[int]) -> dict[int, int]:\n",
    "    folders = _groups.lazy().select(\"folder\").unique().sort(\"folder\").collect().to_series().to_list()\n",
    "    folder_counts = {folder: 0 for folder in folders}\n",
    "    for folder in folders:\n",
    "        folder_counts[folder] = _groups.lazy().filter(pl.col(\"folder\") == folder).filter(pl.col(\"group\").is_in(group_ids)).select(pl.len()).collect().to_series().to_list()[0]\n",
    "    return folder_counts"
   ],
   "id": "a77e2740fbae74d4",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T23:39:04.665736Z",
     "start_time": "2025-07-28T23:17:15.839510Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_folds = 10\n",
    "\n",
    "folder_dist = [(seed, fold, *list(count_folders(groups, group_ids[val]).values())) for seed in range(10000) for fold, (train, val) in enumerate(KFold(n_splits=n_folds, shuffle=True, random_state=seed).split(group_ids))]\n",
    "folder_dist = pl.DataFrame(folder_dist, schema=[\"seed\", \"fold\", *groups.select(\"folder\").unique().sort(\"folder\").to_series().to_list()], orient=\"row\")"
   ],
   "id": "c2aa1cf74b686e1",
   "outputs": [],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T23:39:04.734280Z",
     "start_time": "2025-07-28T23:39:04.716166Z"
    }
   },
   "cell_type": "code",
   "source": [
    "window_to_consider = 100\n",
    "folder_deviance = (\n",
    "    folder_dist.lazy()\n",
    "    .group_by(\"seed\")\n",
    "    .agg(\n",
    "        cs.starts_with(\"dist\").std(),\n",
    "    ).select(\n",
    "        \"seed\",\n",
    "        mean_folder_deviance=pl.mean_horizontal(cs.starts_with(\"dist\"))\n",
    "    ).sort(\"mean_folder_deviance\")\n",
    "    .head(window_to_consider)\n",
    "    .with_row_index(\"folder_rank\")\n",
    "    .collect()\n",
    ")\n",
    "selected_seeds = folder_deviance.select(\"seed\").to_series().to_list()"
   ],
   "id": "7574e38e6ef2374e",
   "outputs": [],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T23:39:04.782572Z",
     "start_time": "2025-07-28T23:39:04.777033Z"
    }
   },
   "cell_type": "code",
   "source": "folder_deviance",
   "id": "4e39278c32f0d063",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shape: (100, 3)\n",
       "\n",
       " folder_rank  seed  mean_folder_deviance \n",
       " ---          ---   ---                  \n",
       " u32          i64   f64                  \n",
       "\n",
       " 0            7301  3.272586             \n",
       " 1            9777  3.522954             \n",
       " 2            4616  3.588141             \n",
       " 3            2515  3.626523             \n",
       " 4            3995  3.679613             \n",
       "                                      \n",
       " 95           6532  4.023204             \n",
       " 96           1631  4.023393             \n",
       " 97           662   4.025235             \n",
       " 98           9022  4.025997             \n",
       " 99           4124  4.026027             \n",
       ""
      ],
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (100, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>folder_rank</th><th>seed</th><th>mean_folder_deviance</th></tr><tr><td>u32</td><td>i64</td><td>f64</td></tr></thead><tbody><tr><td>0</td><td>7301</td><td>3.272586</td></tr><tr><td>1</td><td>9777</td><td>3.522954</td></tr><tr><td>2</td><td>4616</td><td>3.588141</td></tr><tr><td>3</td><td>2515</td><td>3.626523</td></tr><tr><td>4</td><td>3995</td><td>3.679613</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>95</td><td>6532</td><td>4.023204</td></tr><tr><td>96</td><td>1631</td><td>4.023393</td></tr><tr><td>97</td><td>662</td><td>4.025235</td></tr><tr><td>98</td><td>9022</td><td>4.025997</td></tr><tr><td>99</td><td>4124</td><td>4.026027</td></tr></tbody></table></div>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T23:39:05.030398Z",
     "start_time": "2025-07-28T23:39:04.898316Z"
    }
   },
   "cell_type": "code",
   "source": [
    "top_splits = [(seed, fold, list(group_ids[list(val)])) for seed in selected_seeds for fold, (train, val) in enumerate(KFold(n_splits=n_folds, shuffle=True, random_state=seed).split(group_ids))]\n",
    "top_splits = pl.DataFrame(top_splits, schema=[\"seed\", \"fold\", \"groups\"], orient=\"row\").explode(\"groups\").rename({\"groups\": \"group\"})\n",
    "top_splits = top_splits.join(groups, on=\"group\", how=\"right\").sort(\"seed\", \"fold\", \"group\")\n",
    "top_splits = top_splits.join(annotations, on=\"identifier\", how=\"inner\", validate=\"m:1\")"
   ],
   "id": "7bb2c53e87d0747",
   "outputs": [],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T23:39:05.077820Z",
     "start_time": "2025-07-28T23:39:05.068371Z"
    }
   },
   "cell_type": "code",
   "source": [
    "selected_groups = top_splits.select(\"group\").unique().to_series().to_list()\n",
    "set(selected_groups) ^ set(group_ids)"
   ],
   "id": "b4f7f4d2af4105dd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{50, 162}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 84
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T23:39:05.177721Z",
     "start_time": "2025-07-28T23:39:05.152338Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class_deviance =(\n",
    "    top_splits.lazy()\n",
    "    .group_by(\"seed\", \"fold\")\n",
    "    .agg(\n",
    "        pl.col(*class_names).sum(),\n",
    "    ).with_columns(\n",
    "        total=pl.sum_horizontal(*class_names)\n",
    "    ).with_columns(\n",
    "        (pl.col(*class_names) / pl.col(\"total\") * 100)\n",
    "    ).group_by(\"seed\").agg(\n",
    "        pl.col(*class_names).std(),\n",
    "    ).select(\n",
    "        \"seed\",\n",
    "    mean_class_deviance=pl.mean_horizontal(*class_names)\n",
    "    ).sort(\"mean_class_deviance\")\n",
    "    .with_row_index(\"class_rank\")\n",
    "    .collect()\n",
    " )\n",
    "class_deviance"
   ],
   "id": "2af98b07f34f112f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shape: (100, 3)\n",
       "\n",
       " class_rank  seed  mean_class_deviance \n",
       " ---         ---   ---                 \n",
       " u32         i64   f64                 \n",
       "\n",
       " 0           6276  0.746895            \n",
       " 1           541   0.863384            \n",
       " 2           5881  0.930949            \n",
       " 3           546   0.959446            \n",
       " 4           4732  1.012635            \n",
       "                                    \n",
       " 95          356   1.846893            \n",
       " 96          6928  1.962526            \n",
       " 97          4665  1.987367            \n",
       " 98          7301  2.001316            \n",
       " 99          2225  2.04173             \n",
       ""
      ],
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (100, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>class_rank</th><th>seed</th><th>mean_class_deviance</th></tr><tr><td>u32</td><td>i64</td><td>f64</td></tr></thead><tbody><tr><td>0</td><td>6276</td><td>0.746895</td></tr><tr><td>1</td><td>541</td><td>0.863384</td></tr><tr><td>2</td><td>5881</td><td>0.930949</td></tr><tr><td>3</td><td>546</td><td>0.959446</td></tr><tr><td>4</td><td>4732</td><td>1.012635</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>95</td><td>356</td><td>1.846893</td></tr><tr><td>96</td><td>6928</td><td>1.962526</td></tr><tr><td>97</td><td>4665</td><td>1.987367</td></tr><tr><td>98</td><td>7301</td><td>2.001316</td></tr><tr><td>99</td><td>2225</td><td>2.04173</td></tr></tbody></table></div>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T23:39:05.308910Z",
     "start_time": "2025-07-28T23:39:05.301454Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ranking = class_deviance.join(folder_deviance, on=\"seed\", how=\"inner\").with_columns(\n",
    "    rank=pl.col(\"class_rank\") + pl.col(\"folder_rank\")\n",
    ").sort(\"rank\")\n",
    "ranking"
   ],
   "id": "e8e1242812d64d57",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shape: (100, 6)\n",
       "\n",
       " class_rank  seed  mean_class_deviance  folder_rank  mean_folder_deviance  rank \n",
       " ---         ---   ---                  ---          ---                   ---  \n",
       " u32         i64   f64                  u32          f64                   u32  \n",
       "\n",
       " 9           3272  1.084436             6            3.708909              15   \n",
       " 17          9777  1.136417             1            3.522954              18   \n",
       " 0           6276  0.746895             19           3.811847              19   \n",
       " 12          8364  1.102338             8            3.732766              20   \n",
       " 15          956   1.110946             10           3.739863              25   \n",
       "                                                                          \n",
       " 82          8383  1.633806             85           4.010891              167  \n",
       " 99          2225  2.04173              69           3.98774               168  \n",
       " 71          4124  1.555989             99           4.026027              170  \n",
       " 90          9569  1.74683              93           4.018202              183  \n",
       " 95          356   1.846893             92           4.018178              187  \n",
       ""
      ],
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (100, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>class_rank</th><th>seed</th><th>mean_class_deviance</th><th>folder_rank</th><th>mean_folder_deviance</th><th>rank</th></tr><tr><td>u32</td><td>i64</td><td>f64</td><td>u32</td><td>f64</td><td>u32</td></tr></thead><tbody><tr><td>9</td><td>3272</td><td>1.084436</td><td>6</td><td>3.708909</td><td>15</td></tr><tr><td>17</td><td>9777</td><td>1.136417</td><td>1</td><td>3.522954</td><td>18</td></tr><tr><td>0</td><td>6276</td><td>0.746895</td><td>19</td><td>3.811847</td><td>19</td></tr><tr><td>12</td><td>8364</td><td>1.102338</td><td>8</td><td>3.732766</td><td>20</td></tr><tr><td>15</td><td>956</td><td>1.110946</td><td>10</td><td>3.739863</td><td>25</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>82</td><td>8383</td><td>1.633806</td><td>85</td><td>4.010891</td><td>167</td></tr><tr><td>99</td><td>2225</td><td>2.04173</td><td>69</td><td>3.98774</td><td>168</td></tr><tr><td>71</td><td>4124</td><td>1.555989</td><td>99</td><td>4.026027</td><td>170</td></tr><tr><td>90</td><td>9569</td><td>1.74683</td><td>93</td><td>4.018202</td><td>183</td></tr><tr><td>95</td><td>356</td><td>1.846893</td><td>92</td><td>4.018178</td><td>187</td></tr></tbody></table></div>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T23:39:05.482067Z",
     "start_time": "2025-07-28T23:39:05.478216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# final_seeds = [4785, 8957, 635] # 3 folds\n",
    "# final_seeds = [7194, 1118, 758] # 5 folds\n",
    "# final_seeds = [3272, 9777, 6276] # 10 folds\n",
    "final_seeds = ranking.select(\"seed\").to_series().to_list()[:3]"
   ],
   "id": "8765d3fe9a5ab01",
   "outputs": [],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T23:39:05.847638Z",
     "start_time": "2025-07-28T23:39:05.731002Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i, seed in enumerate(final_seeds):\n",
    "    top_splits.filter(pl.col(\"seed\") == seed).select(\"folder\", \"identifier\", \"fold\").sort(\"fold\", \"identifier\").write_csv(f\"../data/a2md_public/splits_{n_folds}-folds_{i}.csv\", include_header=True, separator=\",\")"
   ],
   "id": "9ba21cd4592923ae",
   "outputs": [],
   "execution_count": 88
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a9f6da59590f4b6b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
