{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "from tbparse import SummaryReader\n",
    "import os"
   ],
   "id": "b020a8d47540e269"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from settings import TrainingSettings, DatasetSettings, EvaluationSettings, CNNSettings, CNNMambaSettings, CNNAttentionSettings, CRNNSettings, asdict\n",
    "\n",
    "def get_columns_with_type(typ, get_only_model_settings=False) -> list[str]:\n",
    "    out = []\n",
    "    if not get_only_model_settings:\n",
    "        classes = [TrainingSettings, DatasetSettings, EvaluationSettings]\n",
    "        for cls in classes:\n",
    "            settings = cls()\n",
    "            dic = asdict(settings)\n",
    "            for name, value in dic.items():\n",
    "                if type(value) is typ:\n",
    "                    out.append(name)\n",
    "    classes = [CNNSettings, CNNAttentionSettings, CNNMambaSettings, CRNNSettings]\n",
    "    for cls in classes:\n",
    "        settings = cls(3, 84)\n",
    "        dic = asdict(settings)\n",
    "        for name, value in dic.items():\n",
    "            if type(value) is typ:\n",
    "                out.append(name)\n",
    "    return list(set(out))"
   ],
   "id": "33457be80aff0561"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "integer_values = list(set(get_columns_with_type(int) + [\"early_stopping\"]))\n",
    "boolean_values = get_columns_with_type(bool)\n",
    "float_values = get_columns_with_type(float)\n",
    "string_values = get_columns_with_type(str) + [\"dir_name\"]\n",
    "# string_values.remove(\"backbone\")\n",
    "integer_values.remove(\"dropout\")"
   ],
   "id": "abb40ad4fea3ef24"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "integer_values",
   "id": "3186bdafe166ae00"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Convert hyperparameters and per step scalars",
   "id": "f8c0ed05ec4c0364"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "pl.config.Config.restore_defaults()",
   "id": "a89a8ce343207451"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "log_dir = \"runs/CRNN/Vogl/Validation\"\n",
    "output_dir = \"processed/CRNN/Vogl/Validation\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "logs = SummaryReader(log_dir, pivot=True, extra_columns={'dir_name'})"
   ],
   "id": "417c21c9e0ad0181"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# convert types\n",
    "params = logs.hparams\n",
    "params = params.loc[:,~params.columns.duplicated()].copy()\n",
    "params[params == \"None\"] = None\n",
    "int_cols = list(set(integer_values) & set(params.columns.values))\n",
    "params[int_cols] = params[int_cols].astype(pd.Int64Dtype(), errors=\"ignore\")\n",
    "bool_cols = list(set(boolean_values) & set(params.columns.values))\n",
    "params[bool_cols] = params[bool_cols].astype(bool)\n",
    "float_cols = list(set(float_values) & set(params.columns.values))\n",
    "params[float_cols] = params[float_cols].astype(np.float64)\n",
    "string_cols = list(set(string_values) & set(params.columns.values))\n",
    "params[string_cols] = params[string_cols].astype(pd.StringDtype())\n",
    "params = pd.DataFrame(params)"
   ],
   "id": "56623deb3e2ecc51"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "scalars = logs.scalars\n",
    "# broken_columns = [\"F-Score/Avg/Test/RBMA\", \"F-Score/Sum/Test/RBMA\", \"Loss/Test/RBMA\"]\n",
    "# for col in broken_columns:\n",
    "#     scalars = scalars[scalars[col].apply(lambda x: isinstance(x, float))].copy(deep=True)\n",
    "# scalars[broken_columns] = scalars[broken_columns].astype(np.float64)\n",
    "scalars.drop_duplicates(subset=[\"dir_name\", \"step\"], keep=False, inplace=True)"
   ],
   "id": "5e160577222acba6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "logs.tensors",
   "id": "3042412e2c0cd1b5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "params = pl.from_pandas(params, nan_to_null=True)",
   "id": "e6960d5a86432103"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "scores = pl.from_pandas(scalars, nan_to_null=True)",
   "id": "625fb94cc7c4a2ed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "hparams = params.join(scores.select(pl.col(\"F-Score\", \"dir_name\")), on='dir_name', how='inner')\n",
    "hparams = hparams.select(pl.all().exclude(\"dir_name\"), pl.col(\"dir_name\").str.split(\"/\").list.first())"
   ],
   "id": "7c4dbe2d6087896"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# convert time\n",
    "hparams = hparams.with_columns(pl.col(\"dir_name\").str.split(\"_\").list.slice(0, 2).list.join(\"_\").str.to_datetime(\"%b%d_%H-%M-%S\", strict=False, ambiguous=\"earliest\").alias(\"start_time\"))\n",
    "hparams = hparams.with_columns(pl.datetime(2025, pl.col(\"start_time\").dt.month(), pl.col(\"start_time\").dt.day(), pl.col(\"start_time\").dt.hour(), pl.col(\"start_time\").dt.minute(), pl.col(\"start_time\").dt.second(), time_unit=\"ns\").alias(\"start_time\"))"
   ],
   "id": "5c6be2da9d782092"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "scalars",
   "id": "7f770e23ee6ee41d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "hparams.write_parquet(f\"{output_dir}/hparams.parquet\")\n",
    "scores.write_parquet(f\"{output_dir}/scores.parquet\")"
   ],
   "id": "418b26c2db8fa635"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Process plots",
   "id": "609f6e80a2fa953b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "logs_no_pivot = SummaryReader(log_dir, pivot=False, extra_columns={'dir_name'})",
   "id": "da5b1a6d12f95d7d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Convert raw tensor data\n",
    "tensors = logs_no_pivot.tensors\n",
    "columns = tensors[\"tag\"].unique().astype(str)\n",
    "columns = columns[~np.char.endswith(columns, \"Best_Thresholds\")]\n",
    "tensor_shapes = np.array(tensors.loc[tensors[\"tag\"] == columns[0]].iloc[0][\"value\"].shape)\n",
    "tensors[\"value\"] = tensors[\"value\"].apply(lambda x: x.flatten())"
   ],
   "id": "98585eae45c980fb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "tensors = pl.from_pandas(tensors, nan_to_null=True, schema_overrides={\"tag\": pl.String, \"dir_name\": pl.String}, include_index=True)\n",
    "tensors = tensors.filter(pl.col(\"tag\").is_in(columns))\n",
    "num_rows = tensors.select(pl.len()).to_series()[0]\n",
    "tensors = tensors.with_columns(pl.col(\"value\").reshape(tuple([num_rows, *tensor_shapes])).alias(\"value\"))"
   ],
   "id": "103de629e795f575"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "tensors = tensors.unique(subset=[\"dir_name\", \"step\", \"tag\"], keep=\"none\")\n",
    "tensors = tensors.pivot(values=[\"value\"], on=[\"tag\"], index=[\"dir_name\", \"step\"])\n",
    "tensors = tensors.sort(\"dir_name\", \"step\")"
   ],
   "id": "90ad68967c1098be"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "tensors.write_parquet(\"./processed/BA_fixed/tensors.parquet\", compression=\"zstd\", compression_level=22)",
   "id": "65d2966e292c34cd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Convert plots\n",
    "images = logs_no_pivot.images\n",
    "size = np.array(images.iloc[0][\"value\"].shape)\n",
    "images[\"value\"] = images[\"value\"].apply(lambda x: x.flatten())"
   ],
   "id": "994590cd9598f211"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# dumb stuff for datasets that barely fit into memory\n",
    "import gc\n",
    "\n",
    "data = [data for data in images[\"value\"].to_numpy() if type(data) is np.ndarray]\n",
    "images = images.drop(\"value\", axis=1)\n",
    "images_buf = images.copy(deep=True)\n",
    "del images\n",
    "gc.collect()\n",
    "data = np.array(data)\n",
    "images = images_buf\n",
    "del images_buf"
   ],
   "id": "751731fc4f31e981"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# plots = pl.read_parquet(\"./processed/images.parquet\")\n",
    "plots = pl.from_pandas(images, nan_to_null=True, schema_overrides={\"tag\": pl.String, \"dir_name\": pl.String}, include_index=True)\n",
    "plots = plots.with_columns(pl.Series(name=\"value\", values=data))"
   ],
   "id": "5cedfb81eae01109"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "num_rows = plots.select(pl.len()).to_series()[0]",
   "id": "8476895b80cafd53"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "plots = plots.with_columns(pl.col(\"value\").reshape(tuple([num_rows, *size])).alias(\"value\"))",
   "id": "f4c83ef2861ce9bb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "plots.write_parquet(\"./processed/BA_fixed/plots.parquet\", compression=\"zstd\")",
   "id": "8dbcf7740751bcbe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "# compress images for easier handling\n",
    "\n",
    "plots = pl.scan_parquet(\"./processed/BA_fixed/plots.parquet\")\n",
    "\n",
    "def convert_np_to_png(array: np.ndarray):\n",
    "    file_buf = BytesIO()\n",
    "    img = Image.fromarray(array, mode=\"RGB\")\n",
    "    img.save(file_buf, format=\"PNG\", optimize=True)\n",
    "    png_bin = file_buf.getvalue()\n",
    "    return png_bin"
   ],
   "id": "b65a21e0d853c197"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "plots.select(pl.len()).collect()",
   "id": "e5c8cfddedc82ae2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "test_img = plots.head(1).collect()[0, 3]\n",
    "png_img = convert_np_to_png(np.array(test_img))\n",
    "as_polars = pl.DataFrame({\"img\": [png_img]})\n",
    "png_img = as_polars[0, \"img\"]\n",
    "reversed_image = Image.open(BytesIO(png_img))\n",
    "reversed_image.show()\n",
    "\n",
    "test_img_map = plots.head(1).collect().with_columns(pl.col(\"value\").map_elements(lambda x: convert_np_to_png(np.array(x, dtype=np.uint8)), return_dtype=pl.Binary))[0, 3]\n",
    "reversed_image = Image.open(BytesIO(test_img_map))\n",
    "reversed_image.show()"
   ],
   "id": "1bc9a3c79f140f72"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# very slow\n",
    "plots.with_columns(pl.col(\"value\").map_elements(lambda x: convert_np_to_png(np.array(x, dtype=np.uint8)), return_dtype=pl.Binary, strategy=\"threading\")).sink_parquet(\"./processed/BA_fixed/plots_png.parquet\", compression_level=22)\n"
   ],
   "id": "529e074447f5370c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "plots = pl.scan_parquet(\"./processed/plots_png.parquet\")",
   "id": "7b10e112f600fc9d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plots = plots.unique(subset=[\"dir_name\", \"step\", \"tag\"], keep=\"none\").collect()\n",
    "plots = plots.pivot(values=[\"value\"], on=[\"tag\"], index=[\"dir_name\", \"step\"])\n",
    "plots = plots.sort(\"dir_name\", \"step\")"
   ],
   "id": "d8ddde32b2eabb50"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plots.write_parquet(\"./processed/BA_fixed/plots_png_pivot.parquet\", compression_level=22)\n",
    "del plots"
   ],
   "id": "6dcc9c65ee4a8fe5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Inspect data",
   "id": "ae28c8abfa978c21"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "hparams = pl.scan_parquet(\"./processed/hparams.parquet\")\n",
    "scalars = pl.scan_parquet(\"./processed/scores.parquet\")\n",
    "plots = pl.scan_parquet(\"./processed/plots_png_pivot.parquet\")"
   ],
   "id": "7f88051663e1414d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "hparams.collect()",
   "id": "7ef70d16a03f3c2c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "pl.Config.set_tbl_cols(100)\n",
    "pl.Config.set_tbl_rows(100)\n",
    "\n",
    "\n",
    "def get_model_settings(model_type: str) -> (pl.DataFrame, pl.DataFrame):\n",
    "    global hparams\n",
    "    model = hparams.filter(pl.col(\"model_settings\").str.contains(model_type))\n",
    "    non_null = model.select(pl.all().is_not_null().all()).row(0)\n",
    "    model = model[:, non_null]\n",
    "    different = model.select(pl.all().n_unique() > 1).row(0)\n",
    "    diff = model[:, different].sort(\"F-Score\", descending=True)\n",
    "    iden = model.select(pl.all().n_unique() == 1).row(0)\n",
    "    identical = model[:, iden].select(pl.all().exclude(\"dir_name\", \"F-Score\")).limit(1)\n",
    "\n",
    "    return diff, identical\n",
    "\n",
    "\n",
    "def get_history(name: str) -> pl.DataFrame:\n",
    "    global plots, scores\n",
    "    data = scores.filter(pl.col(\"dir_name\") == name)\n",
    "    prs = plots.filter(pl.col(\"dir_name\") == name)\n",
    "    data = data.join(prs, on=\"step\", how=\"inner\")\n",
    "    return data"
   ],
   "id": "1bca31173af07d03"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "unique, identical = get_model_settings(\"mamba\")\n",
    "print(identical)\n",
    "unique"
   ],
   "id": "4691bf0b298c6b80"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "unique, identical = get_model_settings(\"attention\")\n",
    "print(identical)\n",
    "unique"
   ],
   "id": "46d5cb9e18efadc7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "unique, identical = get_model_settings(\"cnn\")\n",
    "print(identical)\n",
    "unique"
   ],
   "id": "39564b9af843e74b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "unique, identical = get_model_settings(\"crnn\")\n",
    "print(identical)\n",
    "unique"
   ],
   "id": "53906a2741cb2612"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "best = unique.select(\"dir_name\").row(0)[0]\n",
    "history = get_history(best)\n",
    "tags = [\"Validation/PR-Curve/\" ,\"Test/RBMA_full/PR-Curve/\", \"Test/MDB_full/PR-Curve/\", \"Validation/Threshold-Curve/\", \"Test/RBMA_full/Threshold-Curve/\", \"Test/MDB_full/Threshold-Curve/\"]\n",
    "curves = []\n",
    "for tag in tags:\n",
    "    curves.append(history.select(pl.col(tag)).filter(pl.all().is_not_null()).row(-1)[0])\n",
    "# Show Curves in a grid\n",
    "fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    ax.imshow(curves[i])\n",
    "    ax.axis(\"off\")\n",
    "    # reduce spacing\n",
    "    ax.margins(0)\n",
    "    ax.axis(\"tight\")\n"
   ],
   "id": "416fda9adef4a51b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_model_dict(unique: pl.DataFrame, identical: pl.DataFrame) -> dict:\n",
    "    dics = []\n",
    "    for row in unique.to_dicts():\n",
    "        dics.append(row | identical.to_dicts()[0])\n",
    "    return dics"
   ],
   "id": "890a15a6a287691c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "get_model_dict(unique, identical)[0]",
   "id": "6521209a862ef26e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Get Value\n",
    "params.loc[params[\"dir_name\"].str.contains(best)][[\"full_length_test\"]]"
   ],
   "id": "f2d63559013a995b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "55eea5ae22539e25"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Import data from optuna",
   "id": "9a8ec9df69b9c649"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import optuna\n",
    "import ipywidgets as widgets\n",
    "import polars.selectors as cs\n",
    "from glob import glob\n",
    "\n",
    "_ = pl.Config.restore_defaults()"
   ],
   "id": "4e30e27e648cc091"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "hparams = pl.scan_parquet(\"processed/BA_fixed/hparams.parquet\")\n",
    "scalars = pl.scan_parquet(\"processed/BA_fixed/scores.parquet\")\n",
    "tensors = pl.scan_parquet(\"processed/BA_fixed/tensors.parquet\")"
   ],
   "id": "2116d44fd0eed456"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "storage: optuna.storages.BaseStorage = None\n",
    "\n",
    "db_files = glob(\"./optuna/*.db\")\n",
    "conn_strings = [\"sqlite:///\" + db for db in db_files]\n",
    "\n",
    "databases = [\"postgresql://BachelorarbeitSync:BachelorarbeitSyncPlsDontHackMe@192.168.2.206:5432\"]\n",
    "databases = conn_strings + databases\n",
    "\n",
    "db_dropdown = widgets.Dropdown(options=databases, description=\"Database: \")\n",
    "\n",
    "def set_storage(connection_string: str):\n",
    "    global storage\n",
    "    storage = optuna.storages.RDBStorage(\n",
    "        url=connection_string,\n",
    "        engine_kwargs={\"pool_pre_ping\": True, \"pool_recycle\": 3600, \"pool_timeout\": 3600},\n",
    "        heartbeat_interval=60,\n",
    "        grace_period=3600,\n",
    "    )\n",
    "\n",
    "widgets.interact(set_storage, connection_string=db_dropdown)\n",
    "\n",
    "study_dropdown = widgets.Dropdown(options=[], description=\"Study: \")\n",
    "\n",
    "def update_options(*args):\n",
    "    studies = storage.get_all_studies()\n",
    "    study_dropdown.options = [stdy.study_name for stdy in studies]\n",
    "db_dropdown.observe(update_options, \"value\")\n",
    "\n",
    "def select_study(selected_study):\n",
    "    global study\n",
    "    global storage\n",
    "\n",
    "    study = optuna.load_study(storage=storage, study_name=selected_study)\n",
    "\n",
    "_ = widgets.interact(select_study, selected_study=study_dropdown)\n",
    "study: optuna.Study = study"
   ],
   "id": "efa01af8568bd6eb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "study_data = study.trials_dataframe()\n",
    "study_data = pl.from_pandas(study_data).lazy()\n",
    "study_data = study_data.filter(pl.col(\"state\") == \"COMPLETE\").sort(cs.contains(\"value\"), descending=True)\n",
    "num_trials = study_data.select(pl.len()).collect()[0, 0]\n",
    "print(num_trials)\n",
    "\n",
    "optuna_param_list = study_data.select(cs.contains(\"params_\").name.map(lambda s: s.removeprefix(\"params_\"))).collect_schema()\n",
    "\n",
    "study_data = (\n",
    "    study_data\n",
    "    .select(cs.contains(\"params_\").name.map(lambda s: s.removeprefix(\"params_\")), ~cs.contains(\"params_\"))\n",
    "    .select(~(cs.contains(\"user\") | cs.contains(\"system_attrs\")), cs.contains(\"user\").name.map(lambda x: x.removeprefix(\"user_attrs_\")))\n",
    "    .select(~cs.contains(\"f_score\"), cs.contains(\"f_score\").name.prefix(\"optuna_\"))\n",
    "    .drop(\"state\", \"number\")\n",
    "    .with_columns(pl.lit(study.study_name).alias(\"study_name\"))\n",
    ")\n",
    "study_data = study_data.with_columns(pl.col(list(set(integer_values) & set(study_data.collect_schema().names()))).cast(pl.Int64))\n",
    "logs_param_list = hparams.collect_schema()\n",
    "matched_params = [key for key, dtype in optuna_param_list.items() if key in logs_param_list.keys()]\n",
    "\n",
    "# matched_params.remove(\"expansion_factor\")\n",
    "# matched_params.remove(\"hidden_units\")\n",
    "print(logs_param_list)\n",
    "matched_params"
   ],
   "id": "4218dccc3d88a959"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "hparams.collect()",
   "id": "5d0765bb9727df3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "study_data.collect()",
   "id": "68bfdff30d049cd6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from itertools import combinations\n",
    "\n",
    "res = reversed([list(combinations(matched_params, r)) for r in range(1, len(matched_params) + 1)])\n",
    "res = [list(sublist) for g in res for sublist in g]\n",
    "\n",
    "full_matched_params = None\n",
    "\n",
    "for comb in res:\n",
    "    joined = hparams.with_columns(cs.by_dtype(pl.String).exclude(\"dir_name\").str.to_lowercase()).join(study_data, on=comb, how=\"inner\", nulls_equal=True)\n",
    "    unique_matches = joined.unique(subset=\"datetime_start\").select(pl.len()).collect()[0, 0]\n",
    "    if unique_matches == num_trials:\n",
    "        full_matched_params = comb\n",
    "        print(full_matched_params)\n",
    "        break\n",
    "\n",
    "# assert full_matched_params is not None, \"No matching subset was found. Are logs for all the experiments present?\"\n",
    "\n",
    "# full_matched_params = comb\n",
    "mismatched_params = [param for param in matched_params if param not in full_matched_params]\n",
    "\n",
    "joined = hparams.with_columns(cs.by_dtype(pl.String).exclude(\"dir_name\").str.to_lowercase()).join(study_data, on=full_matched_params, how=\"cross\", nulls_equal=True).collect()\n",
    "joined = joined[[s.name for s in joined if not (s.null_count() == joined.height)]]\n",
    "joined = joined.filter((abs((pl.col(\"start_time\") - pl.col(\"datetime_start\"))) < pl.duration(minutes=30)) & (pl.col(\"start_time\") > pl.col(\"datetime_start\")))\n",
    "useful_cols = [col + \"_right\" for col in mismatched_params if col not in joined.columns]\n",
    "if len(useful_cols) > 0:\n",
    "    joined = joined.select(cs.exclude(useful_cols), pl.col(useful_cols).name.map(lambda s: s.removesuffix(\"_right\")))\n",
    "joined = joined.select(~cs.contains(\"_right\")) # parameters that are mismatched are most likely due to a param being generated but not assigned\n",
    "joined = joined[[s.name for s in joined if not (s.null_count() == joined.height)]]\n",
    "joined\n",
    "\n",
    "# sub = joined.select(\"dir_name\", \"datetime_start\", cs.contains(*mismatched_params))\n",
    "# sorted_mis = sorted(sub.columns)\n",
    "# sorted_mis.remove(\"datetime_start\")\n",
    "# sorted_mis.remove(\"dir_name\")\n",
    "# duplicated_dates = sub.group_by(\"datetime_start\").agg(pl.len().alias(\"count\")).filter(pl.col(\"count\") > 1).select(\"datetime_start\").to_series().to_list()\n",
    "# sub.select(\"dir_name\", \"datetime_start\", *sorted_mis).sort(\"datetime_start\").filter(pl.col(\"datetime_start\").is_in(duplicated_dates))"
   ],
   "id": "e8250d730388458"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# joined = hparams.with_columns(cs.by_dtype(pl.String).exclude(\"dir_name\").str.to_lowercase()).with_columns(pl.duration(minutes=2).alias(\"tolerance\")).join_where(study_data, abs((pl.col(\"start_time\") - pl.col(\"datetime_start\"))) < pl.col(\"tolerance\"))\n",
    "study_data.filter(~(pl.col(\"datetime_start\").is_in(joined.select(pl.col(\"datetime_start\")).to_series()))).collect()"
   ],
   "id": "31608e1e19861843"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pathlib\n",
    "\n",
    "if not pathlib.Path(\"./processed/optuna.parquet\").exists():\n",
    "    joined.write_parquet(\"./processed/optuna.parquet\")\n",
    "else:\n",
    "    optuna_collection = pl.read_parquet(\"./processed/optuna.parquet\")\n",
    "    optuna_cols = set(optuna_collection.columns)\n",
    "    optuna_schema = optuna_collection.schema\n",
    "    joined_cols = set(joined.columns)\n",
    "    joined_schema = joined.schema\n",
    "    missing_cols = joined_cols - optuna_cols\n",
    "    missing_schema = optuna_cols - joined_cols\n",
    "    print(missing_cols)\n",
    "    print(missing_schema)\n",
    "    for col in missing_cols:\n",
    "        optuna_collection = optuna_collection.with_columns(pl.lit(None).alias(col).cast(joined.schema[col]))\n",
    "    for col in missing_schema:\n",
    "        joined = joined.with_columns(pl.lit(None).alias(col).cast(optuna_collection.schema[col]))\n",
    "    joined = joined.select(pl.col(optuna_collection.columns))\n",
    "    out = pl.concat([optuna_collection, joined], how=\"vertical_relaxed\")\n",
    "    out.write_parquet(\"./processed/optuna.parquet\")\n",
    "\n",
    "    # optuna_collection.write_parquet(\"./processed/optuna.parquet\")\n",
    "\n"
   ],
   "id": "677743c5c83eb8ed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "optuna_collection = pl.read_parquet(\"./processed/optuna.parquet\")\n",
    "optuna_collection = optuna_collection[[s.name for s in optuna_collection if not (s.null_count() == optuna_collection.height)]]\n",
    "optuna_collection.unique(subset=\"dir_name\", keep=\"any\").write_parquet(\"./processed/optuna.parquet\", compression=\"zstd\")"
   ],
   "id": "72f6fcb6357059aa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "hparams.filter((pl.col(\"dataset_version\") == \"M\") | (pl.col(\"dataset_version\") == \"L\")).sort(\"F-Score\", descending=True).collect()",
   "id": "e55822bb5e4848c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "scalar_cols = set(scalars.collect_schema().names()) - {\"dir_name\", \"step\"}\n",
    "plots_cols = set(plots.collect_schema().names()) - {\"dir_name\", \"step\"}\n",
    "# data points that get lost in the join are most likely due to ^C exit\n",
    "joined_plots = scalars.join(plots, on=[\"dir_name\", \"step\"], how=\"inner\").sort([\"dir_name\", \"step\"])\n",
    "joined_plots.sink_parquet(\"./processed/plots_with_scalars.parquet\", compression=\"zstd\", compression_level=22)\n",
    "\n"
   ],
   "id": "d3f9eeb7d40fbd7e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# View Data",
   "id": "86045c5eb1118142"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from functools import lru_cache\n",
    "\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import optuna\n",
    "import ipywidgets as widgets\n",
    "import polars.selectors as cs\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import io"
   ],
   "id": "3904f3c9a6332eef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "pl.Config.set_tbl_hide_column_data_types(True)\n",
    "pl.Config.set_tbl_hide_dataframe_shape(True)\n",
    "pl.Config.set_tbl_cols(17)\n",
    "pl.Config.set_tbl_rows(20)\n",
    "\n",
    "def drop_columns_that_are_all_null(_df: pl.DataFrame) -> pl.DataFrame:\n",
    "    return _df[[s.name for s in _df if not (s.null_count() == _df.height)]]\n",
    "\n",
    "assert integer_values\n",
    "def sort_columns(_df: pl.DataFrame) -> pl.DataFrame:\n",
    "    parameters = set(integer_values) | set(boolean_values) | set(string_values) | set(float_values)\n",
    "    columns = set(_df.columns)\n",
    "    scores = sorted(list(set(_df.select(cs.contains(\"core\")).columns) - parameters))\n",
    "    losses = sorted(list(set(_df.select(cs.contains(\"oss\")).columns) - parameters))\n",
    "    parameters = sorted(list(parameters & columns))\n",
    "    sorted_columns: list[str] = [\"dir_name\", \"F-Score\", \"flops\", \"params\", *scores, *losses, *parameters, *columns]\n",
    "\n",
    "    sorted_columns = [col for col, _ in dict([item[::-1] for item in enumerate(sorted_columns)]).items()] # deduplication using dict as an ordered set\n",
    "    sorted_columns = [col for col in sorted_columns if col in columns]\n",
    "    return _df.select(pl.col(*sorted_columns))"
   ],
   "id": "9031d8c28307e3bc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "hparams = pl.scan_parquet(\"./processed/optuna.parquet\")\n",
    "plots = pl.scan_parquet(\"./processed/plots_png_pivot.parquet\")\n",
    "scalars = pl.scan_parquet(\"./processed/scores.parquet\")"
   ],
   "id": "86650bd7797d99ab"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model_settings: pl.DataFrame = None\n",
    "# select model type\n",
    "model_types = hparams.select(pl.col(\"model_settings\").unique()).collect().to_series().to_list()\n",
    "model_selector = widgets.Dropdown(options=model_types, description=\"Model Type: \")\n",
    "\n",
    "def set_model_settings(model_type: str):\n",
    "    global model_settings\n",
    "    best_values = scalars.select(\n",
    "        pl.col(\"dir_name\"),\n",
    "        cs.contains(\"core\").max().over(\"dir_name\"),\n",
    "        *[pl.col(\"step\").get(pl.col(_col).arg_max()).over(\"dir_name\").alias(_col + \"_step\") for _col in scalars.select(cs.contains(\"core\")).collect_schema().names()],\n",
    "        cs.contains(\"oss\").min().over(\"dir_name\"),\n",
    "        *[pl.col(\"step\").get(pl.col(_col).arg_min()).over(\"dir_name\").alias(_col + \"_step\") for _col in scalars.select(cs.contains(\"oss\")).collect_schema().names()]\n",
    "    ).unique(\"dir_name\")\n",
    "    _df = hparams.filter(pl.col(\"model_settings\") == model_type).collect()\n",
    "    _df = _df.lazy().join(best_values, on=pl.col(\"dir_name\")).sort(\"F-Score\", descending=True).collect()\n",
    "    model_settings = sort_columns(drop_columns_that_are_all_null(_df))\n",
    "\n",
    "\n",
    "# set_model_settings(\"crnn\")\n",
    "\n",
    "\n",
    "_ = widgets.interact(set_model_settings, model_type=model_selector)"
   ],
   "id": "805920cd18a40509"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "model_settings.sort(\"dir_name\")",
   "id": "8e9a90c91cebacfe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "selectable_range = 20\n",
    "\n",
    "\n",
    "run_options = model_settings.head(selectable_range).select(\"dir_name\").to_series().to_list()\n",
    "run_selector = widgets.Dropdown(options=run_options, value=run_options[0])\n",
    "\n",
    "run = run_options[0]\n",
    "\n",
    "@lru_cache\n",
    "def get_run(name: str):\n",
    "    settings = model_settings.filter(pl.col(\"dir_name\") == name)\n",
    "    settings = drop_columns_that_are_all_null(settings)\n",
    "    model_params = sorted(set([param for typ in [int, float, str, bool] for param in get_columns_with_type(typ, True)]) & set(settings.columns))\n",
    "    rows = [\n",
    "        settings.select(pl.col(*settings.columns[:4], \"dataset_version\")),\n",
    "        settings.select(cs.contains(\"/\") & cs.contains(\"core\") & ~cs.contains(\"_step\")),\n",
    "        settings.select(cs.contains(\"/\") & cs.contains(\"core\") & cs.contains(\"_step\")),\n",
    "        settings.select(pl.col(model_params)),\n",
    "    ]\n",
    "\n",
    "    values = scalars.lazy().filter(pl.col(\"dir_name\") == name).sort(\"step\")\n",
    "    losses = values.select(pl.col(\"step\"), cs.by_dtype(pl.Float64) & cs.contains(\"oss\")).collect()\n",
    "    losses = (\n",
    "        drop_columns_that_are_all_null(losses)\n",
    "            .lazy()\n",
    "            .unpivot(cs.contains(\"oss\"), index=\"step\", variable_name=\"tag\")\n",
    "            .with_columns(pl.col(\"tag\").str.split(\"/\").list.to_struct(n_field_strategy=\"max_width\", fields=[\"score\", \"split\", \"tag\"]))\n",
    "            .unnest(\"tag\")\n",
    "            .drop(\"score\")\n",
    "            .with_columns(pl.col(\"split\", \"tag\").fill_null(pl.col(\"split\")))\n",
    "            .collect()\n",
    "    )\n",
    "    f_scores = values.select(\"step\", cs.by_dtype(pl.Float64) & cs.contains(\"core\")).collect()\n",
    "\n",
    "    f_scores = (\n",
    "        drop_columns_that_are_all_null(f_scores)\n",
    "            .lazy()\n",
    "            .unpivot(cs.contains(\"core\"), index=\"step\", variable_name=\"tag\")\n",
    "            .with_columns(pl.col(\"tag\").str.split(\"/\").list.to_struct(n_field_strategy=\"max_width\", fields=[\"score\", \"type\", \"split\", \"tag\"]))\n",
    "            .unnest(\"tag\")\n",
    "            .drop(\"score\")\n",
    "            .with_columns(pl.col(\"type\", \"split\", \"tag\").fill_null(pl.col(\"split\")))\n",
    "            .collect()\n",
    "    )\n",
    "    return rows, losses, f_scores\n",
    "\n",
    "def plot_run(name: str):\n",
    "    global run\n",
    "    run = name\n",
    "    step_selector.max = scalars.filter(pl.col(\"dir_name\") == run).select(pl.col(\"step\").max()).collect().to_series()[0]\n",
    "\n",
    "    rows, losses, f_scores = get_run(name)\n",
    "    for row in rows:\n",
    "        print(row)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(15, 6), ncols=2)\n",
    "    sns.lineplot(data=losses, x=\"step\", y=\"value\", hue=\"tag\", ax=ax[0], style=\"split\")\n",
    "    ax[0].set_title(f\"Losses for {name}\")\n",
    "    ax[0].set_xlabel(\"Step\")\n",
    "    ax[0].set_ylabel(\"Loss\")\n",
    "    ax[0].set_yscale('log')\n",
    "\n",
    "    sns.lineplot(data=f_scores, x=\"step\", y=\"value\", hue=\"tag\", ax=ax[1], style=\"type\")\n",
    "    ax[1].set_title(f\"F-Scores for {name}\")\n",
    "    ax[1].set_xlabel(\"Step\")\n",
    "    ax[1].set_ylabel(\"F-Score\")\n",
    "    ax[1].set_ylim(0, 1)\n",
    "    ax[1].set_yticks(np.arange(0, 1.1, 0.1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# plot_run(run)\n",
    "\n",
    "\n",
    "def update_run_options(*args):\n",
    "    global run_selector\n",
    "    run_selector.options = model_settings.head(selectable_range).select(\"dir_name\").to_series().to_list()\n",
    "model_selector.observe(update_run_options, \"value\")\n",
    "\n",
    "@lru_cache\n",
    "def get_plots(run, step):\n",
    "    global plots\n",
    "    step_plots = (\n",
    "        plots.lazy()\n",
    "            .filter(pl.col(\"dir_name\") == run)\n",
    "            .sort(\"step\")\n",
    "            .select(pl.all().fill_null(strategy=\"forward\"))\n",
    "            .filter(pl.col(\"step\") == step)\n",
    "            .select(cs.by_dtype(pl.Binary))\n",
    "            .collect()\n",
    "    )\n",
    "    return drop_columns_that_are_all_null(step_plots)\n",
    "\n",
    "def plot_step(step: int):\n",
    "    global plots\n",
    "    step_plots = get_plots(run_selector.value, step)\n",
    "    pr_plots = step_plots.select(cs.contains(\"PR-Curve\"))\n",
    "    threshold_plots = step_plots.select(cs.contains(\"Threshold\"))\n",
    "    to_plot = [pr_plots, threshold_plots]\n",
    "    n_tags = pr_plots.shape[1]\n",
    "    if n_tags == 0:\n",
    "        return\n",
    "    _fig, _axs = plt.subplots(figsize=(10, 12), ncols=2, nrows=n_tags)\n",
    "    if n_tags == 1:\n",
    "        _axs = [_axs]\n",
    "    for _i, ax_row in enumerate(_axs):\n",
    "        for j, _ax in enumerate(ax_row):\n",
    "            png = to_plot[j][0, _i]\n",
    "            png_file = io.BytesIO(png)\n",
    "            img = np.asarray(Image.open(png_file, formats=[\"PNG\"]))\n",
    "            _ax.imshow(img)\n",
    "            _ax.axis(\"off\")\n",
    "            # reduce spacing\n",
    "            _ax.margins(0)\n",
    "            # _ax.axis(\"tight\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# plot_step(0)\n",
    "\n",
    "max_step = scalars.filter(pl.col(\"dir_name\") == run).select(pl.col(\"step\").max()).collect().to_series()[0]\n",
    "step_selector = widgets.IntSlider(min=0, max=max_step)\n",
    "\n",
    "def update_max_steps(*args):\n",
    "    step_selector.max = scalars.filter(pl.col(\"dir_name\") == run).select(pl.col(\"step\").max()).collect().to_series()[0]\n",
    "model_selector.observe(update_max_steps, \"value\")\n",
    "run_selector.observe(update_max_steps, \"value\")\n",
    "\n",
    "def plot_all(name: str, step: int):\n",
    "    print(model_settings.head(selectable_range).select(pl.col(*model_settings.columns[:4], \"dataset_version\")))\n",
    "    # print(model_settings.head(selectable_range).select(cs.contains(\"Test\")))\n",
    "    plot_run(name)\n",
    "    plot_step(step)\n",
    "\n",
    "# plot_all(run , 0)\n",
    "\n",
    "run_plot = widgets.interactive(plot_all, name=run_selector, step=step_selector)\n",
    "output = run_plot.children[-1]\n",
    "output.layout.height = '2400px'\n",
    "\n",
    "run_plot\n"
   ],
   "id": "c35564a53c8dd371"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluate hyperparameter validation",
   "id": "357566bf99f2a386"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T01:15:52.924990Z",
     "start_time": "2025-07-05T01:15:51.280566Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from settings import TrainingSettings, DatasetSettings, EvaluationSettings, CNNSettings, CNNMambaSettings, CNNAttentionSettings, CRNNSettings, asdict, Config"
   ],
   "id": "e49cd7ea300231c0",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T01:17:34.336728Z",
     "start_time": "2025-07-05T01:17:34.331883Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_columns_with_type(typ, get_only_model_settings=False) -> list[str]:\n",
    "    out = []\n",
    "    if not get_only_model_settings:\n",
    "        classes = [TrainingSettings, DatasetSettings, EvaluationSettings]\n",
    "        for cls in classes:\n",
    "            settings = cls()\n",
    "            dic = asdict(settings)\n",
    "            for name, value in dic.items():\n",
    "                if type(value) is typ:\n",
    "                    out.append(name)\n",
    "    classes = [CNNSettings, CNNAttentionSettings, CNNMambaSettings, CRNNSettings]\n",
    "    for cls in classes:\n",
    "        settings = cls(3, 84)\n",
    "        dic = asdict(settings)\n",
    "        for name, value in dic.items():\n",
    "            if type(value) is typ:\n",
    "                out.append(name)\n",
    "    return list(set(out))\n",
    "\n",
    "def drop_columns_that_are_all_null(_df: pl.DataFrame) -> pl.DataFrame:\n",
    "    return _df[[s.name for s in _df if not (s.null_count() == _df.height)]]\n",
    "\n",
    "def get_settings(param_row: pl.DataFrame):\n",
    "    settings = drop_columns_that_are_all_null(param_row)\n",
    "    model_params = sorted(set([param for typ in [int, float, str, bool] for param in get_columns_with_type(typ, False)]) & set(settings.columns))\n",
    "    _dict = settings.select(pl.col(model_params)).to_dicts()[0]\n",
    "    if _dict[\"model_settings\"] == \"crnn\" and \"hidden_units\" in _dict.keys():\n",
    "        _dict.pop(\"hidden_units\")\n",
    "    if _dict[\"model_settings\"] in [\"crnn\", \"mamba\", \"mamba_fast\"] and \"use_relative_pos\" in _dict.keys():\n",
    "        _dict.pop(\"use_relative_pos\")\n",
    "    if _dict[\"model_settings\"].startswith(\"mamba\") and \"expansion_factor\" in _dict.keys():\n",
    "        _dict.pop(\"expansion_factor\")\n",
    "    config = Config.from_flat_dict(_dict)\n",
    "    reversed_settings = {\n",
    "        **asdict(config.training),\n",
    "        **asdict(config.evaluation),\n",
    "        **asdict(config.dataset),\n",
    "    }\n",
    "    if config.model is not None:\n",
    "        reversed_settings.update(asdict(config.model))\n",
    "    for key, item in _dict.items():\n",
    "        if key in [\"activation\", \"mapping\", \"splits\", \"test_sets\"]:\n",
    "            assert str(item) == str(reversed_settings[key])\n",
    "            # print(f\"{item} == {reversed_settings[key]}: Please check manually if {key} is equal\")\n",
    "            continue\n",
    "        assert item == reversed_settings[key], f\"Key {key} is mismatched: {item}({type(item)}) != {reversed_settings[key]}({type(reversed_settings[key])})\"\n",
    "    return _dict"
   ],
   "id": "c0aa33c1d8d81bc1",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T01:16:07.308671Z",
     "start_time": "2025-07-05T01:16:07.306308Z"
    }
   },
   "cell_type": "code",
   "source": "output_dir = \"processed/CRNN/Params validation\"",
   "id": "cb4c69a06108debd",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T01:16:08.196388Z",
     "start_time": "2025-07-05T01:16:08.128392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hparams = pl.read_parquet(f\"{output_dir}/hparams.parquet\")\n",
    "scores = pl.read_parquet(f\"{output_dir}/scores.parquet\").filter(pl.col(\"F-Score\").is_null()).drop(\"F-Score\")"
   ],
   "id": "b05771dbb89921d",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T01:16:50.187888Z",
     "start_time": "2025-07-05T01:16:50.182760Z"
    }
   },
   "cell_type": "code",
   "source": "hparams",
   "id": "d709c3af444dc64d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shape: (50, 64)\n",
       "┌────────────┬────────────┬───────┬────────┬───┬─────────────┬──────────┬─────────────┬────────────┐\n",
       "│ activation ┆ batch_size ┆ beats ┆ beta_1 ┆ … ┆ weight_deca ┆ F-Score  ┆ dir_name    ┆ start_time │\n",
       "│ ---        ┆ ---        ┆ ---   ┆ ---    ┆   ┆ y           ┆ ---      ┆ ---         ┆ ---        │\n",
       "│ str        ┆ i64        ┆ bool  ┆ f64    ┆   ┆ ---         ┆ f64      ┆ str         ┆ datetime[n │\n",
       "│            ┆            ┆       ┆        ┆   ┆ f64         ┆          ┆             ┆ s]         │\n",
       "╞════════════╪════════════╪═══════╪════════╪═══╪═════════════╪══════════╪═════════════╪════════════╡\n",
       "│ ReLU       ┆ 37         ┆ false ┆ 0.9    ┆ … ┆ 6.0639e-7   ┆ 0.68648  ┆ Jun30_16-53 ┆ 2025-06-30 │\n",
       "│            ┆            ┆       ┆        ┆   ┆             ┆          ┆ -32_marclie ┆ 16:53:32   │\n",
       "│            ┆            ┆       ┆        ┆   ┆             ┆          ┆ -desktop    ┆            │\n",
       "│ ReLU       ┆ 7          ┆ false ┆ 0.9    ┆ … ┆ 1.1095e-15  ┆ 0.655962 ┆ Jun30_16-58 ┆ 2025-06-30 │\n",
       "│            ┆            ┆       ┆        ┆   ┆             ┆          ┆ -38_marclie ┆ 16:58:38   │\n",
       "│            ┆            ┆       ┆        ┆   ┆             ┆          ┆ -desktop    ┆            │\n",
       "│ ELU        ┆ 6          ┆ false ┆ 0.9    ┆ … ┆ 2.0121e-7   ┆ 0.72142  ┆ Jun30_17-02 ┆ 2025-06-30 │\n",
       "│            ┆            ┆       ┆        ┆   ┆             ┆          ┆ -41_marclie ┆ 17:02:41   │\n",
       "│            ┆            ┆       ┆        ┆   ┆             ┆          ┆ -desktop    ┆            │\n",
       "│ ELU        ┆ 12         ┆ false ┆ 0.9    ┆ … ┆ 8.0411e-8   ┆ 0.724782 ┆ Jun30_17-05 ┆ 2025-06-30 │\n",
       "│            ┆            ┆       ┆        ┆   ┆             ┆          ┆ -45_marclie ┆ 17:05:45   │\n",
       "│            ┆            ┆       ┆        ┆   ┆             ┆          ┆ -desktop    ┆            │\n",
       "│ ELU        ┆ 8          ┆ false ┆ 0.9    ┆ … ┆ 2.9620e-8   ┆ 0.716706 ┆ Jun30_17-08 ┆ 2025-06-30 │\n",
       "│            ┆            ┆       ┆        ┆   ┆             ┆          ┆ -24_marclie ┆ 17:08:24   │\n",
       "│            ┆            ┆       ┆        ┆   ┆             ┆          ┆ -desktop    ┆            │\n",
       "│ …          ┆ …          ┆ …     ┆ …      ┆ … ┆ …           ┆ …        ┆ …           ┆ …          │\n",
       "│ ELU        ┆ 8          ┆ false ┆ 0.9    ┆ … ┆ 5.9861e-9   ┆ 0.666329 ┆ Jun30_19-58 ┆ 2025-06-30 │\n",
       "│            ┆            ┆       ┆        ┆   ┆             ┆          ┆ -26_marclie ┆ 19:58:26   │\n",
       "│            ┆            ┆       ┆        ┆   ┆             ┆          ┆ -desktop    ┆            │\n",
       "│ SELU       ┆ 4          ┆ false ┆ 0.9    ┆ … ┆ 3.3012e-12  ┆ 0.729093 ┆ Jun30_20-02 ┆ 2025-06-30 │\n",
       "│            ┆            ┆       ┆        ┆   ┆             ┆          ┆ -54_marclie ┆ 20:02:54   │\n",
       "│            ┆            ┆       ┆        ┆   ┆             ┆          ┆ -desktop    ┆            │\n",
       "│ ELU        ┆ 5          ┆ false ┆ 0.9    ┆ … ┆ 1.1468e-8   ┆ 0.701014 ┆ Jun30_20-07 ┆ 2025-06-30 │\n",
       "│            ┆            ┆       ┆        ┆   ┆             ┆          ┆ -04_marclie ┆ 20:07:04   │\n",
       "│            ┆            ┆       ┆        ┆   ┆             ┆          ┆ -desktop    ┆            │\n",
       "│ ELU        ┆ 9          ┆ false ┆ 0.9    ┆ … ┆ 9.5536e-10  ┆ 0.736903 ┆ Jun30_20-10 ┆ 2025-06-30 │\n",
       "│            ┆            ┆       ┆        ┆   ┆             ┆          ┆ -49_marclie ┆ 20:10:49   │\n",
       "│            ┆            ┆       ┆        ┆   ┆             ┆          ┆ -desktop    ┆            │\n",
       "│ ELU        ┆ 8          ┆ false ┆ 0.9    ┆ … ┆ 3.9279e-7   ┆ 0.701464 ┆ Jun30_20-16 ┆ 2025-06-30 │\n",
       "│            ┆            ┆       ┆        ┆   ┆             ┆          ┆ -41_marclie ┆ 20:16:41   │\n",
       "│            ┆            ┆       ┆        ┆   ┆             ┆          ┆ -desktop    ┆            │\n",
       "└────────────┴────────────┴───────┴────────┴───┴─────────────┴──────────┴─────────────┴────────────┘"
      ],
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (50, 64)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>activation</th><th>batch_size</th><th>beats</th><th>beta_1</th><th>beta_2</th><th>causal</th><th>center</th><th>channel_multiplication</th><th>classifier_dim</th><th>dataset_version</th><th>decoupled_weight_decay</th><th>detect_tolerance</th><th>down_sample_factor</th><th>dropout</th><th>early_stopping</th><th>ema</th><th>epochs</th><th>epsilon</th><th>eval_set</th><th>fft_size</th><th>flux</th><th>frame_length</th><th>frame_overlap</th><th>full_length_test</th><th>hop_size</th><th>ignore_beats</th><th>label_lead_in</th><th>label_lead_out</th><th>learning_rate</th><th>mapping</th><th>mel_max</th><th>mel_min</th><th>min_save_score</th><th>min_test_score</th><th>model_settings</th><th>n_mels</th><th>normalize</th><th>num_channels</th><th>num_conv_layers</th><th>num_rnn_layers</th><th>num_workers</th><th>onset_cooldown</th><th>pad_annotations</th><th>pad_mode</th><th>pad_value</th><th>peak_max_range</th><th>peak_mean_range</th><th>positive_weight</th><th>power</th><th>pr_points</th><th>rnn_units</th><th>sample_rate</th><th>scheduler</th><th>seed</th><th>segment_type</th><th>splits</th><th>test_batch_size</th><th>test_sets</th><th>time_shift</th><th>train_set</th><th>weight_decay</th><th>F-Score</th><th>dir_name</th><th>start_time</th></tr><tr><td>str</td><td>i64</td><td>bool</td><td>f64</td><td>f64</td><td>bool</td><td>bool</td><td>i64</td><td>i64</td><td>str</td><td>bool</td><td>f64</td><td>i64</td><td>f64</td><td>str</td><td>bool</td><td>i64</td><td>f64</td><td>str</td><td>i64</td><td>bool</td><td>f64</td><td>f64</td><td>bool</td><td>i64</td><td>bool</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>i64</td><td>bool</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>f64</td><td>bool</td><td>str</td><td>f64</td><td>i64</td><td>i64</td><td>f64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>bool</td><td>f64</td><td>str</td><td>str</td><td>i64</td><td>str</td><td>f64</td><td>str</td><td>f64</td><td>f64</td><td>str</td><td>datetime[ns]</td></tr></thead><tbody><tr><td>&quot;ReLU&quot;</td><td>37</td><td>false</td><td>0.9</td><td>0.999</td><td>true</td><td>true</td><td>3</td><td>31</td><td>&quot;S&quot;</td><td>true</td><td>0.025</td><td>4</td><td>0.35</td><td>&quot;5&quot;</td><td>false</td><td>30</td><td>1.0000e-8</td><td>&quot;A2MD&quot;</td><td>2048</td><td>true</td><td>2.3</td><td>1.1</td><td>true</td><td>441</td><td>true</td><td>0.25</td><td>0.1</td><td>0.003421</td><td>&quot;Three class standard&quot;</td><td>20000.0</td><td>20.0</td><td>0.7</td><td>0.6</td><td>&quot;crnn&quot;</td><td>84</td><td>false</td><td>16</td><td>2</td><td>3</td><td>16</td><td>0.021</td><td>true</td><td>&quot;constant&quot;</td><td>0.25</td><td>2</td><td>2</td><td>1.0</td><td>1</td><td>100</td><td>61</td><td>44100</td><td>false</td><td>0.0</td><td>&quot;frame&quot;</td><td>&quot;[0.75, 0.25, 0.0]&quot;</td><td>1</td><td>&quot;(&#x27;RBMA&#x27;, &#x27;MDB&#x27;)&quot;</td><td>0.035</td><td>&quot;a2md_train&quot;</td><td>6.0639e-7</td><td>0.68648</td><td>&quot;Jun30_16-53-32_marclie-desktop&quot;</td><td>2025-06-30 16:53:32</td></tr><tr><td>&quot;ReLU&quot;</td><td>7</td><td>false</td><td>0.9</td><td>0.999</td><td>true</td><td>true</td><td>1</td><td>32</td><td>&quot;S&quot;</td><td>true</td><td>0.025</td><td>1</td><td>0.3</td><td>&quot;5&quot;</td><td>false</td><td>30</td><td>1.0000e-8</td><td>&quot;A2MD&quot;</td><td>2048</td><td>true</td><td>3.9</td><td>1.1</td><td>true</td><td>441</td><td>true</td><td>0.25</td><td>0.1</td><td>0.00362</td><td>&quot;Three class standard&quot;</td><td>20000.0</td><td>20.0</td><td>0.7</td><td>0.6</td><td>&quot;crnn&quot;</td><td>96</td><td>false</td><td>32</td><td>0</td><td>2</td><td>16</td><td>0.021</td><td>true</td><td>&quot;constant&quot;</td><td>0.25</td><td>2</td><td>2</td><td>1.0</td><td>1</td><td>100</td><td>23</td><td>44100</td><td>false</td><td>1.0</td><td>&quot;frame&quot;</td><td>&quot;[0.75, 0.25, 0.0]&quot;</td><td>1</td><td>&quot;(&#x27;RBMA&#x27;, &#x27;MDB&#x27;)&quot;</td><td>0.035</td><td>&quot;a2md_train&quot;</td><td>1.1095e-15</td><td>0.655962</td><td>&quot;Jun30_16-58-38_marclie-desktop&quot;</td><td>2025-06-30 16:58:38</td></tr><tr><td>&quot;ELU&quot;</td><td>6</td><td>false</td><td>0.9</td><td>0.999</td><td>true</td><td>true</td><td>1</td><td>33</td><td>&quot;S&quot;</td><td>true</td><td>0.025</td><td>4</td><td>0.35</td><td>&quot;5&quot;</td><td>false</td><td>30</td><td>1.0000e-8</td><td>&quot;A2MD&quot;</td><td>2048</td><td>true</td><td>3.5</td><td>1.2</td><td>true</td><td>441</td><td>true</td><td>0.25</td><td>0.1</td><td>0.000779</td><td>&quot;Three class standard&quot;</td><td>20000.0</td><td>20.0</td><td>0.7</td><td>0.6</td><td>&quot;crnn&quot;</td><td>84</td><td>false</td><td>16</td><td>0</td><td>4</td><td>16</td><td>0.021</td><td>true</td><td>&quot;constant&quot;</td><td>0.25</td><td>2</td><td>2</td><td>1.0</td><td>1</td><td>100</td><td>70</td><td>44100</td><td>false</td><td>2.0</td><td>&quot;frame&quot;</td><td>&quot;[0.75, 0.25, 0.0]&quot;</td><td>1</td><td>&quot;(&#x27;RBMA&#x27;, &#x27;MDB&#x27;)&quot;</td><td>0.035</td><td>&quot;a2md_train&quot;</td><td>2.0121e-7</td><td>0.72142</td><td>&quot;Jun30_17-02-41_marclie-desktop&quot;</td><td>2025-06-30 17:02:41</td></tr><tr><td>&quot;ELU&quot;</td><td>12</td><td>false</td><td>0.9</td><td>0.999</td><td>true</td><td>true</td><td>1</td><td>45</td><td>&quot;S&quot;</td><td>true</td><td>0.025</td><td>4</td><td>0.5</td><td>&quot;5&quot;</td><td>false</td><td>30</td><td>1.0000e-8</td><td>&quot;A2MD&quot;</td><td>2048</td><td>true</td><td>4.1</td><td>1.2</td><td>true</td><td>441</td><td>true</td><td>0.25</td><td>0.1</td><td>0.004734</td><td>&quot;Three class standard&quot;</td><td>20000.0</td><td>20.0</td><td>0.7</td><td>0.6</td><td>&quot;crnn&quot;</td><td>84</td><td>false</td><td>16</td><td>1</td><td>3</td><td>16</td><td>0.021</td><td>true</td><td>&quot;constant&quot;</td><td>0.25</td><td>2</td><td>2</td><td>1.0</td><td>1</td><td>100</td><td>55</td><td>44100</td><td>false</td><td>3.0</td><td>&quot;frame&quot;</td><td>&quot;[0.75, 0.25, 0.0]&quot;</td><td>1</td><td>&quot;(&#x27;RBMA&#x27;, &#x27;MDB&#x27;)&quot;</td><td>0.035</td><td>&quot;a2md_train&quot;</td><td>8.0411e-8</td><td>0.724782</td><td>&quot;Jun30_17-05-45_marclie-desktop&quot;</td><td>2025-06-30 17:05:45</td></tr><tr><td>&quot;ELU&quot;</td><td>8</td><td>false</td><td>0.9</td><td>0.999</td><td>true</td><td>true</td><td>1</td><td>19</td><td>&quot;S&quot;</td><td>true</td><td>0.025</td><td>3</td><td>0.3</td><td>&quot;5&quot;</td><td>false</td><td>30</td><td>1.0000e-8</td><td>&quot;A2MD&quot;</td><td>2048</td><td>true</td><td>3.5</td><td>1.3</td><td>true</td><td>441</td><td>true</td><td>0.25</td><td>0.1</td><td>0.000469</td><td>&quot;Three class standard&quot;</td><td>20000.0</td><td>20.0</td><td>0.7</td><td>0.6</td><td>&quot;crnn&quot;</td><td>84</td><td>false</td><td>24</td><td>1</td><td>1</td><td>16</td><td>0.021</td><td>true</td><td>&quot;constant&quot;</td><td>0.25</td><td>2</td><td>2</td><td>1.0</td><td>1</td><td>100</td><td>100</td><td>44100</td><td>false</td><td>4.0</td><td>&quot;frame&quot;</td><td>&quot;[0.75, 0.25, 0.0]&quot;</td><td>1</td><td>&quot;(&#x27;RBMA&#x27;, &#x27;MDB&#x27;)&quot;</td><td>0.035</td><td>&quot;a2md_train&quot;</td><td>2.9620e-8</td><td>0.716706</td><td>&quot;Jun30_17-08-24_marclie-desktop&quot;</td><td>2025-06-30 17:08:24</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;ELU&quot;</td><td>8</td><td>false</td><td>0.9</td><td>0.999</td><td>true</td><td>true</td><td>1</td><td>46</td><td>&quot;S&quot;</td><td>true</td><td>0.025</td><td>4</td><td>0.45</td><td>&quot;5&quot;</td><td>false</td><td>30</td><td>1.0000e-8</td><td>&quot;A2MD&quot;</td><td>2048</td><td>true</td><td>4.9</td><td>1.5</td><td>true</td><td>441</td><td>true</td><td>0.25</td><td>0.1</td><td>0.004061</td><td>&quot;Three class standard&quot;</td><td>20000.0</td><td>20.0</td><td>0.7</td><td>0.6</td><td>&quot;crnn&quot;</td><td>84</td><td>false</td><td>16</td><td>1</td><td>3</td><td>16</td><td>0.021</td><td>true</td><td>&quot;constant&quot;</td><td>0.25</td><td>2</td><td>2</td><td>1.0</td><td>1</td><td>100</td><td>109</td><td>44100</td><td>false</td><td>45.0</td><td>&quot;frame&quot;</td><td>&quot;[0.75, 0.25, 0.0]&quot;</td><td>1</td><td>&quot;(&#x27;RBMA&#x27;, &#x27;MDB&#x27;)&quot;</td><td>0.035</td><td>&quot;a2md_train&quot;</td><td>5.9861e-9</td><td>0.666329</td><td>&quot;Jun30_19-58-26_marclie-desktop&quot;</td><td>2025-06-30 19:58:26</td></tr><tr><td>&quot;SELU&quot;</td><td>4</td><td>false</td><td>0.9</td><td>0.999</td><td>true</td><td>true</td><td>2</td><td>16</td><td>&quot;S&quot;</td><td>true</td><td>0.025</td><td>4</td><td>0.0</td><td>&quot;5&quot;</td><td>false</td><td>30</td><td>1.0000e-8</td><td>&quot;A2MD&quot;</td><td>2048</td><td>true</td><td>7.0</td><td>1.4</td><td>true</td><td>441</td><td>true</td><td>0.25</td><td>0.1</td><td>0.000677</td><td>&quot;Three class standard&quot;</td><td>20000.0</td><td>20.0</td><td>0.7</td><td>0.6</td><td>&quot;crnn&quot;</td><td>64</td><td>false</td><td>24</td><td>0</td><td>5</td><td>16</td><td>0.021</td><td>true</td><td>&quot;constant&quot;</td><td>0.25</td><td>2</td><td>2</td><td>1.0</td><td>1</td><td>100</td><td>114</td><td>44100</td><td>false</td><td>46.0</td><td>&quot;frame&quot;</td><td>&quot;[0.75, 0.25, 0.0]&quot;</td><td>1</td><td>&quot;(&#x27;RBMA&#x27;, &#x27;MDB&#x27;)&quot;</td><td>0.035</td><td>&quot;a2md_train&quot;</td><td>3.3012e-12</td><td>0.729093</td><td>&quot;Jun30_20-02-54_marclie-desktop&quot;</td><td>2025-06-30 20:02:54</td></tr><tr><td>&quot;ELU&quot;</td><td>5</td><td>false</td><td>0.9</td><td>0.999</td><td>true</td><td>true</td><td>1</td><td>38</td><td>&quot;S&quot;</td><td>true</td><td>0.025</td><td>4</td><td>0.3</td><td>&quot;5&quot;</td><td>false</td><td>30</td><td>1.0000e-8</td><td>&quot;A2MD&quot;</td><td>2048</td><td>true</td><td>2.2</td><td>1.0</td><td>true</td><td>441</td><td>true</td><td>0.25</td><td>0.1</td><td>0.000397</td><td>&quot;Three class standard&quot;</td><td>20000.0</td><td>20.0</td><td>0.7</td><td>0.6</td><td>&quot;crnn&quot;</td><td>128</td><td>false</td><td>24</td><td>0</td><td>3</td><td>16</td><td>0.021</td><td>true</td><td>&quot;constant&quot;</td><td>0.25</td><td>2</td><td>2</td><td>1.0</td><td>1</td><td>100</td><td>94</td><td>44100</td><td>false</td><td>47.0</td><td>&quot;frame&quot;</td><td>&quot;[0.75, 0.25, 0.0]&quot;</td><td>1</td><td>&quot;(&#x27;RBMA&#x27;, &#x27;MDB&#x27;)&quot;</td><td>0.035</td><td>&quot;a2md_train&quot;</td><td>1.1468e-8</td><td>0.701014</td><td>&quot;Jun30_20-07-04_marclie-desktop&quot;</td><td>2025-06-30 20:07:04</td></tr><tr><td>&quot;ELU&quot;</td><td>9</td><td>false</td><td>0.9</td><td>0.999</td><td>true</td><td>true</td><td>1</td><td>35</td><td>&quot;S&quot;</td><td>true</td><td>0.025</td><td>3</td><td>0.2</td><td>&quot;5&quot;</td><td>false</td><td>30</td><td>1.0000e-8</td><td>&quot;A2MD&quot;</td><td>2048</td><td>true</td><td>4.2</td><td>1.7</td><td>true</td><td>441</td><td>true</td><td>0.25</td><td>0.1</td><td>0.000533</td><td>&quot;Three class standard&quot;</td><td>20000.0</td><td>20.0</td><td>0.7</td><td>0.6</td><td>&quot;crnn&quot;</td><td>84</td><td>false</td><td>32</td><td>0</td><td>2</td><td>16</td><td>0.021</td><td>true</td><td>&quot;constant&quot;</td><td>0.25</td><td>2</td><td>2</td><td>1.0</td><td>1</td><td>100</td><td>64</td><td>44100</td><td>false</td><td>48.0</td><td>&quot;frame&quot;</td><td>&quot;[0.75, 0.25, 0.0]&quot;</td><td>1</td><td>&quot;(&#x27;RBMA&#x27;, &#x27;MDB&#x27;)&quot;</td><td>0.035</td><td>&quot;a2md_train&quot;</td><td>9.5536e-10</td><td>0.736903</td><td>&quot;Jun30_20-10-49_marclie-desktop&quot;</td><td>2025-06-30 20:10:49</td></tr><tr><td>&quot;ELU&quot;</td><td>8</td><td>false</td><td>0.9</td><td>0.999</td><td>true</td><td>true</td><td>1</td><td>74</td><td>&quot;S&quot;</td><td>true</td><td>0.025</td><td>4</td><td>0.35</td><td>&quot;5&quot;</td><td>false</td><td>30</td><td>1.0000e-8</td><td>&quot;A2MD&quot;</td><td>2048</td><td>true</td><td>2.7</td><td>1.2</td><td>true</td><td>441</td><td>true</td><td>0.25</td><td>0.1</td><td>0.001432</td><td>&quot;Three class standard&quot;</td><td>20000.0</td><td>20.0</td><td>0.7</td><td>0.6</td><td>&quot;crnn&quot;</td><td>84</td><td>false</td><td>16</td><td>0</td><td>4</td><td>16</td><td>0.021</td><td>true</td><td>&quot;constant&quot;</td><td>0.25</td><td>2</td><td>2</td><td>1.0</td><td>1</td><td>100</td><td>75</td><td>44100</td><td>false</td><td>49.0</td><td>&quot;frame&quot;</td><td>&quot;[0.75, 0.25, 0.0]&quot;</td><td>1</td><td>&quot;(&#x27;RBMA&#x27;, &#x27;MDB&#x27;)&quot;</td><td>0.035</td><td>&quot;a2md_train&quot;</td><td>3.9279e-7</td><td>0.701464</td><td>&quot;Jun30_20-16-41_marclie-desktop&quot;</td><td>2025-06-30 20:16:41</td></tr></tbody></table></div>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T01:17:41.136574Z",
     "start_time": "2025-07-05T01:17:41.113350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "group_index = hparams.sort(\"dir_name\").group_by(\"learning_rate\", maintain_order=True).agg(\"dir_name\").drop(\"learning_rate\").with_row_index(\"group\").explode(\"dir_name\")\n",
    "params = hparams.join(group_index, on=\"dir_name\")\n",
    "grouped = scores.with_columns(pl.col(\"dir_name\").replace_strict(group_index[:, \"dir_name\"], group_index[:, \"group\"], return_dtype=pl.Int16).alias(\"group\"))\n",
    "aggregated = grouped.group_by(\"dir_name\", \"group\").agg(pl.col(\"step\").max(), cs.contains(\"core\").max()).group_by(\"group\").agg(pl.exclude(\"dir_name\").mean(), pl.exclude(\"dir_name\").std().name.suffix(\"_std\"))\n",
    "top_group = aggregated.sort(\"F-Score/Sum/Validation\", descending=True)[:3, \"group\"].to_list()\n",
    "top_group"
   ],
   "id": "1f449cb01bf27b86",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 8, 9]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T01:18:38.841159Z",
     "start_time": "2025-07-05T01:18:38.808922Z"
    }
   },
   "cell_type": "code",
   "source": [
    "grouped.filter(pl.col(\"group\").is_in(top_group))\n",
    "selected_params = params.filter(pl.col(\"group\").is_in(top_group)).drop(\"dir_name\", \"start_time\", \"F-Score\", \"seed\").unique()\n",
    "final_params = [get_settings(selected_params.filter(pl.col(\"group\") == group)) for group in top_group]\n",
    "print(final_params)"
   ],
   "id": "bdff998dc9c38fd1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'activation': 'ELU', 'batch_size': 12, 'beats': False, 'beta_1': 0.9, 'beta_2': 0.999, 'causal': True, 'center': True, 'channel_multiplication': 1, 'classifier_dim': 45, 'dataset_version': 'S', 'decoupled_weight_decay': True, 'detect_tolerance': 0.025, 'down_sample_factor': 4, 'dropout': 0.5, 'early_stopping': '5', 'ema': False, 'epochs': 30, 'epsilon': 1e-08, 'eval_set': 'A2MD', 'fft_size': 2048, 'flux': True, 'frame_length': 4.1, 'frame_overlap': 1.2, 'full_length_test': True, 'hop_size': 441, 'ignore_beats': True, 'label_lead_in': 0.25, 'label_lead_out': 0.1, 'learning_rate': 0.004733562104434663, 'mapping': 'Three class standard', 'mel_max': 20000.0, 'mel_min': 20.0, 'min_save_score': 0.7, 'min_test_score': 0.6, 'model_settings': 'crnn', 'n_mels': 84, 'normalize': False, 'num_channels': 16, 'num_conv_layers': 1, 'num_rnn_layers': 3, 'num_workers': 16, 'onset_cooldown': 0.021, 'pad_annotations': True, 'pad_mode': 'constant', 'pad_value': 0.25, 'peak_max_range': 2, 'peak_mean_range': 2, 'power': 1, 'pr_points': 100, 'rnn_units': 55, 'sample_rate': 44100, 'scheduler': False, 'segment_type': 'frame', 'splits': '[0.75, 0.25, 0.0]', 'test_batch_size': 1, 'test_sets': \"('RBMA', 'MDB')\", 'time_shift': 0.035, 'train_set': 'a2md_train', 'weight_decay': 8.041082029081438e-08}, {'activation': 'ELU', 'batch_size': 9, 'beats': False, 'beta_1': 0.9, 'beta_2': 0.999, 'causal': True, 'center': True, 'channel_multiplication': 1, 'classifier_dim': 35, 'dataset_version': 'S', 'decoupled_weight_decay': True, 'detect_tolerance': 0.025, 'down_sample_factor': 3, 'dropout': 0.2, 'early_stopping': '5', 'ema': False, 'epochs': 30, 'epsilon': 1e-08, 'eval_set': 'A2MD', 'fft_size': 2048, 'flux': True, 'frame_length': 4.2, 'frame_overlap': 1.7, 'full_length_test': True, 'hop_size': 441, 'ignore_beats': True, 'label_lead_in': 0.25, 'label_lead_out': 0.1, 'learning_rate': 0.0005334950964022998, 'mapping': 'Three class standard', 'mel_max': 20000.0, 'mel_min': 20.0, 'min_save_score': 0.7, 'min_test_score': 0.6, 'model_settings': 'crnn', 'n_mels': 84, 'normalize': False, 'num_channels': 32, 'num_conv_layers': 0, 'num_rnn_layers': 2, 'num_workers': 16, 'onset_cooldown': 0.021, 'pad_annotations': True, 'pad_mode': 'constant', 'pad_value': 0.25, 'peak_max_range': 2, 'peak_mean_range': 2, 'power': 1, 'pr_points': 100, 'rnn_units': 64, 'sample_rate': 44100, 'scheduler': False, 'segment_type': 'frame', 'splits': '[0.75, 0.25, 0.0]', 'test_batch_size': 1, 'test_sets': \"('RBMA', 'MDB')\", 'time_shift': 0.035, 'train_set': 'a2md_train', 'weight_decay': 9.55356591756452e-10}, {'activation': 'ELU', 'batch_size': 8, 'beats': False, 'beta_1': 0.9, 'beta_2': 0.999, 'causal': True, 'center': True, 'channel_multiplication': 1, 'classifier_dim': 74, 'dataset_version': 'S', 'decoupled_weight_decay': True, 'detect_tolerance': 0.025, 'down_sample_factor': 4, 'dropout': 0.35, 'early_stopping': '5', 'ema': False, 'epochs': 30, 'epsilon': 1e-08, 'eval_set': 'A2MD', 'fft_size': 2048, 'flux': True, 'frame_length': 2.7, 'frame_overlap': 1.2, 'full_length_test': True, 'hop_size': 441, 'ignore_beats': True, 'label_lead_in': 0.25, 'label_lead_out': 0.1, 'learning_rate': 0.0014315230037013243, 'mapping': 'Three class standard', 'mel_max': 20000.0, 'mel_min': 20.0, 'min_save_score': 0.7, 'min_test_score': 0.6, 'model_settings': 'crnn', 'n_mels': 84, 'normalize': False, 'num_channels': 16, 'num_conv_layers': 0, 'num_rnn_layers': 4, 'num_workers': 16, 'onset_cooldown': 0.021, 'pad_annotations': True, 'pad_mode': 'constant', 'pad_value': 0.25, 'peak_max_range': 2, 'peak_mean_range': 2, 'power': 1, 'pr_points': 100, 'rnn_units': 75, 'sample_rate': 44100, 'scheduler': False, 'segment_type': 'frame', 'splits': '[0.75, 0.25, 0.0]', 'test_batch_size': 1, 'test_sets': \"('RBMA', 'MDB')\", 'time_shift': 0.035, 'train_set': 'a2md_train', 'weight_decay': 3.9278519504013e-07}]\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Get Settings of runs of interest",
   "id": "5d5785844b3232fa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from settings import Config\n",
    "import polars as pl\n",
    "from copy import deepcopy"
   ],
   "id": "d40b406017c5af90"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "hparams = pl.scan_parquet(\"./processed/optuna.parquet\")",
   "id": "1f5424dbb7cf2f21"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "runs_of_interest = {\n",
    "    \"Attention best\": \"Feb14_00-01-28_marclie-desktop\",\n",
    "    \"Attention faster\": \"Feb15_15-25-56_marclie-desktop\",\n",
    "    \"Attention no conv\": \"Feb16_11-25-37_marclie-desktop\",\n",
    "    \"CRNN best\": \"Feb04_02-45-50_seppel-liemarce\",\n",
    "    \"CRNN small\": \"Feb01_17-55-46_seppel-liemarce\",\n",
    "    \"CRNN no conv\": \"Feb12_22-38-38_seppel-liemarce\",\n",
    "    \"Mamba best\": \"Feb25_20-22-44_seppel-liemarce\",\n",
    "    \"Mamba fast\": \"Feb22_15-27-14_marclie-desktop\",\n",
    "    \"Mamba no conv\": \"Feb26_17-41-56_seppel-liemarce\",\n",
    "}"
   ],
   "id": "ee6083bee239888e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "_ = pl.Config.restore_defaults()\n",
    "\n",
    "def drop_columns_that_are_all_null(_df: pl.DataFrame) -> pl.DataFrame:\n",
    "    return _df[[s.name for s in _df if not (s.null_count() == _df.height)]]\n",
    "\n",
    "def get_settings(dir_name: str):\n",
    "    global hparams\n",
    "    settings = hparams.filter(pl.col(\"dir_name\") == dir_name)\n",
    "    settings = drop_columns_that_are_all_null(settings.collect())\n",
    "    model_params = sorted(set([param for typ in [int, float, str, bool] for param in get_columns_with_type(typ, False)]) & set(settings.columns))\n",
    "    _dict = settings.select(pl.col(model_params)).to_dicts()[0]\n",
    "    activation_map = {\n",
    "        \"relu\": \"ReLU\",\n",
    "        \"selu\": \"SELU\",\n",
    "        \"silu\": \"SiLU\",\n",
    "        \"elu\": \"ELU\",\n",
    "    }\n",
    "    _dict[\"activation\"] = activation_map[_dict[\"activation\"]]\n",
    "    if _dict[\"model_settings\"] == \"crnn\" and \"hidden_units\" in _dict.keys():\n",
    "        _dict.pop(\"hidden_units\")\n",
    "    if _dict[\"model_settings\"] in [\"crnn\", \"mamba\", \"mamba_fast\"] and \"use_relative_pos\" in _dict.keys():\n",
    "        _dict.pop(\"use_relative_pos\")\n",
    "    if _dict[\"model_settings\"].startswith(\"mamba\") and \"expansion_factor\" in _dict.keys():\n",
    "        _dict.pop(\"expansion_factor\")\n",
    "    config = Config.from_flat_dict(_dict)\n",
    "    reversed_settings = {\n",
    "        **asdict(config.training),\n",
    "        **asdict(config.evaluation),\n",
    "        **asdict(config.dataset),\n",
    "        **asdict(config.model),\n",
    "    }\n",
    "    for key, item in _dict.items():\n",
    "        if key in [\"activation\", \"mapping\", \"splits\", \"test_sets\"]:\n",
    "            assert str(item) == str(reversed_settings[key])\n",
    "            # print(f\"{item} == {reversed_settings[key]}: Please check manually if {key} is equal\")\n",
    "            continue\n",
    "        assert item == reversed_settings[key], f\"Key {key} is mismatched: {item}({type(item)}) != {reversed_settings[key]}({type(reversed_settings[key])})\"\n",
    "    return _dict\n"
   ],
   "id": "7971d8718c3bd82b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "settings_of_interest = {name: get_settings(run) for name, run in runs_of_interest.items()}",
   "id": "d63770474ab6de50"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "final_experiment_params = deepcopy(settings_of_interest)\n",
    "for name, settings in final_experiment_params.items():\n",
    "    settings[\"pr_points\"] = 1000\n",
    "    settings[\"min_save_score\"] = 0.0\n",
    "    settings[\"min_test_score\"] = 0.0\n",
    "    settings[\"dataset_version\"] = \"M\"\n",
    "    settings[\"epochs\"] = 40\n",
    "    settings[\"test_sets\"] = \"('RBMA', 'MDB')\"\n",
    "    settings[\"eval_set\"] = \"A2MD\"\n",
    "    settings[\"scheduler\"] = False\n",
    "    settings[\"time_shift\"] = 0.015\n",
    "    settings[\"pad_value\"] = 0.5\n",
    "    settings[\"beats\"] = False\n",
    "    settings[\"causal\"] = True\n",
    "    settings[\"early_stopping\"] = None\n",
    "    settings[\"fft_size\"] = 1024\n",
    "    settings[\"ema\"] = True\n",
    "    settings.pop(\"num_workers\")\n",
    "\n",
    "identical_params = {**final_experiment_params[\"Attention best\"]}\n",
    "different_params = []\n",
    "for name, settings in final_experiment_params.items():\n",
    "    for key, value in settings.items():\n",
    "        if key in identical_params:\n",
    "            if not value == identical_params[key]:\n",
    "                identical_params.pop(key)\n",
    "                different_params.append(key)\n",
    "\n",
    "print(identical_params)\n",
    "print(different_params)\n",
    "\n",
    "for param in different_params:\n",
    "    print(f\"-------{param}---------\")\n",
    "    for name, settings in final_experiment_params.items():\n",
    "        if param in settings:\n",
    "            print(name, settings[param])\n",
    "\n",
    "print(\"\\n\\n\\n\")\n",
    "final_experiment_params"
   ],
   "id": "bb9a16c8250d4cf4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Test saved checkpoints",
   "id": "80242d59c9ee2c38"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T19:46:17.777698Z",
     "start_time": "2025-08-05T19:46:10.204798Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from glob import glob\n",
    "import os\n",
    "from model import EnsembleModel\n",
    "from settings import Config, asdict, TrainingSettings, DatasetSettings, EvaluationSettings\n",
    "from dataclasses import asdict as dataclass_asdict\n",
    "from model.cnn import CNN\n",
    "from model.cnnA import CNNAttention\n",
    "from model.cnnM2 import CNNMambaFast\n",
    "from model.CRNN import CRNN, CRNN_Vogl\n",
    "from dataset.RBMA13 import RBMA13\n",
    "from dataset.MDB_Drums import MDBDrums\n",
    "from dataset.A2MD import A2MD\n",
    "from dataset import get_dataloader\n",
    "from main import evaluate"
   ],
   "id": "11482a9fbee39a88",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T19:46:17.803608Z",
     "start_time": "2025-08-05T19:46:17.799415Z"
    }
   },
   "cell_type": "code",
   "source": [
    "folder = \"models/L 5 fold Mamba\"\n",
    "files = glob(os.path.join(folder, \"*.pt\"))"
   ],
   "id": "266e0a586bb99b3f",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T19:46:17.984552Z",
     "start_time": "2025-08-05T19:46:17.979852Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_model(file: str):\n",
    "    checkpoint = torch.load(file, map_location=\"cpu\")\n",
    "    training_settings = TrainingSettings.from_flat_dict(checkpoint[\"training_settings\"])\n",
    "    dataset_settings = DatasetSettings.from_flat_dict(checkpoint[\"dataset_settings\"])\n",
    "    n_classes = dataset_settings.annotation_settings.n_classes\n",
    "    n_mels = dataset_settings.audio_settings.n_mels\n",
    "    match training_settings.model_settings:\n",
    "        case \"cnn\":\n",
    "            model_settings = training_settings.get_model_settings_class().from_flat_dict(checkpoint[\"model_settings\"])\n",
    "            model = CNN(**dataclass_asdict(model_settings), n_classes=n_classes, n_mels=n_mels)\n",
    "        case \"cnn_attention\":\n",
    "            model_settings = training_settings.get_model_settings_class().from_flat_dict(checkpoint[\"model_settings\"])\n",
    "            model = CNNAttention(**dataclass_asdict(model_settings), n_classes=n_classes, n_mels=n_mels)\n",
    "        case \"mamba_fast\":\n",
    "            model_settings = training_settings.get_model_settings_class().from_flat_dict(checkpoint[\"model_settings\"])\n",
    "            model = CNNMambaFast(**dataclass_asdict(model_settings), n_classes=n_classes, n_mels=n_mels)\n",
    "        case \"crnn\":\n",
    "            model_settings = training_settings.get_model_settings_class().from_flat_dict(checkpoint[\"model_settings\"])\n",
    "            model = CRNN(**dataclass_asdict(model_settings), n_classes=n_classes, n_mels=n_mels)\n",
    "        case \"vogl\":\n",
    "            model = CRNN_Vogl(n_classes=n_classes, n_mels=n_mels, causal=True)\n",
    "        case _:\n",
    "            raise ValueError(f\"Unknown model type: {training_settings.model_settings}\")\n",
    "    model.load_state_dict(checkpoint[\"model\"])\n",
    "    return model, dataset_settings\n"
   ],
   "id": "bb2e4b7a161e0074",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T19:46:18.364522Z",
     "start_time": "2025-08-05T19:46:18.031567Z"
    }
   },
   "cell_type": "code",
   "source": [
    "models = [get_model(file) for file in files]\n",
    "dataset_settings = models[0][1]\n",
    "models = [model.to(\"cpu\") for model, _ in models]\n",
    "ensemble = EnsembleModel(models)"
   ],
   "id": "6bfc56c756b87918",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T19:46:38.072092Z",
     "start_time": "2025-08-05T19:46:18.376589Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset_settings.k_folds = None\n",
    "dataset_settings.dataset_version = \"L\"\n",
    "\n",
    "rbma = RBMA13(\"data/rbma_13\", dataset_settings, segment=False, splits=None, is_train=False, use_dataloader=True)\n",
    "mdb = MDBDrums(\"data/MDB Drums\", dataset_settings, segment=False, split=None, is_train=False, use_dataloader=True)\n",
    "a2md = A2MD(\"data/a2md_public\", dataset_settings, segment=False, split=None, is_train=False, use_dataloader=True)"
   ],
   "id": "b4d2637df50cef6a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/marcl/Documents/Uni/2023_24_WS/Automatic-Drum-Transcription/dataset/RBMA13.py:51: UserWarning: loadtxt: input contained no data: \"data/rbma_13/annotations/drums_full/RBMA_VA_2013-Track-07.drums\"\n",
      "  drums = np.loadtxt(os.path.join(root, file), delimiter=\"\\t\", )\n",
      "/mnt/c/Users/marcl/Documents/Uni/2023_24_WS/Automatic-Drum-Transcription/dataset/RBMA13.py:51: UserWarning: loadtxt: input contained no data: \"data/rbma_13/annotations/drums_full/RBMA_VA_2013-Track-26.drums\"\n",
      "  drums = np.loadtxt(os.path.join(root, file), delimiter=\"\\t\", )\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T19:46:38.094475Z",
     "start_time": "2025-08-05T19:46:38.091373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 1\n",
    "\n",
    "rbma_loader = get_dataloader(rbma, batch_size=batch_size, num_workers=16, is_train=False)\n",
    "mdb_loader = get_dataloader(mdb, batch_size=batch_size, num_workers=16, is_train=False)\n",
    "a2md_loader = get_dataloader(a2md, batch_size=3, num_workers=16, is_train=False)"
   ],
   "id": "7dc69743e54fdbbe",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T19:46:39.409098Z",
     "start_time": "2025-08-05T19:46:38.142986Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "ensemble = ensemble.to(device)"
   ],
   "id": "b8b3ed3c111bf1d",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T19:50:14.455523Z",
     "start_time": "2025-08-05T19:46:39.419345Z"
    }
   },
   "cell_type": "code",
   "source": [
    "evaluate(\n",
    "    0,\n",
    "    ensemble,\n",
    "    a2md_loader,\n",
    "    torch.nn.BCEWithLogitsLoss(reduction=\"none\"),\n",
    "    device,\n",
    "    EvaluationSettings(pr_points=1000, detect_tolerance=0.05, ),\n",
    "    None,\n",
    ")"
   ],
   "id": "ec3e0676e278b9c2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation:   0%|          | 0/521 [00:00<?, ?mini-batch/s]W0805 21:46:50.472000 28448 torch/_inductor/utils.py:1137] [0/0] Not enough SMs to use max_autotune_gemm mode\n",
      "Evaluation: 100%|██████████| 521/521 [01:57<00:00,  4.44mini-batch/s]\n",
      "100%|██████████| 1000/1000 [01:21<00:00, 12.28it/s]s]]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.08453381948187347,\n",
       " 0.8771509528160095,\n",
       " 0.8763518333435059,\n",
       " tensor([0.0860, 0.1730, 0.1170]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T19:53:01.988919Z",
     "start_time": "2025-08-05T19:52:37.887107Z"
    }
   },
   "cell_type": "code",
   "source": [
    "evaluate(\n",
    "    0,\n",
    "    models[0].to(device),\n",
    "    rbma_loader,\n",
    "    torch.nn.BCEWithLogitsLoss(reduction=\"none\"),\n",
    "    device,\n",
    "    EvaluationSettings(pr_points=1000, detect_tolerance=0.05, ),\n",
    "    None,\n",
    "    # thresholds=[0.0900, 0.1500, 0.1000]\n",
    ") # vogl 0.6689 first 0.6757 ensemble\n",
    "# mamba 0.6326 first 0.6753 ensemble"
   ],
   "id": "f5a115f4acc85b0b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 28/28 [00:22<00:00,  1.24mini-batch/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 16036.02it/s]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.09868937724136881,\n",
       " 0.6326425671577454,\n",
       " 0.6455109715461731,\n",
       " tensor([0.1180, 0.1790, 0.0840]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T19:54:08.465072Z",
     "start_time": "2025-08-05T19:53:58.865955Z"
    }
   },
   "cell_type": "code",
   "source": [
    "evaluate(\n",
    "    0,\n",
    "    models[0].to(device),\n",
    "    mdb_loader,\n",
    "    torch.nn.BCEWithLogitsLoss(reduction=\"none\"),\n",
    "    device,\n",
    "    EvaluationSettings(pr_points=1000, detect_tolerance=0.05, ),\n",
    "    None,\n",
    "    # thresholds=[0.0900, 0.1500, 0.1000]\n",
    ") # vogl 0.7329 ensemble 0.7154 first\n",
    "# mamba 0.7230 ensemble 0.6988 first"
   ],
   "id": "d3ae2c30840dee6d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 23/23 [00:09<00:00,  2.47mini-batch/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 8624.38it/s]]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.10995919467962306,\n",
       " 0.6988956332206726,\n",
       " 0.7007308602333069,\n",
       " tensor([0.1090, 0.1150, 0.1440]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8464045adc35139d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
