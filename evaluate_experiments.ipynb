{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "from tbparse import SummaryReader\n",
    "import os"
   ],
   "id": "b020a8d47540e269"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from settings import TrainingSettings, DatasetSettings, EvaluationSettings, CNNSettings, CNNMambaSettings, CNNAttentionSettings, CRNNSettings, asdict\n",
    "\n",
    "def get_columns_with_type(typ, get_only_model_settings=False) -> list[str]:\n",
    "    out = []\n",
    "    if not get_only_model_settings:\n",
    "        classes = [TrainingSettings, DatasetSettings, EvaluationSettings]\n",
    "        for cls in classes:\n",
    "            settings = cls()\n",
    "            dic = asdict(settings)\n",
    "            for name, value in dic.items():\n",
    "                if type(value) is typ:\n",
    "                    out.append(name)\n",
    "    classes = [CNNSettings, CNNAttentionSettings, CNNMambaSettings, CRNNSettings]\n",
    "    for cls in classes:\n",
    "        settings = cls(3, 84)\n",
    "        dic = asdict(settings)\n",
    "        for name, value in dic.items():\n",
    "            if type(value) is typ:\n",
    "                out.append(name)\n",
    "    return list(set(out))"
   ],
   "id": "33457be80aff0561"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "integer_values = list(set(get_columns_with_type(int) + [\"early_stopping\"]))\n",
    "boolean_values = get_columns_with_type(bool)\n",
    "float_values = get_columns_with_type(float)\n",
    "string_values = get_columns_with_type(str) + [\"dir_name\"]\n",
    "# string_values.remove(\"backbone\")\n",
    "integer_values.remove(\"dropout\")"
   ],
   "id": "abb40ad4fea3ef24"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "integer_values",
   "id": "3186bdafe166ae00"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Convert hyperparameters and per step scalars",
   "id": "f8c0ed05ec4c0364"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "pl.config.Config.restore_defaults()",
   "id": "a89a8ce343207451"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "log_dir = \"runs/CRNN/Vogl/Validation\"\n",
    "output_dir = \"processed/CRNN/Vogl/Validation\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "logs = SummaryReader(log_dir, pivot=True, extra_columns={'dir_name'})"
   ],
   "id": "417c21c9e0ad0181"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# convert types\n",
    "params = logs.hparams\n",
    "params = params.loc[:,~params.columns.duplicated()].copy()\n",
    "params[params == \"None\"] = None\n",
    "int_cols = list(set(integer_values) & set(params.columns.values))\n",
    "params[int_cols] = params[int_cols].astype(pd.Int64Dtype(), errors=\"ignore\")\n",
    "bool_cols = list(set(boolean_values) & set(params.columns.values))\n",
    "params[bool_cols] = params[bool_cols].astype(bool)\n",
    "float_cols = list(set(float_values) & set(params.columns.values))\n",
    "params[float_cols] = params[float_cols].astype(np.float64)\n",
    "string_cols = list(set(string_values) & set(params.columns.values))\n",
    "params[string_cols] = params[string_cols].astype(pd.StringDtype())\n",
    "params = pd.DataFrame(params)"
   ],
   "id": "56623deb3e2ecc51"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "scalars = logs.scalars\n",
    "# broken_columns = [\"F-Score/Avg/Test/RBMA\", \"F-Score/Sum/Test/RBMA\", \"Loss/Test/RBMA\"]\n",
    "# for col in broken_columns:\n",
    "#     scalars = scalars[scalars[col].apply(lambda x: isinstance(x, float))].copy(deep=True)\n",
    "# scalars[broken_columns] = scalars[broken_columns].astype(np.float64)\n",
    "scalars.drop_duplicates(subset=[\"dir_name\", \"step\"], keep=False, inplace=True)"
   ],
   "id": "5e160577222acba6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "logs.tensors",
   "id": "3042412e2c0cd1b5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "params = pl.from_pandas(params, nan_to_null=True)",
   "id": "e6960d5a86432103"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "scores = pl.from_pandas(scalars, nan_to_null=True)",
   "id": "625fb94cc7c4a2ed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "hparams = params.join(scores.select(pl.col(\"F-Score\", \"dir_name\")), on='dir_name', how='inner')\n",
    "hparams = hparams.select(pl.all().exclude(\"dir_name\"), pl.col(\"dir_name\").str.split(\"/\").list.first())"
   ],
   "id": "7c4dbe2d6087896"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# convert time\n",
    "hparams = hparams.with_columns(pl.col(\"dir_name\").str.split(\"_\").list.slice(0, 2).list.join(\"_\").str.to_datetime(\"%b%d_%H-%M-%S\", strict=False, ambiguous=\"earliest\").alias(\"start_time\"))\n",
    "hparams = hparams.with_columns(pl.datetime(2025, pl.col(\"start_time\").dt.month(), pl.col(\"start_time\").dt.day(), pl.col(\"start_time\").dt.hour(), pl.col(\"start_time\").dt.minute(), pl.col(\"start_time\").dt.second(), time_unit=\"ns\").alias(\"start_time\"))"
   ],
   "id": "5c6be2da9d782092"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "scalars",
   "id": "7f770e23ee6ee41d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "hparams.write_parquet(f\"{output_dir}/hparams.parquet\")\n",
    "scores.write_parquet(f\"{output_dir}/scores.parquet\")"
   ],
   "id": "418b26c2db8fa635"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Process plots",
   "id": "609f6e80a2fa953b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "logs_no_pivot = SummaryReader(log_dir, pivot=False, extra_columns={'dir_name'})",
   "id": "da5b1a6d12f95d7d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Convert raw tensor data\n",
    "tensors = logs_no_pivot.tensors\n",
    "columns = tensors[\"tag\"].unique().astype(str)\n",
    "columns = columns[~np.char.endswith(columns, \"Best_Thresholds\")]\n",
    "tensor_shapes = np.array(tensors.loc[tensors[\"tag\"] == columns[0]].iloc[0][\"value\"].shape)\n",
    "tensors[\"value\"] = tensors[\"value\"].apply(lambda x: x.flatten())"
   ],
   "id": "98585eae45c980fb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "tensors = pl.from_pandas(tensors, nan_to_null=True, schema_overrides={\"tag\": pl.String, \"dir_name\": pl.String}, include_index=True)\n",
    "tensors = tensors.filter(pl.col(\"tag\").is_in(columns))\n",
    "num_rows = tensors.select(pl.len()).to_series()[0]\n",
    "tensors = tensors.with_columns(pl.col(\"value\").reshape(tuple([num_rows, *tensor_shapes])).alias(\"value\"))"
   ],
   "id": "103de629e795f575"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "tensors = tensors.unique(subset=[\"dir_name\", \"step\", \"tag\"], keep=\"none\")\n",
    "tensors = tensors.pivot(values=[\"value\"], on=[\"tag\"], index=[\"dir_name\", \"step\"])\n",
    "tensors = tensors.sort(\"dir_name\", \"step\")"
   ],
   "id": "90ad68967c1098be"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "tensors.write_parquet(\"./processed/BA_fixed/tensors.parquet\", compression=\"zstd\", compression_level=22)",
   "id": "65d2966e292c34cd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Convert plots\n",
    "images = logs_no_pivot.images\n",
    "size = np.array(images.iloc[0][\"value\"].shape)\n",
    "images[\"value\"] = images[\"value\"].apply(lambda x: x.flatten())"
   ],
   "id": "994590cd9598f211"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# dumb stuff for datasets that barely fit into memory\n",
    "import gc\n",
    "\n",
    "data = [data for data in images[\"value\"].to_numpy() if type(data) is np.ndarray]\n",
    "images = images.drop(\"value\", axis=1)\n",
    "images_buf = images.copy(deep=True)\n",
    "del images\n",
    "gc.collect()\n",
    "data = np.array(data)\n",
    "images = images_buf\n",
    "del images_buf"
   ],
   "id": "751731fc4f31e981"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# plots = pl.read_parquet(\"./processed/images.parquet\")\n",
    "plots = pl.from_pandas(images, nan_to_null=True, schema_overrides={\"tag\": pl.String, \"dir_name\": pl.String}, include_index=True)\n",
    "plots = plots.with_columns(pl.Series(name=\"value\", values=data))"
   ],
   "id": "5cedfb81eae01109"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "num_rows = plots.select(pl.len()).to_series()[0]",
   "id": "8476895b80cafd53"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "plots = plots.with_columns(pl.col(\"value\").reshape(tuple([num_rows, *size])).alias(\"value\"))",
   "id": "f4c83ef2861ce9bb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "plots.write_parquet(\"./processed/BA_fixed/plots.parquet\", compression=\"zstd\")",
   "id": "8dbcf7740751bcbe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "# compress images for easier handling\n",
    "\n",
    "plots = pl.scan_parquet(\"./processed/BA_fixed/plots.parquet\")\n",
    "\n",
    "def convert_np_to_png(array: np.ndarray):\n",
    "    file_buf = BytesIO()\n",
    "    img = Image.fromarray(array, mode=\"RGB\")\n",
    "    img.save(file_buf, format=\"PNG\", optimize=True)\n",
    "    png_bin = file_buf.getvalue()\n",
    "    return png_bin"
   ],
   "id": "b65a21e0d853c197"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "plots.select(pl.len()).collect()",
   "id": "e5c8cfddedc82ae2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "test_img = plots.head(1).collect()[0, 3]\n",
    "png_img = convert_np_to_png(np.array(test_img))\n",
    "as_polars = pl.DataFrame({\"img\": [png_img]})\n",
    "png_img = as_polars[0, \"img\"]\n",
    "reversed_image = Image.open(BytesIO(png_img))\n",
    "reversed_image.show()\n",
    "\n",
    "test_img_map = plots.head(1).collect().with_columns(pl.col(\"value\").map_elements(lambda x: convert_np_to_png(np.array(x, dtype=np.uint8)), return_dtype=pl.Binary))[0, 3]\n",
    "reversed_image = Image.open(BytesIO(test_img_map))\n",
    "reversed_image.show()"
   ],
   "id": "1bc9a3c79f140f72"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# very slow\n",
    "plots.with_columns(pl.col(\"value\").map_elements(lambda x: convert_np_to_png(np.array(x, dtype=np.uint8)), return_dtype=pl.Binary, strategy=\"threading\")).sink_parquet(\"./processed/BA_fixed/plots_png.parquet\", compression_level=22)\n"
   ],
   "id": "529e074447f5370c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "plots = pl.scan_parquet(\"./processed/plots_png.parquet\")",
   "id": "7b10e112f600fc9d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plots = plots.unique(subset=[\"dir_name\", \"step\", \"tag\"], keep=\"none\").collect()\n",
    "plots = plots.pivot(values=[\"value\"], on=[\"tag\"], index=[\"dir_name\", \"step\"])\n",
    "plots = plots.sort(\"dir_name\", \"step\")"
   ],
   "id": "d8ddde32b2eabb50"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plots.write_parquet(\"./processed/BA_fixed/plots_png_pivot.parquet\", compression_level=22)\n",
    "del plots"
   ],
   "id": "6dcc9c65ee4a8fe5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Inspect data",
   "id": "ae28c8abfa978c21"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "hparams = pl.scan_parquet(\"./processed/hparams.parquet\")\n",
    "scalars = pl.scan_parquet(\"./processed/scores.parquet\")\n",
    "plots = pl.scan_parquet(\"./processed/plots_png_pivot.parquet\")"
   ],
   "id": "7f88051663e1414d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "hparams.collect()",
   "id": "7ef70d16a03f3c2c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "pl.Config.set_tbl_cols(100)\n",
    "pl.Config.set_tbl_rows(100)\n",
    "\n",
    "\n",
    "def get_model_settings(model_type: str) -> (pl.DataFrame, pl.DataFrame):\n",
    "    global hparams\n",
    "    model = hparams.filter(pl.col(\"model_settings\").str.contains(model_type))\n",
    "    non_null = model.select(pl.all().is_not_null().all()).row(0)\n",
    "    model = model[:, non_null]\n",
    "    different = model.select(pl.all().n_unique() > 1).row(0)\n",
    "    diff = model[:, different].sort(\"F-Score\", descending=True)\n",
    "    iden = model.select(pl.all().n_unique() == 1).row(0)\n",
    "    identical = model[:, iden].select(pl.all().exclude(\"dir_name\", \"F-Score\")).limit(1)\n",
    "\n",
    "    return diff, identical\n",
    "\n",
    "\n",
    "def get_history(name: str) -> pl.DataFrame:\n",
    "    global plots, scores\n",
    "    data = scores.filter(pl.col(\"dir_name\") == name)\n",
    "    prs = plots.filter(pl.col(\"dir_name\") == name)\n",
    "    data = data.join(prs, on=\"step\", how=\"inner\")\n",
    "    return data"
   ],
   "id": "1bca31173af07d03"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "unique, identical = get_model_settings(\"mamba\")\n",
    "print(identical)\n",
    "unique"
   ],
   "id": "4691bf0b298c6b80"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "unique, identical = get_model_settings(\"attention\")\n",
    "print(identical)\n",
    "unique"
   ],
   "id": "46d5cb9e18efadc7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "unique, identical = get_model_settings(\"cnn\")\n",
    "print(identical)\n",
    "unique"
   ],
   "id": "39564b9af843e74b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "unique, identical = get_model_settings(\"crnn\")\n",
    "print(identical)\n",
    "unique"
   ],
   "id": "53906a2741cb2612"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "best = unique.select(\"dir_name\").row(0)[0]\n",
    "history = get_history(best)\n",
    "tags = [\"Validation/PR-Curve/\" ,\"Test/RBMA_full/PR-Curve/\", \"Test/MDB_full/PR-Curve/\", \"Validation/Threshold-Curve/\", \"Test/RBMA_full/Threshold-Curve/\", \"Test/MDB_full/Threshold-Curve/\"]\n",
    "curves = []\n",
    "for tag in tags:\n",
    "    curves.append(history.select(pl.col(tag)).filter(pl.all().is_not_null()).row(-1)[0])\n",
    "# Show Curves in a grid\n",
    "fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    ax.imshow(curves[i])\n",
    "    ax.axis(\"off\")\n",
    "    # reduce spacing\n",
    "    ax.margins(0)\n",
    "    ax.axis(\"tight\")\n"
   ],
   "id": "416fda9adef4a51b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_model_dict(unique: pl.DataFrame, identical: pl.DataFrame) -> dict:\n",
    "    dics = []\n",
    "    for row in unique.to_dicts():\n",
    "        dics.append(row | identical.to_dicts()[0])\n",
    "    return dics"
   ],
   "id": "890a15a6a287691c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "get_model_dict(unique, identical)[0]",
   "id": "6521209a862ef26e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Get Value\n",
    "params.loc[params[\"dir_name\"].str.contains(best)][[\"full_length_test\"]]"
   ],
   "id": "f2d63559013a995b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "55eea5ae22539e25"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Import data from optuna",
   "id": "9a8ec9df69b9c649"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import optuna\n",
    "import ipywidgets as widgets\n",
    "import polars.selectors as cs\n",
    "from glob import glob\n",
    "\n",
    "_ = pl.Config.restore_defaults()"
   ],
   "id": "4e30e27e648cc091"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "hparams = pl.scan_parquet(\"processed/BA_fixed/hparams.parquet\")\n",
    "scalars = pl.scan_parquet(\"processed/BA_fixed/scores.parquet\")\n",
    "tensors = pl.scan_parquet(\"processed/BA_fixed/tensors.parquet\")"
   ],
   "id": "2116d44fd0eed456"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "storage: optuna.storages.BaseStorage = None\n",
    "\n",
    "db_files = glob(\"./optuna/*.db\")\n",
    "conn_strings = [\"sqlite:///\" + db for db in db_files]\n",
    "\n",
    "databases = [\"postgresql://BachelorarbeitSync:BachelorarbeitSyncPlsDontHackMe@192.168.2.206:5432\"]\n",
    "databases = conn_strings + databases\n",
    "\n",
    "db_dropdown = widgets.Dropdown(options=databases, description=\"Database: \")\n",
    "\n",
    "def set_storage(connection_string: str):\n",
    "    global storage\n",
    "    storage = optuna.storages.RDBStorage(\n",
    "        url=connection_string,\n",
    "        engine_kwargs={\"pool_pre_ping\": True, \"pool_recycle\": 3600, \"pool_timeout\": 3600},\n",
    "        heartbeat_interval=60,\n",
    "        grace_period=3600,\n",
    "    )\n",
    "\n",
    "widgets.interact(set_storage, connection_string=db_dropdown)\n",
    "\n",
    "study_dropdown = widgets.Dropdown(options=[], description=\"Study: \")\n",
    "\n",
    "def update_options(*args):\n",
    "    studies = storage.get_all_studies()\n",
    "    study_dropdown.options = [stdy.study_name for stdy in studies]\n",
    "db_dropdown.observe(update_options, \"value\")\n",
    "\n",
    "def select_study(selected_study):\n",
    "    global study\n",
    "    global storage\n",
    "\n",
    "    study = optuna.load_study(storage=storage, study_name=selected_study)\n",
    "\n",
    "_ = widgets.interact(select_study, selected_study=study_dropdown)\n",
    "study: optuna.Study = study"
   ],
   "id": "efa01af8568bd6eb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "study_data = study.trials_dataframe()\n",
    "study_data = pl.from_pandas(study_data).lazy()\n",
    "study_data = study_data.filter(pl.col(\"state\") == \"COMPLETE\").sort(cs.contains(\"value\"), descending=True)\n",
    "num_trials = study_data.select(pl.len()).collect()[0, 0]\n",
    "print(num_trials)\n",
    "\n",
    "optuna_param_list = study_data.select(cs.contains(\"params_\").name.map(lambda s: s.removeprefix(\"params_\"))).collect_schema()\n",
    "\n",
    "study_data = (\n",
    "    study_data\n",
    "    .select(cs.contains(\"params_\").name.map(lambda s: s.removeprefix(\"params_\")), ~cs.contains(\"params_\"))\n",
    "    .select(~(cs.contains(\"user\") | cs.contains(\"system_attrs\")), cs.contains(\"user\").name.map(lambda x: x.removeprefix(\"user_attrs_\")))\n",
    "    .select(~cs.contains(\"f_score\"), cs.contains(\"f_score\").name.prefix(\"optuna_\"))\n",
    "    .drop(\"state\", \"number\")\n",
    "    .with_columns(pl.lit(study.study_name).alias(\"study_name\"))\n",
    ")\n",
    "study_data = study_data.with_columns(pl.col(list(set(integer_values) & set(study_data.collect_schema().names()))).cast(pl.Int64))\n",
    "logs_param_list = hparams.collect_schema()\n",
    "matched_params = [key for key, dtype in optuna_param_list.items() if key in logs_param_list.keys()]\n",
    "\n",
    "# matched_params.remove(\"expansion_factor\")\n",
    "# matched_params.remove(\"hidden_units\")\n",
    "print(logs_param_list)\n",
    "matched_params"
   ],
   "id": "4218dccc3d88a959"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "hparams.collect()",
   "id": "5d0765bb9727df3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "study_data.collect()",
   "id": "68bfdff30d049cd6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from itertools import combinations\n",
    "\n",
    "res = reversed([list(combinations(matched_params, r)) for r in range(1, len(matched_params) + 1)])\n",
    "res = [list(sublist) for g in res for sublist in g]\n",
    "\n",
    "full_matched_params = None\n",
    "\n",
    "for comb in res:\n",
    "    joined = hparams.with_columns(cs.by_dtype(pl.String).exclude(\"dir_name\").str.to_lowercase()).join(study_data, on=comb, how=\"inner\", nulls_equal=True)\n",
    "    unique_matches = joined.unique(subset=\"datetime_start\").select(pl.len()).collect()[0, 0]\n",
    "    if unique_matches == num_trials:\n",
    "        full_matched_params = comb\n",
    "        print(full_matched_params)\n",
    "        break\n",
    "\n",
    "# assert full_matched_params is not None, \"No matching subset was found. Are logs for all the experiments present?\"\n",
    "\n",
    "# full_matched_params = comb\n",
    "mismatched_params = [param for param in matched_params if param not in full_matched_params]\n",
    "\n",
    "joined = hparams.with_columns(cs.by_dtype(pl.String).exclude(\"dir_name\").str.to_lowercase()).join(study_data, on=full_matched_params, how=\"cross\", nulls_equal=True).collect()\n",
    "joined = joined[[s.name for s in joined if not (s.null_count() == joined.height)]]\n",
    "joined = joined.filter((abs((pl.col(\"start_time\") - pl.col(\"datetime_start\"))) < pl.duration(minutes=30)) & (pl.col(\"start_time\") > pl.col(\"datetime_start\")))\n",
    "useful_cols = [col + \"_right\" for col in mismatched_params if col not in joined.columns]\n",
    "if len(useful_cols) > 0:\n",
    "    joined = joined.select(cs.exclude(useful_cols), pl.col(useful_cols).name.map(lambda s: s.removesuffix(\"_right\")))\n",
    "joined = joined.select(~cs.contains(\"_right\")) # parameters that are mismatched are most likely due to a param being generated but not assigned\n",
    "joined = joined[[s.name for s in joined if not (s.null_count() == joined.height)]]\n",
    "joined\n",
    "\n",
    "# sub = joined.select(\"dir_name\", \"datetime_start\", cs.contains(*mismatched_params))\n",
    "# sorted_mis = sorted(sub.columns)\n",
    "# sorted_mis.remove(\"datetime_start\")\n",
    "# sorted_mis.remove(\"dir_name\")\n",
    "# duplicated_dates = sub.group_by(\"datetime_start\").agg(pl.len().alias(\"count\")).filter(pl.col(\"count\") > 1).select(\"datetime_start\").to_series().to_list()\n",
    "# sub.select(\"dir_name\", \"datetime_start\", *sorted_mis).sort(\"datetime_start\").filter(pl.col(\"datetime_start\").is_in(duplicated_dates))"
   ],
   "id": "e8250d730388458"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# joined = hparams.with_columns(cs.by_dtype(pl.String).exclude(\"dir_name\").str.to_lowercase()).with_columns(pl.duration(minutes=2).alias(\"tolerance\")).join_where(study_data, abs((pl.col(\"start_time\") - pl.col(\"datetime_start\"))) < pl.col(\"tolerance\"))\n",
    "study_data.filter(~(pl.col(\"datetime_start\").is_in(joined.select(pl.col(\"datetime_start\")).to_series()))).collect()"
   ],
   "id": "31608e1e19861843"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pathlib\n",
    "\n",
    "if not pathlib.Path(\"./processed/optuna.parquet\").exists():\n",
    "    joined.write_parquet(\"./processed/optuna.parquet\")\n",
    "else:\n",
    "    optuna_collection = pl.read_parquet(\"./processed/optuna.parquet\")\n",
    "    optuna_cols = set(optuna_collection.columns)\n",
    "    optuna_schema = optuna_collection.schema\n",
    "    joined_cols = set(joined.columns)\n",
    "    joined_schema = joined.schema\n",
    "    missing_cols = joined_cols - optuna_cols\n",
    "    missing_schema = optuna_cols - joined_cols\n",
    "    print(missing_cols)\n",
    "    print(missing_schema)\n",
    "    for col in missing_cols:\n",
    "        optuna_collection = optuna_collection.with_columns(pl.lit(None).alias(col).cast(joined.schema[col]))\n",
    "    for col in missing_schema:\n",
    "        joined = joined.with_columns(pl.lit(None).alias(col).cast(optuna_collection.schema[col]))\n",
    "    joined = joined.select(pl.col(optuna_collection.columns))\n",
    "    out = pl.concat([optuna_collection, joined], how=\"vertical_relaxed\")\n",
    "    out.write_parquet(\"./processed/optuna.parquet\")\n",
    "\n",
    "    # optuna_collection.write_parquet(\"./processed/optuna.parquet\")\n",
    "\n"
   ],
   "id": "677743c5c83eb8ed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "optuna_collection = pl.read_parquet(\"./processed/optuna.parquet\")\n",
    "optuna_collection = optuna_collection[[s.name for s in optuna_collection if not (s.null_count() == optuna_collection.height)]]\n",
    "optuna_collection.unique(subset=\"dir_name\", keep=\"any\").write_parquet(\"./processed/optuna.parquet\", compression=\"zstd\")"
   ],
   "id": "72f6fcb6357059aa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "hparams.filter((pl.col(\"dataset_version\") == \"M\") | (pl.col(\"dataset_version\") == \"L\")).sort(\"F-Score\", descending=True).collect()",
   "id": "e55822bb5e4848c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "scalar_cols = set(scalars.collect_schema().names()) - {\"dir_name\", \"step\"}\n",
    "plots_cols = set(plots.collect_schema().names()) - {\"dir_name\", \"step\"}\n",
    "# data points that get lost in the join are most likely due to ^C exit\n",
    "joined_plots = scalars.join(plots, on=[\"dir_name\", \"step\"], how=\"inner\").sort([\"dir_name\", \"step\"])\n",
    "joined_plots.sink_parquet(\"./processed/plots_with_scalars.parquet\", compression=\"zstd\", compression_level=22)\n",
    "\n"
   ],
   "id": "d3f9eeb7d40fbd7e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# View Data",
   "id": "86045c5eb1118142"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from functools import lru_cache\n",
    "\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import optuna\n",
    "import ipywidgets as widgets\n",
    "import polars.selectors as cs\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import io"
   ],
   "id": "3904f3c9a6332eef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "pl.Config.set_tbl_hide_column_data_types(True)\n",
    "pl.Config.set_tbl_hide_dataframe_shape(True)\n",
    "pl.Config.set_tbl_cols(17)\n",
    "pl.Config.set_tbl_rows(20)\n",
    "\n",
    "def drop_columns_that_are_all_null(_df: pl.DataFrame) -> pl.DataFrame:\n",
    "    return _df[[s.name for s in _df if not (s.null_count() == _df.height)]]\n",
    "\n",
    "assert integer_values\n",
    "def sort_columns(_df: pl.DataFrame) -> pl.DataFrame:\n",
    "    parameters = set(integer_values) | set(boolean_values) | set(string_values) | set(float_values)\n",
    "    columns = set(_df.columns)\n",
    "    scores = sorted(list(set(_df.select(cs.contains(\"core\")).columns) - parameters))\n",
    "    losses = sorted(list(set(_df.select(cs.contains(\"oss\")).columns) - parameters))\n",
    "    parameters = sorted(list(parameters & columns))\n",
    "    sorted_columns: list[str] = [\"dir_name\", \"F-Score\", \"flops\", \"params\", *scores, *losses, *parameters, *columns]\n",
    "\n",
    "    sorted_columns = [col for col, _ in dict([item[::-1] for item in enumerate(sorted_columns)]).items()] # deduplication using dict as an ordered set\n",
    "    sorted_columns = [col for col in sorted_columns if col in columns]\n",
    "    return _df.select(pl.col(*sorted_columns))"
   ],
   "id": "9031d8c28307e3bc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "hparams = pl.scan_parquet(\"./processed/optuna.parquet\")\n",
    "plots = pl.scan_parquet(\"./processed/plots_png_pivot.parquet\")\n",
    "scalars = pl.scan_parquet(\"./processed/scores.parquet\")"
   ],
   "id": "86650bd7797d99ab"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model_settings: pl.DataFrame = None\n",
    "# select model type\n",
    "model_types = hparams.select(pl.col(\"model_settings\").unique()).collect().to_series().to_list()\n",
    "model_selector = widgets.Dropdown(options=model_types, description=\"Model Type: \")\n",
    "\n",
    "def set_model_settings(model_type: str):\n",
    "    global model_settings\n",
    "    best_values = scalars.select(\n",
    "        pl.col(\"dir_name\"),\n",
    "        cs.contains(\"core\").max().over(\"dir_name\"),\n",
    "        *[pl.col(\"step\").get(pl.col(_col).arg_max()).over(\"dir_name\").alias(_col + \"_step\") for _col in scalars.select(cs.contains(\"core\")).collect_schema().names()],\n",
    "        cs.contains(\"oss\").min().over(\"dir_name\"),\n",
    "        *[pl.col(\"step\").get(pl.col(_col).arg_min()).over(\"dir_name\").alias(_col + \"_step\") for _col in scalars.select(cs.contains(\"oss\")).collect_schema().names()]\n",
    "    ).unique(\"dir_name\")\n",
    "    _df = hparams.filter(pl.col(\"model_settings\") == model_type).collect()\n",
    "    _df = _df.lazy().join(best_values, on=pl.col(\"dir_name\")).sort(\"F-Score\", descending=True).collect()\n",
    "    model_settings = sort_columns(drop_columns_that_are_all_null(_df))\n",
    "\n",
    "\n",
    "# set_model_settings(\"crnn\")\n",
    "\n",
    "\n",
    "_ = widgets.interact(set_model_settings, model_type=model_selector)"
   ],
   "id": "805920cd18a40509"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "model_settings.sort(\"dir_name\")",
   "id": "8e9a90c91cebacfe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "selectable_range = 20\n",
    "\n",
    "\n",
    "run_options = model_settings.head(selectable_range).select(\"dir_name\").to_series().to_list()\n",
    "run_selector = widgets.Dropdown(options=run_options, value=run_options[0])\n",
    "\n",
    "run = run_options[0]\n",
    "\n",
    "@lru_cache\n",
    "def get_run(name: str):\n",
    "    settings = model_settings.filter(pl.col(\"dir_name\") == name)\n",
    "    settings = drop_columns_that_are_all_null(settings)\n",
    "    model_params = sorted(set([param for typ in [int, float, str, bool] for param in get_columns_with_type(typ, True)]) & set(settings.columns))\n",
    "    rows = [\n",
    "        settings.select(pl.col(*settings.columns[:4], \"dataset_version\")),\n",
    "        settings.select(cs.contains(\"/\") & cs.contains(\"core\") & ~cs.contains(\"_step\")),\n",
    "        settings.select(cs.contains(\"/\") & cs.contains(\"core\") & cs.contains(\"_step\")),\n",
    "        settings.select(pl.col(model_params)),\n",
    "    ]\n",
    "\n",
    "    values = scalars.lazy().filter(pl.col(\"dir_name\") == name).sort(\"step\")\n",
    "    losses = values.select(pl.col(\"step\"), cs.by_dtype(pl.Float64) & cs.contains(\"oss\")).collect()\n",
    "    losses = (\n",
    "        drop_columns_that_are_all_null(losses)\n",
    "            .lazy()\n",
    "            .unpivot(cs.contains(\"oss\"), index=\"step\", variable_name=\"tag\")\n",
    "            .with_columns(pl.col(\"tag\").str.split(\"/\").list.to_struct(n_field_strategy=\"max_width\", fields=[\"score\", \"split\", \"tag\"]))\n",
    "            .unnest(\"tag\")\n",
    "            .drop(\"score\")\n",
    "            .with_columns(pl.col(\"split\", \"tag\").fill_null(pl.col(\"split\")))\n",
    "            .collect()\n",
    "    )\n",
    "    f_scores = values.select(\"step\", cs.by_dtype(pl.Float64) & cs.contains(\"core\")).collect()\n",
    "\n",
    "    f_scores = (\n",
    "        drop_columns_that_are_all_null(f_scores)\n",
    "            .lazy()\n",
    "            .unpivot(cs.contains(\"core\"), index=\"step\", variable_name=\"tag\")\n",
    "            .with_columns(pl.col(\"tag\").str.split(\"/\").list.to_struct(n_field_strategy=\"max_width\", fields=[\"score\", \"type\", \"split\", \"tag\"]))\n",
    "            .unnest(\"tag\")\n",
    "            .drop(\"score\")\n",
    "            .with_columns(pl.col(\"type\", \"split\", \"tag\").fill_null(pl.col(\"split\")))\n",
    "            .collect()\n",
    "    )\n",
    "    return rows, losses, f_scores\n",
    "\n",
    "def plot_run(name: str):\n",
    "    global run\n",
    "    run = name\n",
    "    step_selector.max = scalars.filter(pl.col(\"dir_name\") == run).select(pl.col(\"step\").max()).collect().to_series()[0]\n",
    "\n",
    "    rows, losses, f_scores = get_run(name)\n",
    "    for row in rows:\n",
    "        print(row)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(15, 6), ncols=2)\n",
    "    sns.lineplot(data=losses, x=\"step\", y=\"value\", hue=\"tag\", ax=ax[0], style=\"split\")\n",
    "    ax[0].set_title(f\"Losses for {name}\")\n",
    "    ax[0].set_xlabel(\"Step\")\n",
    "    ax[0].set_ylabel(\"Loss\")\n",
    "    ax[0].set_yscale('log')\n",
    "\n",
    "    sns.lineplot(data=f_scores, x=\"step\", y=\"value\", hue=\"tag\", ax=ax[1], style=\"type\")\n",
    "    ax[1].set_title(f\"F-Scores for {name}\")\n",
    "    ax[1].set_xlabel(\"Step\")\n",
    "    ax[1].set_ylabel(\"F-Score\")\n",
    "    ax[1].set_ylim(0, 1)\n",
    "    ax[1].set_yticks(np.arange(0, 1.1, 0.1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# plot_run(run)\n",
    "\n",
    "\n",
    "def update_run_options(*args):\n",
    "    global run_selector\n",
    "    run_selector.options = model_settings.head(selectable_range).select(\"dir_name\").to_series().to_list()\n",
    "model_selector.observe(update_run_options, \"value\")\n",
    "\n",
    "@lru_cache\n",
    "def get_plots(run, step):\n",
    "    global plots\n",
    "    step_plots = (\n",
    "        plots.lazy()\n",
    "            .filter(pl.col(\"dir_name\") == run)\n",
    "            .sort(\"step\")\n",
    "            .select(pl.all().fill_null(strategy=\"forward\"))\n",
    "            .filter(pl.col(\"step\") == step)\n",
    "            .select(cs.by_dtype(pl.Binary))\n",
    "            .collect()\n",
    "    )\n",
    "    return drop_columns_that_are_all_null(step_plots)\n",
    "\n",
    "def plot_step(step: int):\n",
    "    global plots\n",
    "    step_plots = get_plots(run_selector.value, step)\n",
    "    pr_plots = step_plots.select(cs.contains(\"PR-Curve\"))\n",
    "    threshold_plots = step_plots.select(cs.contains(\"Threshold\"))\n",
    "    to_plot = [pr_plots, threshold_plots]\n",
    "    n_tags = pr_plots.shape[1]\n",
    "    if n_tags == 0:\n",
    "        return\n",
    "    _fig, _axs = plt.subplots(figsize=(10, 12), ncols=2, nrows=n_tags)\n",
    "    if n_tags == 1:\n",
    "        _axs = [_axs]\n",
    "    for _i, ax_row in enumerate(_axs):\n",
    "        for j, _ax in enumerate(ax_row):\n",
    "            png = to_plot[j][0, _i]\n",
    "            png_file = io.BytesIO(png)\n",
    "            img = np.asarray(Image.open(png_file, formats=[\"PNG\"]))\n",
    "            _ax.imshow(img)\n",
    "            _ax.axis(\"off\")\n",
    "            # reduce spacing\n",
    "            _ax.margins(0)\n",
    "            # _ax.axis(\"tight\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# plot_step(0)\n",
    "\n",
    "max_step = scalars.filter(pl.col(\"dir_name\") == run).select(pl.col(\"step\").max()).collect().to_series()[0]\n",
    "step_selector = widgets.IntSlider(min=0, max=max_step)\n",
    "\n",
    "def update_max_steps(*args):\n",
    "    step_selector.max = scalars.filter(pl.col(\"dir_name\") == run).select(pl.col(\"step\").max()).collect().to_series()[0]\n",
    "model_selector.observe(update_max_steps, \"value\")\n",
    "run_selector.observe(update_max_steps, \"value\")\n",
    "\n",
    "def plot_all(name: str, step: int):\n",
    "    print(model_settings.head(selectable_range).select(pl.col(*model_settings.columns[:4], \"dataset_version\")))\n",
    "    # print(model_settings.head(selectable_range).select(cs.contains(\"Test\")))\n",
    "    plot_run(name)\n",
    "    plot_step(step)\n",
    "\n",
    "# plot_all(run , 0)\n",
    "\n",
    "run_plot = widgets.interactive(plot_all, name=run_selector, step=step_selector)\n",
    "output = run_plot.children[-1]\n",
    "output.layout.height = '2400px'\n",
    "\n",
    "run_plot\n"
   ],
   "id": "c35564a53c8dd371"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluate hyperparameter validation",
   "id": "357566bf99f2a386"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from settings import TrainingSettings, DatasetSettings, EvaluationSettings, CNNSettings, CNNMambaSettings, CNNAttentionSettings, CRNNSettings, asdict, Config"
   ],
   "id": "e49cd7ea300231c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_columns_with_type(typ, get_only_model_settings=False) -> list[str]:\n",
    "    out = []\n",
    "    if not get_only_model_settings:\n",
    "        classes = [TrainingSettings, DatasetSettings, EvaluationSettings]\n",
    "        for cls in classes:\n",
    "            settings = cls()\n",
    "            dic = asdict(settings)\n",
    "            for name, value in dic.items():\n",
    "                if type(value) is typ:\n",
    "                    out.append(name)\n",
    "    classes = [CNNSettings, CNNAttentionSettings, CNNMambaSettings, CRNNSettings]\n",
    "    for cls in classes:\n",
    "        settings = cls(3, 84)\n",
    "        dic = asdict(settings)\n",
    "        for name, value in dic.items():\n",
    "            if type(value) is typ:\n",
    "                out.append(name)\n",
    "    return list(set(out))\n",
    "\n",
    "def drop_columns_that_are_all_null(_df: pl.DataFrame) -> pl.DataFrame:\n",
    "    return _df[[s.name for s in _df if not (s.null_count() == _df.height)]]\n",
    "\n",
    "def get_settings(param_row: pl.DataFrame):\n",
    "    settings = drop_columns_that_are_all_null(param_row)\n",
    "    model_params = sorted(set([param for typ in [int, float, str, bool] for param in get_columns_with_type(typ, False)]) & set(settings.columns))\n",
    "    _dict = settings.select(pl.col(model_params)).to_dicts()[0]\n",
    "    activation_map = {\n",
    "        \"relu\": \"ReLU\",\n",
    "        \"selu\": \"SELU\",\n",
    "        \"silu\": \"SiLU\",\n",
    "        \"elu\": \"ELU\",\n",
    "    }\n",
    "    if \"activation\" in _dict:\n",
    "        _dict[\"activation\"] = activation_map[_dict[\"activation\"]]\n",
    "    if _dict[\"model_settings\"] == \"crnn\" and \"hidden_units\" in _dict.keys():\n",
    "        _dict.pop(\"hidden_units\")\n",
    "    if _dict[\"model_settings\"] in [\"crnn\", \"mamba\", \"mamba_fast\"] and \"use_relative_pos\" in _dict.keys():\n",
    "        _dict.pop(\"use_relative_pos\")\n",
    "    if _dict[\"model_settings\"].startswith(\"mamba\") and \"expansion_factor\" in _dict.keys():\n",
    "        _dict.pop(\"expansion_factor\")\n",
    "    config = Config.from_flat_dict(_dict)\n",
    "    reversed_settings = {\n",
    "        **asdict(config.training),\n",
    "        **asdict(config.evaluation),\n",
    "        **asdict(config.dataset),\n",
    "    }\n",
    "    if config.model is not None:\n",
    "        reversed_settings.update(asdict(config.model))\n",
    "    for key, item in _dict.items():\n",
    "        if key in [\"activation\", \"mapping\", \"splits\", \"test_sets\"]:\n",
    "            assert str(item) == str(reversed_settings[key])\n",
    "            # print(f\"{item} == {reversed_settings[key]}: Please check manually if {key} is equal\")\n",
    "            continue\n",
    "        assert item == reversed_settings[key], f\"Key {key} is mismatched: {item}({type(item)}) != {reversed_settings[key]}({type(reversed_settings[key])})\"\n",
    "    return _dict"
   ],
   "id": "c0aa33c1d8d81bc1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "output_dir = \"processed/CRNN/Vogl/Validation\"",
   "id": "cb4c69a06108debd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "hparams = pl.read_parquet(f\"{output_dir}/hparams.parquet\")\n",
    "scores = pl.read_parquet(f\"{output_dir}/scores.parquet\").filter(pl.col(\"F-Score\").is_null()).drop(\"F-Score\")"
   ],
   "id": "b05771dbb89921d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "scores",
   "id": "d709c3af444dc64d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "group_index = hparams.sort(\"dir_name\").group_by(\"learning_rate\", maintain_order=True).agg(\"dir_name\").drop(\"learning_rate\").with_row_index(\"group\").explode(\"dir_name\")\n",
    "params = hparams.join(group_index, on=\"dir_name\")\n",
    "grouped = scores.with_columns(pl.col(\"dir_name\").replace_strict(group_index[:, \"dir_name\"], group_index[:, \"group\"], return_dtype=pl.Int16).alias(\"group\"))\n",
    "aggregated = grouped.group_by(\"dir_name\", \"group\").agg(pl.col(\"step\").max(), cs.contains(\"core\").max()).group_by(\"group\").agg(pl.exclude(\"dir_name\").mean(), pl.exclude(\"dir_name\").std().name.suffix(\"_std\"))\n",
    "top_group = aggregated.sort(\"F-Score/Sum/Validation\", descending=True)[:3, \"group\"].to_list()\n",
    "top_group"
   ],
   "id": "1f449cb01bf27b86"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "grouped.filter(pl.col(\"group\").is_in(top_group))\n",
    "selected_params = params.filter(pl.col(\"group\").is_in(top_group)).drop(\"dir_name\", \"start_time\", \"F-Score\", \"seed\").unique()\n",
    "for group in top_group:\n",
    "    print(get_settings(selected_params.filter(pl.col(\"group\") == group)))"
   ],
   "id": "bdff998dc9c38fd1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Get Settings of runs of interest",
   "id": "5d5785844b3232fa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from settings import Config\n",
    "import polars as pl\n",
    "from copy import deepcopy"
   ],
   "id": "d40b406017c5af90"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "hparams = pl.scan_parquet(\"./processed/optuna.parquet\")",
   "id": "1f5424dbb7cf2f21"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "runs_of_interest = {\n",
    "    \"Attention best\": \"Feb14_00-01-28_marclie-desktop\",\n",
    "    \"Attention faster\": \"Feb15_15-25-56_marclie-desktop\",\n",
    "    \"Attention no conv\": \"Feb16_11-25-37_marclie-desktop\",\n",
    "    \"CRNN best\": \"Feb04_02-45-50_seppel-liemarce\",\n",
    "    \"CRNN small\": \"Feb01_17-55-46_seppel-liemarce\",\n",
    "    \"CRNN no conv\": \"Feb12_22-38-38_seppel-liemarce\",\n",
    "    \"Mamba best\": \"Feb25_20-22-44_seppel-liemarce\",\n",
    "    \"Mamba fast\": \"Feb22_15-27-14_marclie-desktop\",\n",
    "    \"Mamba no conv\": \"Feb26_17-41-56_seppel-liemarce\",\n",
    "}"
   ],
   "id": "ee6083bee239888e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "_ = pl.Config.restore_defaults()\n",
    "\n",
    "def drop_columns_that_are_all_null(_df: pl.DataFrame) -> pl.DataFrame:\n",
    "    return _df[[s.name for s in _df if not (s.null_count() == _df.height)]]\n",
    "\n",
    "def get_settings(dir_name: str):\n",
    "    global hparams\n",
    "    settings = hparams.filter(pl.col(\"dir_name\") == dir_name)\n",
    "    settings = drop_columns_that_are_all_null(settings.collect())\n",
    "    model_params = sorted(set([param for typ in [int, float, str, bool] for param in get_columns_with_type(typ, False)]) & set(settings.columns))\n",
    "    _dict = settings.select(pl.col(model_params)).to_dicts()[0]\n",
    "    activation_map = {\n",
    "        \"relu\": \"ReLU\",\n",
    "        \"selu\": \"SELU\",\n",
    "        \"silu\": \"SiLU\",\n",
    "        \"elu\": \"ELU\",\n",
    "    }\n",
    "    _dict[\"activation\"] = activation_map[_dict[\"activation\"]]\n",
    "    if _dict[\"model_settings\"] == \"crnn\" and \"hidden_units\" in _dict.keys():\n",
    "        _dict.pop(\"hidden_units\")\n",
    "    if _dict[\"model_settings\"] in [\"crnn\", \"mamba\", \"mamba_fast\"] and \"use_relative_pos\" in _dict.keys():\n",
    "        _dict.pop(\"use_relative_pos\")\n",
    "    if _dict[\"model_settings\"].startswith(\"mamba\") and \"expansion_factor\" in _dict.keys():\n",
    "        _dict.pop(\"expansion_factor\")\n",
    "    config = Config.from_flat_dict(_dict)\n",
    "    reversed_settings = {\n",
    "        **asdict(config.training),\n",
    "        **asdict(config.evaluation),\n",
    "        **asdict(config.dataset),\n",
    "        **asdict(config.model),\n",
    "    }\n",
    "    for key, item in _dict.items():\n",
    "        if key in [\"activation\", \"mapping\", \"splits\", \"test_sets\"]:\n",
    "            assert str(item) == str(reversed_settings[key])\n",
    "            # print(f\"{item} == {reversed_settings[key]}: Please check manually if {key} is equal\")\n",
    "            continue\n",
    "        assert item == reversed_settings[key], f\"Key {key} is mismatched: {item}({type(item)}) != {reversed_settings[key]}({type(reversed_settings[key])})\"\n",
    "    return _dict\n"
   ],
   "id": "7971d8718c3bd82b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "settings_of_interest = {name: get_settings(run) for name, run in runs_of_interest.items()}",
   "id": "d63770474ab6de50"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "final_experiment_params = deepcopy(settings_of_interest)\n",
    "for name, settings in final_experiment_params.items():\n",
    "    settings[\"pr_points\"] = 1000\n",
    "    settings[\"min_save_score\"] = 0.0\n",
    "    settings[\"min_test_score\"] = 0.0\n",
    "    settings[\"dataset_version\"] = \"M\"\n",
    "    settings[\"epochs\"] = 40\n",
    "    settings[\"test_sets\"] = \"('RBMA', 'MDB')\"\n",
    "    settings[\"eval_set\"] = \"A2MD\"\n",
    "    settings[\"scheduler\"] = False\n",
    "    settings[\"time_shift\"] = 0.015\n",
    "    settings[\"pad_value\"] = 0.5\n",
    "    settings[\"beats\"] = False\n",
    "    settings[\"causal\"] = True\n",
    "    settings[\"early_stopping\"] = None\n",
    "    settings[\"fft_size\"] = 1024\n",
    "    settings[\"ema\"] = True\n",
    "    settings.pop(\"num_workers\")\n",
    "\n",
    "identical_params = {**final_experiment_params[\"Attention best\"]}\n",
    "different_params = []\n",
    "for name, settings in final_experiment_params.items():\n",
    "    for key, value in settings.items():\n",
    "        if key in identical_params:\n",
    "            if not value == identical_params[key]:\n",
    "                identical_params.pop(key)\n",
    "                different_params.append(key)\n",
    "\n",
    "print(identical_params)\n",
    "print(different_params)\n",
    "\n",
    "for param in different_params:\n",
    "    print(f\"-------{param}---------\")\n",
    "    for name, settings in final_experiment_params.items():\n",
    "        if param in settings:\n",
    "            print(name, settings[param])\n",
    "\n",
    "print(\"\\n\\n\\n\")\n",
    "final_experiment_params"
   ],
   "id": "bb9a16c8250d4cf4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f27c1ee9302107a1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4e254706ecc58251"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
